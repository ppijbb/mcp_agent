"""
Playwright-Lighthouseë¥¼ ì‚¬ìš©í•œ ì‹¤ì œ SEO ë¶„ì„
Medium ê¸€ì˜ helpers.ts íŒŒì¼ì„ Pythonìœ¼ë¡œ ë³€í™˜
"""

import asyncio
import json
import tempfile
import os
from typing import Dict, Any
from datetime import datetime
from .config_loader import seo_config


class PlaywrightLighthouseAnalyzer:
    """Playwright-Lighthouseë¥¼ ì‚¬ìš©í•œ ì›¹ì‚¬ì´íŠ¸ ë¶„ì„ê¸°"""

    def __init__(self):
        self.port = 9222
        self.temp_dir = tempfile.mkdtemp()

    async def analyze_website(self, url: str, strategy: str = "mobile") -> Dict[str, Any]:
        """
        ì›¹ì‚¬ì´íŠ¸ SEO ë¶„ì„ ìˆ˜í–‰

        Args:
            url: ë¶„ì„í•  ì›¹ì‚¬ì´íŠ¸ URL
            strategy: "mobile" ë˜ëŠ” "desktop"

        Returns:
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        try:
            if not url:
                raise ValueError("ë¶„ì„í•  URLì´ í•„ìš”í•©ë‹ˆë‹¤")

            if strategy not in ["mobile", "desktop"]:
                raise ValueError(f"ì˜ëª»ëœ strategy: {strategy}. 'mobile' ë˜ëŠ” 'desktop'ë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤")

            # ì„¤ì • íŒŒì¼ì—ì„œ Lighthouse ì„¤ì • ë¡œë“œ
            config = seo_config.get_lighthouse_config(strategy)

            # Node.js ìŠ¤í¬ë¦½íŠ¸ë¡œ Lighthouse ì‹¤í–‰
            lighthouse_script = self._create_lighthouse_script(url, config, strategy)

            # Node.js ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
            result = await self._run_lighthouse_script(lighthouse_script)

            # ê²°ê³¼ íŒŒì‹± ë° ì •ë¦¬
            analyzed_data = self._parse_lighthouse_result(result, url)

            return analyzed_data

        except Exception as e:
            error_msg = f"Lighthouse ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
            raise Exception(error_msg)

    def _create_lighthouse_script(self, url: str, config: Dict, strategy: str) -> str:
        """Node.js Lighthouse ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""

        script_content = f"""
const lighthouse = require('lighthouse');
const chromeLauncher = require('chrome-launcher');

async function runLighthouse() {{
    const chrome = await chromeLauncher.launch({{
        chromeFlags: ['--headless', '--no-sandbox', '--disable-dev-shm-usage']
    }});

    const options = {{
        logLevel: 'info',
        output: 'json',
        port: chrome.port,
        emulatedFormFactor: '{strategy}',
        onlyCategories: ['performance', 'seo', 'accessibility', 'best-practices']
    }};

    const runnerResult = await lighthouse('{url}', options);

    await chrome.kill();

    console.log(JSON.stringify(runnerResult.lighthouseResult));
}}

runLighthouse().catch(console.error);
"""

        # ì„ì‹œ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ìƒì„±
        script_path = os.path.join(self.temp_dir, f"lighthouse_{strategy}_{int(datetime.now().timestamp())}.js")
        with open(script_path, 'w') as f:
            f.write(script_content)

        return script_path

    async def _run_lighthouse_script(self, script_path: str) -> Dict[str, Any]:
        """Node.js ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰"""

        try:
            # Node.jsë¡œ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
            process = await asyncio.create_subprocess_exec(
                'node', script_path,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )

            stdout, stderr = await process.communicate()

            if process.returncode == 0:
                result = json.loads(stdout.decode())
                return result
            else:
                raise Exception(f"Lighthouse ì‹¤í–‰ ì‹¤íŒ¨: {stderr.decode()}")

        except Exception as e:
            raise Exception(f"ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if os.path.exists(script_path):
                os.remove(script_path)

    def _parse_lighthouse_result(self, result: Dict[str, Any], url: str) -> Dict[str, Any]:
        """Lighthouse ê²°ê³¼ íŒŒì‹± ë° SEO Doctor í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""

        try:
            categories = result.get('categories', {})
            audits = result.get('audits', {})

            # ì ìˆ˜ ì¶”ì¶œ
            performance_score = int(categories.get('performance', {}).get('score', 0) * 100)
            seo_score = int(categories.get('seo', {}).get('score', 0) * 100)
            accessibility_score = int(categories.get('accessibility', {}).get('score', 0) * 100)
            best_practices_score = int(categories.get('best-practices', {}).get('score', 0) * 100)

            # ì „ì²´ ì ìˆ˜ ê³„ì‚° (ì„±ëŠ¥ê³¼ SEO ê°€ì¤‘ í‰ê· )
            overall_score = int((performance_score * 0.4 + seo_score * 0.4 +
                               accessibility_score * 0.1 + best_practices_score * 0.1))

            # ì£¼ìš” ë©”íŠ¸ë¦­ ì¶”ì¶œ
            metrics = self._extract_key_metrics(audits)

            # ë¬¸ì œì  ë° ê°œì„ ì‚¬í•­ ì¶”ì¶œ
            issues = self._extract_issues(audits, categories)

            # ë³µêµ¬ ì‹œê°„ ì˜ˆì¸¡
            recovery_days = self._estimate_recovery_time(overall_score, len(issues))

            # ì‘ê¸‰ ë ˆë²¨ ê²°ì •
            emergency_level = self._determine_emergency_level(overall_score)

            return {
                "url": url,
                "overall_score": overall_score,
                "scores": {
                    "performance": performance_score,
                    "seo": seo_score,
                    "accessibility": accessibility_score,
                    "best_practices": best_practices_score
                },
                "metrics": metrics,
                "issues": issues,
                "recovery_days": recovery_days,
                "emergency_level": emergency_level,
                "improvement_potential": min(40, 100 - overall_score),
                "timestamp": datetime.now().isoformat(),
                "raw_lighthouse_result": result  # ì›ë³¸ ë°ì´í„° ë³´ì¡´
            }

        except Exception as e:
            raise Exception(f"ê²°ê³¼ íŒŒì‹± ì˜¤ë¥˜: {str(e)}")

    def _extract_key_metrics(self, audits: Dict[str, Any]) -> Dict[str, Any]:
        """ì£¼ìš” ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¶”ì¶œ"""

        metrics = {}

        # Core Web Vitals
        if 'largest-contentful-paint' in audits:
            lcp = audits['largest-contentful-paint'].get('numericValue', 0)
            metrics['lcp'] = f"{lcp/1000:.2f}ì´ˆ"

        if 'first-contentful-paint' in audits:
            fcp = audits['first-contentful-paint'].get('numericValue', 0)
            metrics['fcp'] = f"{fcp/1000:.2f}ì´ˆ"

        if 'cumulative-layout-shift' in audits:
            cls = audits['cumulative-layout-shift'].get('numericValue', 0)
            metrics['cls'] = f"{cls:.3f}"

        if 'total-blocking-time' in audits:
            tbt = audits['total-blocking-time'].get('numericValue', 0)
            metrics['tbt'] = f"{tbt}ms"

        if 'speed-index' in audits:
            si = audits['speed-index'].get('numericValue', 0)
            metrics['speed_index'] = f"{si/1000:.2f}ì´ˆ"

        return metrics

    def _extract_issues(self, audits: Dict[str, Any], categories: Dict[str, Any]) -> list:
        """ë¬¸ì œì  ì¶”ì¶œ ë° ë¶„ë¥˜"""

        issues = []

        # ì„±ëŠ¥ ë¬¸ì œ
        performance_audits = categories.get('performance', {}).get('auditRefs', [])
        for audit_ref in performance_audits:
            audit_id = audit_ref.get('id')
            if audit_id in audits:
                audit = audits[audit_id]
                if audit.get('score', 1) < 0.9:  # 90% ë¯¸ë§Œì¸ ê²½ìš°
                    issues.append(f"ğŸš€ ì„±ëŠ¥: {audit.get('title', audit_id)}")

        # SEO ë¬¸ì œ
        seo_audits = categories.get('seo', {}).get('auditRefs', [])
        for audit_ref in seo_audits:
            audit_id = audit_ref.get('id')
            if audit_id in audits:
                audit = audits[audit_id]
                if audit.get('score', 1) < 1.0:  # 100% ë¯¸ë§Œì¸ ê²½ìš°
                    issues.append(f"ğŸ” SEO: {audit.get('title', audit_id)}")

        # ì ‘ê·¼ì„± ë¬¸ì œ
        accessibility_audits = categories.get('accessibility', {}).get('auditRefs', [])
        for audit_ref in accessibility_audits:
            audit_id = audit_ref.get('id')
            if audit_id in audits:
                audit = audits[audit_id]
                if audit.get('score', 1) < 0.9:  # 90% ë¯¸ë§Œì¸ ê²½ìš°
                    issues.append(f"â™¿ ì ‘ê·¼ì„±: {audit.get('title', audit_id)}")

        return issues[:8]  # ìµœëŒ€ 8ê°œê¹Œì§€ë§Œ í‘œì‹œ

    def _estimate_recovery_time(self, score: int, issue_count: int) -> int:
        """íšŒë³µ ì‹œê°„ ì˜ˆì¸¡ - ì„¤ì • ê¸°ë°˜"""
        return seo_config.calculate_recovery_time(score, issue_count)

    def _determine_emergency_level(self, score: int) -> str:
        """ì‘ê¸‰ ë ˆë²¨ ê²°ì • - ì„¤ì • ê¸°ë°˜"""
        emergency_info = seo_config.determine_emergency_level(score)
        return f"{emergency_info['emoji']} {emergency_info['label']}"

    def __del__(self):
        """ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬"""
        try:
            import shutil
            if os.path.exists(self.temp_dir):
                shutil.rmtree(self.temp_dir)
        except:
            pass


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
lighthouse_analyzer = PlaywrightLighthouseAnalyzer()


async def analyze_website_with_lighthouse(url: str, strategy: str = "mobile") -> Dict[str, Any]:
    """ì™¸ë¶€ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê°„ë‹¨í•œ ì¸í„°í˜ì´ìŠ¤"""
    return await lighthouse_analyzer.analyze_website(url, strategy)
