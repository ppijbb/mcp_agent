"""
ëª¨ë‹ˆí„°ë§ Agent
==============

ì‹œìŠ¤í…œ ìƒíƒœ ë° ì„±ëŠ¥ì„ ëª¨ë‹ˆí„°ë§í•˜ê³  ì˜ˆì¸¡ì  ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” Agent
"""

import asyncio
import os
import json
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict

from mcp_agent.app import MCPApp
from mcp_agent.agents.agent import Agent
from mcp_agent.workflows.orchestrator.orchestrator import Orchestrator
from mcp_agent.workflows.llm.augmented_llm import RequestParams
from mcp_agent.workflows.llm.augmented_llm_openai import OpenAIAugmentedLLM

@dataclass
class MetricData:
    """ë©”íŠ¸ë¦­ ë°ì´í„°"""
    name: str
    value: float
    unit: str
    timestamp: datetime
    labels: Dict[str, str]

@dataclass
class AlertRule:
    """ì•Œë¦¼ ê·œì¹™"""
    name: str
    condition: str
    threshold: float
    duration: str
    severity: str  # info, warning, critical
    enabled: bool = True

@dataclass
class Alert:
    """ì•Œë¦¼"""
    id: str
    rule_name: str
    message: str
    severity: str
    timestamp: datetime
    status: str  # firing, resolved
    labels: Dict[str, str]

@dataclass
class PerformanceAnalysis:
    """ì„±ëŠ¥ ë¶„ì„ ê²°ê³¼"""
    resource_usage: Dict[str, float]
    bottlenecks: List[str]
    recommendations: List[str]
    predicted_scaling_needs: Dict[str, Any]
    health_score: float

class MonitoringAgent:
    """mcp_agent ê¸°ë°˜ ëª¨ë‹ˆí„°ë§ Agent"""
    
    def __init__(self, output_dir: str = "monitoring_reports"):
        self.output_dir = output_dir
        os.makedirs(self.output_dir, exist_ok=True)
        
        # mcp_agent App ì´ˆê¸°í™” (ì„¤ì • íŒŒì¼ ì—†ì´ ë™ì  ìƒì„±)
        self.app = MCPApp(
            name="monitoring_agent",
            human_input_callback=None
        )
        
        # Agent ì„¤ì •
        self.agent = Agent(
            name="monitoring_agent",
            instruction="ì‹œìŠ¤í…œ ìƒíƒœ ë° ì„±ëŠ¥ì„ ëª¨ë‹ˆí„°ë§í•˜ê³  ì˜ˆì¸¡ì  ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” Agentì…ë‹ˆë‹¤.",
            server_names=["monitoring-mcp", "k8s-mcp"],
            llm_factory=lambda: OpenAIAugmentedLLM(
                model="gpt-4",
            ),
        )
        
        # ëª¨ë‹ˆí„°ë§ ìƒíƒœ
        self.active_alerts: List[Alert] = []
        self.alert_rules: List[AlertRule] = []
        self.metric_history: Dict[str, List[MetricData]] = {}
        
        # ê¸°ë³¸ ì•Œë¦¼ ê·œì¹™ ì„¤ì •
        self._setup_default_alert_rules()
        
    def _setup_default_alert_rules(self):
        """ê¸°ë³¸ ì•Œë¦¼ ê·œì¹™ ì„¤ì •"""
        self.alert_rules = [
            AlertRule(
                name="high_cpu_usage",
                condition="cpu_usage > 80%",
                threshold=80.0,
                duration="5m",
                severity="warning"
            ),
            AlertRule(
                name="high_memory_usage",
                condition="memory_usage > 85%",
                threshold=85.0,
                duration="5m",
                severity="warning"
            ),
            AlertRule(
                name="pod_restart_frequency",
                condition="pod_restarts > 5",
                threshold=5.0,
                duration="10m",
                severity="critical"
            ),
            AlertRule(
                name="high_error_rate",
                condition="error_rate > 5%",
                threshold=5.0,
                duration="2m",
                severity="critical"
            ),
            AlertRule(
                name="disk_usage_high",
                condition="disk_usage > 90%",
                threshold=90.0,
                duration="5m",
                severity="warning"
            )
        ]
    
    async def start_monitoring(self, namespace: str = "default"):
        """ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        try:
            async with self.app.run() as app_context:
                context = app_context.context
                logger = app_context.logger
                
                logger.info(f"Starting monitoring for namespace: {namespace}")
                
                # 1. ì´ˆê¸° ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
                await self._check_initial_system_state(namespace, context)
                
                # 2. ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œì‘
                await self._start_metric_collection(namespace, context)
                
                # 3. ì•Œë¦¼ ëª¨ë‹ˆí„°ë§ ì‹œì‘
                await self._start_alert_monitoring(context)
                
                # 4. ì˜ˆì¸¡ì  ë¶„ì„ ì‹œì‘
                await self._start_predictive_analysis(context)
                
                logger.info("Monitoring started successfully")
                
        except Exception as e:
            logger.error(f"Failed to start monitoring: {e}")
            raise
    
    async def _check_initial_system_state(self, namespace: str, context):
        """ì´ˆê¸° ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸"""
        logger = context.logger
        
        # í´ëŸ¬ìŠ¤í„° ìƒíƒœ í™•ì¸
        cluster_health = await self._get_cluster_health(context)
        logger.info(f"Cluster health: {cluster_health}")
        
        # ë…¸ë“œ ìƒíƒœ í™•ì¸
        nodes = await self._get_node_status(context)
        logger.info(f"Node count: {len(nodes)}")
        
        # ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë¦¬ì†ŒìŠ¤ í™•ì¸
        namespace_resources = await self._get_namespace_resources(namespace, context)
        logger.info(f"Namespace resources: {namespace_resources}")
        
        # ì´ˆê¸° ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        initial_metrics = await self._collect_initial_metrics(namespace, context)
        self.metric_history["initial"] = initial_metrics
        
        logger.info("Initial system state check completed")
    
    async def _start_metric_collection(self, namespace: str, context):
        """ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œì‘"""
        logger = context.logger
        
        # ì£¼ê¸°ì  ë©”íŠ¸ë¦­ ìˆ˜ì§‘ íƒœìŠ¤í¬ ì‹œì‘
        asyncio.create_task(self._periodic_metric_collection(namespace, context))
        
        logger.info("Metric collection started")
    
    async def _periodic_metric_collection(self, namespace: str, context):
        """ì£¼ê¸°ì  ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        logger = context.logger
        
        while True:
            try:
                # CPU ë©”íŠ¸ë¦­ ìˆ˜ì§‘
                cpu_metrics = await self._collect_cpu_metrics(namespace, context)
                self._store_metrics("cpu", cpu_metrics)
                
                # ë©”ëª¨ë¦¬ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
                memory_metrics = await self._collect_memory_metrics(namespace, context)
                self._store_metrics("memory", memory_metrics)
                
                # ë„¤íŠ¸ì›Œí¬ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
                network_metrics = await self._collect_network_metrics(namespace, context)
                self._store_metrics("network", network_metrics)
                
                # ë””ìŠ¤í¬ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
                disk_metrics = await self._collect_disk_metrics(namespace, context)
                self._store_metrics("disk", disk_metrics)
                
                # ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
                app_metrics = await self._collect_application_metrics(namespace, context)
                self._store_metrics("application", app_metrics)
                
                logger.debug("Periodic metric collection completed")
                
                # 30ì´ˆ ëŒ€ê¸°
                await asyncio.sleep(30)
                
            except Exception as e:
                logger.error(f"Metric collection error: {e}")
                await asyncio.sleep(60)  # ì—ëŸ¬ ì‹œ 1ë¶„ ëŒ€ê¸°
    
    async def _start_alert_monitoring(self, context):
        """ì•Œë¦¼ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        logger = context.logger
        
        # ì£¼ê¸°ì  ì•Œë¦¼ ì²´í¬ íƒœìŠ¤í¬ ì‹œì‘
        asyncio.create_task(self._periodic_alert_check(context))
        
        logger.info("Alert monitoring started")
    
    async def _periodic_alert_check(self, context):
        """ì£¼ê¸°ì  ì•Œë¦¼ ì²´í¬"""
        logger = context.logger
        
        while True:
            try:
                # ê° ì•Œë¦¼ ê·œì¹™ì— ëŒ€í•´ ì²´í¬
                for rule in self.alert_rules:
                    if rule.enabled:
                        await self._check_alert_rule(rule, context)
                
                # í•´ê²°ëœ ì•Œë¦¼ ì²˜ë¦¬
                await self._process_resolved_alerts(context)
                
                logger.debug("Periodic alert check completed")
                
                # 10ì´ˆ ëŒ€ê¸°
                await asyncio.sleep(10)
                
            except Exception as e:
                logger.error(f"Alert check error: {e}")
                await asyncio.sleep(30)
    
    async def _start_predictive_analysis(self, context):
        """ì˜ˆì¸¡ì  ë¶„ì„ ì‹œì‘"""
        logger = context.logger
        
        # ì£¼ê¸°ì  ì˜ˆì¸¡ ë¶„ì„ íƒœìŠ¤í¬ ì‹œì‘
        asyncio.create_task(self._periodic_predictive_analysis(context))
        
        logger.info("Predictive analysis started")
    
    async def _periodic_predictive_analysis(self, context):
        """ì£¼ê¸°ì  ì˜ˆì¸¡ ë¶„ì„"""
        logger = context.logger
        
        while True:
            try:
                # ì„±ëŠ¥ ë¶„ì„ ìˆ˜í–‰
                analysis = await self._perform_performance_analysis(context)
                
                # ìŠ¤ì¼€ì¼ë§ ì˜ˆì¸¡
                scaling_prediction = await self._predict_scaling_needs(context)
                
                # ë¶„ì„ ê²°ê³¼ ì €ì¥
                await self._save_analysis_results(analysis, scaling_prediction)
                
                logger.debug("Predictive analysis completed")
                
                # 5ë¶„ ëŒ€ê¸°
                await asyncio.sleep(300)
                
            except Exception as e:
                logger.error(f"Predictive analysis error: {e}")
                await asyncio.sleep(600)  # ì—ëŸ¬ ì‹œ 10ë¶„ ëŒ€ê¸°
    
    async def _check_alert_rule(self, rule: AlertRule, context):
        """ì•Œë¦¼ ê·œì¹™ ì²´í¬"""
        try:
            # ë©”íŠ¸ë¦­ ê°’ ì¡°íšŒ
            metric_value = await self._get_metric_value(rule.name, context)
            
            # ì„ê³„ê°’ ì²´í¬
            if metric_value > rule.threshold:
                # ìƒˆë¡œìš´ ì•Œë¦¼ ìƒì„±
                alert = Alert(
                    id=f"{rule.name}_{int(datetime.now().timestamp())}",
                    rule_name=rule.name,
                    message=f"{rule.name}: {metric_value} > {rule.threshold}",
                    severity=rule.severity,
                    timestamp=datetime.now(),
                    status="firing",
                    labels={"rule": rule.name, "threshold": str(rule.threshold)}
                )
                
                # ì¤‘ë³µ ì•Œë¦¼ ì²´í¬
                if not self._is_duplicate_alert(alert):
                    self.active_alerts.append(alert)
                    await self._send_alert_notification(alert, context)
                    
        except Exception as e:
            context.logger.error(f"Alert rule check failed for {rule.name}: {e}")
    
    async def _process_resolved_alerts(self, context):
        """í•´ê²°ëœ ì•Œë¦¼ ì²˜ë¦¬"""
        current_time = datetime.now()
        resolved_alerts = []
        
        for alert in self.active_alerts:
            if alert.status == "firing":
                # ì•Œë¦¼ì´ í•´ê²°ë˜ì—ˆëŠ”ì§€ ì²´í¬
                metric_value = await self._get_metric_value(alert.rule_name, context)
                rule = self._get_alert_rule(alert.rule_name)
                
                if rule and metric_value <= rule.threshold:
                    alert.status = "resolved"
                    resolved_alerts.append(alert)
                    await self._send_resolution_notification(alert, context)
        
        # í•´ê²°ëœ ì•Œë¦¼ì„ í™œì„± ì•Œë¦¼ ëª©ë¡ì—ì„œ ì œê±°
        self.active_alerts = [alert for alert in self.active_alerts if alert.status == "firing"]
    
    async def _perform_performance_analysis(self, context) -> PerformanceAnalysis:
        """ì„±ëŠ¥ ë¶„ì„ ìˆ˜í–‰"""
        logger = context.logger
        
        # ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ë¶„ì„
        resource_usage = await self._analyze_resource_usage(context)
        
        # ë³‘ëª© ì§€ì  ë¶„ì„
        bottlenecks = await self._identify_bottlenecks(context)
        
        # ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„±
        recommendations = await self._generate_recommendations(resource_usage, bottlenecks, context)
        
        # í—¬ìŠ¤ ìŠ¤ì½”ì–´ ê³„ì‚°
        health_score = await self._calculate_health_score(resource_usage, context)
        
        analysis = PerformanceAnalysis(
            resource_usage=resource_usage,
            bottlenecks=bottlenecks,
            recommendations=recommendations,
            predicted_scaling_needs={},  # ë³„ë„ ë©”ì„œë“œì—ì„œ ì„¤ì •
            health_score=health_score
        )
        
        logger.info(f"Performance analysis completed. Health score: {health_score}")
        return analysis
    
    async def _predict_scaling_needs(self, context) -> Dict[str, Any]:
        """ìŠ¤ì¼€ì¼ë§ ìš”êµ¬ì‚¬í•­ ì˜ˆì¸¡"""
        logger = context.logger
        
        # CPU ì‚¬ìš©ëŸ‰ íŠ¸ë Œë“œ ë¶„ì„
        cpu_trend = await self._analyze_cpu_trend(context)
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ íŠ¸ë Œë“œ ë¶„ì„
        memory_trend = await self._analyze_memory_trend(context)
        
        # íŠ¸ë˜í”½ íŒ¨í„´ ë¶„ì„
        traffic_pattern = await self._analyze_traffic_pattern(context)
        
        # ì˜ˆì¸¡ ëª¨ë¸ ì ìš©
        scaling_prediction = {
            "cpu_scaling_needed": cpu_trend.get("trend") == "increasing",
            "memory_scaling_needed": memory_trend.get("trend") == "increasing",
            "predicted_cpu_usage_1h": cpu_trend.get("prediction_1h", 0),
            "predicted_memory_usage_1h": memory_trend.get("prediction_1h", 0),
            "recommended_replicas": await self._calculate_recommended_replicas(context),
            "confidence": 0.85
        }
        
        logger.info(f"Scaling prediction: {scaling_prediction}")
        return scaling_prediction
    
    def _store_metrics(self, metric_type: str, metrics: List[MetricData]):
        """ë©”íŠ¸ë¦­ ì €ì¥"""
        if metric_type not in self.metric_history:
            self.metric_history[metric_type] = []
        
        self.metric_history[metric_type].extend(metrics)
        
        # ë©”íŠ¸ë¦­ íˆìŠ¤í† ë¦¬ í¬ê¸° ì œí•œ (ìµœê·¼ 1000ê°œë§Œ ìœ ì§€)
        if len(self.metric_history[metric_type]) > 1000:
            self.metric_history[metric_type] = self.metric_history[metric_type][-1000:]
    
    def _is_duplicate_alert(self, alert: Alert) -> bool:
        """ì¤‘ë³µ ì•Œë¦¼ ì²´í¬"""
        for active_alert in self.active_alerts:
            if (active_alert.rule_name == alert.rule_name and 
                active_alert.status == "firing"):
                return True
        return False
    
    def _get_alert_rule(self, rule_name: str) -> Optional[AlertRule]:
        """ì•Œë¦¼ ê·œì¹™ ì¡°íšŒ"""
        for rule in self.alert_rules:
            if rule.name == rule_name:
                return rule
        return None
    
    async def _save_analysis_results(self, analysis: PerformanceAnalysis, scaling_prediction: Dict[str, Any]):
        """ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = os.path.join(self.output_dir, f"performance_analysis_{timestamp}.json")
        
        report_data = {
            "timestamp": timestamp,
            "performance_analysis": asdict(analysis),
            "scaling_prediction": scaling_prediction,
            "active_alerts": [asdict(alert) for alert in self.active_alerts]
        }
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)
        
        print(f"Performance analysis report saved to: {report_file}")
    
    # ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë©”ì„œë“œë“¤ (ì‹œë®¬ë ˆì´ì…˜)
    async def _get_cluster_health(self, context) -> Dict[str, Any]:
        """í´ëŸ¬ìŠ¤í„° í—¬ìŠ¤ ì¡°íšŒ"""
        return {"status": "healthy", "nodes": 5, "pods": 150}
    
    async def _get_node_status(self, context) -> List[Dict[str, Any]]:
        """ë…¸ë“œ ìƒíƒœ ì¡°íšŒ"""
        return [
            {"name": "node-1", "status": "Ready", "cpu": "45%", "memory": "60%"},
            {"name": "node-2", "status": "Ready", "cpu": "52%", "memory": "65%"},
            {"name": "node-3", "status": "Ready", "cpu": "38%", "memory": "55%"}
        ]
    
    async def _get_namespace_resources(self, namespace: str, context) -> Dict[str, Any]:
        """ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë¦¬ì†ŒìŠ¤ ì¡°íšŒ"""
        return {
            "pods": 25,
            "services": 8,
            "deployments": 12,
            "configmaps": 15,
            "secrets": 10
        }
    
    async def _collect_initial_metrics(self, namespace: str, context) -> List[MetricData]:
        """ì´ˆê¸° ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        return [
            MetricData("cluster_cpu_usage", 45.2, "percent", datetime.now(), {"namespace": namespace}),
            MetricData("cluster_memory_usage", 62.8, "percent", datetime.now(), {"namespace": namespace}),
            MetricData("pod_count", 25, "count", datetime.now(), {"namespace": namespace})
        ]
    
    async def _collect_cpu_metrics(self, namespace: str, context) -> List[MetricData]:
        """CPU ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        return [
            MetricData("cpu_usage", 45.2, "percent", datetime.now(), {"namespace": namespace}),
            MetricData("cpu_requests", 80.5, "percent", datetime.now(), {"namespace": namespace}),
            MetricData("cpu_limits", 65.3, "percent", datetime.now(), {"namespace": namespace})
        ]
    
    async def _collect_memory_metrics(self, namespace: str, context) -> List[MetricData]:
        """ë©”ëª¨ë¦¬ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        return [
            MetricData("memory_usage", 62.8, "percent", datetime.now(), {"namespace": namespace}),
            MetricData("memory_requests", 85.2, "percent", datetime.now(), {"namespace": namespace}),
            MetricData("memory_limits", 70.1, "percent", datetime.now(), {"namespace": namespace})
        ]
    
    async def _collect_network_metrics(self, namespace: str, context) -> List[MetricData]:
        """ë„¤íŠ¸ì›Œí¬ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        return [
            MetricData("network_rx_bytes", 1024.5, "bytes", datetime.now(), {"namespace": namespace}),
            MetricData("network_tx_bytes", 2048.3, "bytes", datetime.now(), {"namespace": namespace}),
            MetricData("network_errors", 0.1, "count", datetime.now(), {"namespace": namespace})
        ]
    
    async def _collect_disk_metrics(self, namespace: str, context) -> List[MetricData]:
        """ë””ìŠ¤í¬ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        return [
            MetricData("disk_usage", 75.2, "percent", datetime.now(), {"namespace": namespace}),
            MetricData("disk_read_bytes", 512.8, "bytes", datetime.now(), {"namespace": namespace}),
            MetricData("disk_write_bytes", 1024.6, "bytes", datetime.now(), {"namespace": namespace})
        ]
    
    async def _collect_application_metrics(self, namespace: str, context) -> List[MetricData]:
        """ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        return [
            MetricData("http_requests_total", 1250, "count", datetime.now(), {"namespace": namespace}),
            MetricData("http_request_duration", 150.5, "milliseconds", datetime.now(), {"namespace": namespace}),
            MetricData("error_rate", 2.1, "percent", datetime.now(), {"namespace": namespace})
        ]
    
    async def _get_metric_value(self, metric_name: str, context) -> float:
        """ë©”íŠ¸ë¦­ ê°’ ì¡°íšŒ"""
        # ì‹¤ì œë¡œëŠ” Prometheus API í˜¸ì¶œ
        metric_values = {
            "high_cpu_usage": 45.2,
            "high_memory_usage": 62.8,
            "pod_restart_frequency": 2.0,
            "high_error_rate": 2.1,
            "disk_usage_high": 75.2
        }
        return metric_values.get(metric_name, 0.0)
    
    async def _send_alert_notification(self, alert: Alert, context):
        """ì•Œë¦¼ ì „ì†¡"""
        logger = context.logger
        logger.warning(f"ALERT: {alert.message} (Severity: {alert.severity})")
        
        # ì‹¤ì œë¡œëŠ” Slack, ì´ë©”ì¼, PagerDuty ë“±ìœ¼ë¡œ ì „ì†¡
        print(f"ğŸš¨ ALERT: {alert.message}")
    
    async def _send_resolution_notification(self, alert: Alert, context):
        """í•´ê²° ì•Œë¦¼ ì „ì†¡"""
        logger = context.logger
        logger.info(f"RESOLVED: {alert.rule_name}")
        
        # ì‹¤ì œë¡œëŠ” Slack, ì´ë©”ì¼ ë“±ìœ¼ë¡œ ì „ì†¡
        print(f"âœ… RESOLVED: {alert.rule_name}")
    
    async def _analyze_resource_usage(self, context) -> Dict[str, float]:
        """ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ë¶„ì„"""
        return {
            "cpu_usage": 45.2,
            "memory_usage": 62.8,
            "disk_usage": 75.2,
            "network_usage": 35.6
        }
    
    async def _identify_bottlenecks(self, context) -> List[str]:
        """ë³‘ëª© ì§€ì  ì‹ë³„"""
        bottlenecks = []
        
        # CPU ë³‘ëª© ì²´í¬
        if await self._get_metric_value("high_cpu_usage", context) > 80:
            bottlenecks.append("High CPU usage detected")
        
        # ë©”ëª¨ë¦¬ ë³‘ëª© ì²´í¬
        if await self._get_metric_value("high_memory_usage", context) > 85:
            bottlenecks.append("High memory usage detected")
        
        # ë””ìŠ¤í¬ ë³‘ëª© ì²´í¬
        if await self._get_metric_value("disk_usage_high", context) > 90:
            bottlenecks.append("High disk usage detected")
        
        return bottlenecks
    
    async def _generate_recommendations(self, resource_usage: Dict[str, float], bottlenecks: List[str], context) -> List[str]:
        """ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        if resource_usage["cpu_usage"] > 70:
            recommendations.append("Consider scaling up CPU resources or adding more replicas")
        
        if resource_usage["memory_usage"] > 75:
            recommendations.append("Consider increasing memory limits or optimizing memory usage")
        
        if resource_usage["disk_usage"] > 80:
            recommendations.append("Consider cleaning up unused data or expanding storage")
        
        if "High CPU usage detected" in bottlenecks:
            recommendations.append("Implement horizontal pod autoscaling for CPU-based scaling")
        
        return recommendations
    
    async def _calculate_health_score(self, resource_usage: Dict[str, float], context) -> float:
        """í—¬ìŠ¤ ìŠ¤ì½”ì–´ ê³„ì‚°"""
        # ê° ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥ ì„ ê¸°ë°˜ìœ¼ë¡œ ì ìˆ˜ ê³„ì‚°
        cpu_score = max(0, 100 - resource_usage["cpu_usage"])
        memory_score = max(0, 100 - resource_usage["memory_usage"])
        disk_score = max(0, 100 - resource_usage["disk_usage"])
        
        # ê°€ì¤‘ í‰ê·  ê³„ì‚°
        health_score = (cpu_score * 0.4 + memory_score * 0.4 + disk_score * 0.2)
        
        return round(health_score, 2)
    
    async def _analyze_cpu_trend(self, context) -> Dict[str, Any]:
        """CPU íŠ¸ë Œë“œ ë¶„ì„"""
        return {
            "trend": "stable",
            "prediction_1h": 48.5,
            "prediction_6h": 52.3,
            "confidence": 0.85
        }
    
    async def _analyze_memory_trend(self, context) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ íŠ¸ë Œë“œ ë¶„ì„"""
        return {
            "trend": "increasing",
            "prediction_1h": 68.2,
            "prediction_6h": 75.8,
            "confidence": 0.78
        }
    
    async def _analyze_traffic_pattern(self, context) -> Dict[str, Any]:
        """íŠ¸ë˜í”½ íŒ¨í„´ ë¶„ì„"""
        return {
            "pattern": "normal",
            "peak_hours": ["09:00", "14:00", "18:00"],
            "traffic_spike": False,
            "anomaly_detected": False
        }
    
    async def _calculate_recommended_replicas(self, context) -> int:
        """ê¶Œì¥ ë ˆí”Œë¦¬ì¹´ ìˆ˜ ê³„ì‚°"""
        current_cpu = await self._get_metric_value("high_cpu_usage", context)
        current_memory = await self._get_metric_value("high_memory_usage", context)
        
        # ê°„ë‹¨í•œ ë¡œì§: ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥ ì´ ë†’ìœ¼ë©´ ë ˆí”Œë¦¬ì¹´ ì¦ê°€
        if current_cpu > 80 or current_memory > 85:
            return 5
        elif current_cpu > 60 or current_memory > 70:
            return 4
        else:
            return 3
    
    async def get_active_alerts(self) -> List[Alert]:
        """í™œì„± ì•Œë¦¼ ì¡°íšŒ"""
        return self.active_alerts
    
    async def get_metric_history(self, metric_type: str) -> List[MetricData]:
        """ë©”íŠ¸ë¦­ íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
        return self.metric_history.get(metric_type, [])
    
    async def add_alert_rule(self, rule: AlertRule):
        """ì•Œë¦¼ ê·œì¹™ ì¶”ê°€"""
        self.alert_rules.append(rule)
    
    async def remove_alert_rule(self, rule_name: str):
        """ì•Œë¦¼ ê·œì¹™ ì œê±°"""
        self.alert_rules = [rule for rule in self.alert_rules if rule.name != rule_name]

# ì‚¬ìš© ì˜ˆì‹œ
async def main():
    """ì‚¬ìš© ì˜ˆì‹œ"""
    agent = MonitoringAgent()
    
    # ëª¨ë‹ˆí„°ë§ ì‹œì‘
    await agent.start_monitoring("default")
    
    # 30ì´ˆ ë™ì•ˆ ëª¨ë‹ˆí„°ë§ ì‹¤í–‰
    await asyncio.sleep(30)
    
    # í™œì„± ì•Œë¦¼ ì¡°íšŒ
    alerts = await agent.get_active_alerts()
    print(f"Active alerts: {len(alerts)}")
    
    # ë©”íŠ¸ë¦­ íˆìŠ¤í† ë¦¬ ì¡°íšŒ
    cpu_metrics = await agent.get_metric_history("cpu")
    print(f"CPU metrics collected: {len(cpu_metrics)}")

if __name__ == "__main__":
    asyncio.run(main()) 