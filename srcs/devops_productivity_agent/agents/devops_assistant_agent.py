#!/usr/bin/env python3
"""
DevOps Productivity MCP Agent
================================
Production-level DevOps assistant with MCP server integrations:
- AWS management via official MCP servers
- GitHub operations via MCP
- Prometheus monitoring via MCP
- Kubernetes cluster management
- Multi-cloud support (GCP, Azure)
"""

import asyncio
import os
import json
from datetime import datetime
from typing import Dict, List, Any, Optional

# MCP Agent imports
from srcs.core.agent.base import BaseAgent
from mcp_agent.workflows.orchestrator.orchestrator import Orchestrator
from mcp_agent.workflows.llm.google_augmented_llm import GoogleAugmentedLLM
from mcp_agent.workflows.llm.augmented_llm import RequestParams


class DevOpsProductivityAgent(BaseAgent):
    """Production DevOps Assistant with MCP server integrations"""
    
    def __init__(self, output_dir: str = "devops_reports"):
        super().__init__(
            name="devops_productivity_agent",
            instruction="ì „ë¬¸ DevOps ì—”ì§€ë‹ˆì–´. AWS ë¦¬ì†ŒìŠ¤ ê´€ë¦¬, GitHub CI/CD, Kubernetes, ì¸í”„ë¼ ëª¨ë‹ˆí„°ë§ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. MCP ì„œë²„ë¥¼ í†µí•´ ë‹¤ì–‘í•œ í´ë¼ìš°ë“œ ë¦¬ì†ŒìŠ¤ì™€ ë„êµ¬ë“¤ì„ ìë™ìœ¼ë¡œ ì¡°ì •í•©ë‹ˆë‹¤.",
            server_names=["aws-kb", "github", "prometheus", "kubernetes", "gcp-admin", "azure-admin"]
        )
        
        self.output_dir = output_dir
        os.makedirs(self.output_dir, exist_ok=True)
        
        # Initialize Google LLM with latest Gemini model
        self.model_name = "gemini-2.5-flash-latest"
        self.llm = GoogleAugmentedLLM(
            model_name=self.model_name,
            api_key=os.getenv("GOOGLE_API_KEY", "")
        )
        
        # Define agent capabilities
        self.capabilities = {
            "aws_management": "AWS EC2, S3, Lambda, CloudFormation ê´€ë¦¬",
            "github_operations": "GitHub ë¦¬í¬ì§€í† ë¦¬, PR, ì´ìŠˆ, CI/CD íŒŒì´í”„ë¼ì¸ ê´€ë¦¬",
            "kubernetes_ops": "Kubernetes í´ëŸ¬ìŠ¤í„° ë° ì›Œí¬ë¡œë“œ ê´€ë¦¬",
            "infrastructure_monitoring": "Prometheus ë©”íŠ¸ë¦­ ê¸°ë°˜ ì¸í”„ë¼ ëª¨ë‹ˆí„°ë§",
            "multi_cloud_coordination": "AWS, GCP, Azure ê°„ ë¦¬ì†ŒìŠ¤ ì¡°ì •"
        }
    
    async def run_workflow(self, request: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        Main workflow using Orchestrator for automatic tool selection and execution.
        The LLM will automatically choose appropriate MCP tools based on the request.
        """
        try:
            self.logger.info(f"Processing DevOps request: {request}")
            
            # Create orchestrator for automatic tool selection
            orchestrator = self.get_orchestrator([])
            
            # Prepare context for the orchestrator
            workflow_context = {
                "request": request,
                "capabilities": self.capabilities,
                "timestamp": datetime.now().isoformat(),
                **(context or {})
            }
            
            # Let the orchestrator handle the request using available MCP tools
            result = await orchestrator.execute(request, workflow_context)
            
            # Save result to output directory
            output_file = os.path.join(
                self.output_dir, 
                f"devops_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            )
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            
            self.logger.info(f"DevOps workflow completed. Result saved to: {output_file}")
            
            return {
                "status": "success",
                "request": request,
                "result": result,
                "output_file": output_file,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"DevOps workflow failed: {str(e)}")
            return {
                "status": "error",
                "request": request,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }


async def main():
    """Test the DevOps assistant with MCP integration"""
    agent = DevOpsProductivityAgent()
    
    # Test with sample requests
    test_requests = [
        "AWS EC2 ì¸ìŠ¤í„´ìŠ¤ ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”",
        "GitHub microsoft ì¡°ì§ì˜ ë¦¬í¬ì§€í† ë¦¬ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”",
        "Kubernetes í´ëŸ¬ìŠ¤í„°ì˜ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥ ì„ ì¡°íšŒí•´ì£¼ì„¸ìš”",
        "Prometheus ë©”íŠ¸ë¦­ì„ í†µí•´ ì¸í”„ë¼ ìƒíƒœë¥¼ ëª¨ë‹ˆí„°ë§í•´ì£¼ì„¸ìš”"
    ]
    
    for request in test_requests:
        print(f"\nğŸ”„ Processing: {request}")
        try:
            result = await agent.run_workflow(request)
            print(f"âœ… Status: {result['status']}")
            if result['status'] == 'success':
                print(f"ğŸ“ Output saved to: {result['output_file']}")
            else:
                print(f"âŒ Error: {result.get('error', 'Unknown error')}")
        except Exception as e:
            print(f"âŒ Exception: {str(e)}")


if __name__ == "__main__":
    asyncio.run(main()) 