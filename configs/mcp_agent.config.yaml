$schema: configs/mcp-agent.config.schema.json

execution_engine: asyncio
logger:
  transports: [console, file]
  level: info
  progress_display: true
  path_settings:
    path_pattern: "logs/mcp-agent-{unique_id}.jsonl"
    unique_id: "timestamp" # Options: "timestamp" or "session_id"
    timestamp_format: "%Y%m%d_%H%M%S"

mcp:
  servers:
    fetch:
      command: "uvx"
      args: ["mcp-server-fetch"]
    g-search: # Google Search MCP server
      command: "npx"
      args: ["-y", "g-search-mcp"]
    filesystem:
      command: "npx"
      args: ["-y", "@modelcontextprotocol/server-filesystem", "."]
    urban-hive: # Urban Hive data provider MCP server
      command: "python"
      args: ["-m", "uvicorn", "srcs.urban_hive.providers.urban_hive_mcp_server:app", "--port", "8002"]
      env:
        URBAN_HIVE_API_BASE: "http://127.0.0.1:8001"
    pubmed:
      command: "uvx"
      args: ["-y", "pubmedmcp@0.1.3"]
    puppeteer:
      command: "npx"
      args: [
        "-y", 
        "@modelcontextprotocol/server-puppeteer"
      ]
    slack:
      command: "npx"
      args: ["-y", "@modelcontextprotocol/server-slack"]
      # consider defining sensitive values in a separate mcp_agent.secrets.yaml file
      # env:
      #   SLACK_BOT_TOKEN: "xoxb-your-bot-token"
      #   SLACK_TEAM_ID": "T01234567"
    brave:
      command: "npx"
      args: ["-y", "@modelcontextprotocol/server-brave-search"]

    interpreter:
      command: "docker"
      args:
        [
          "run",
          "-i",
          "--rm",
          "--pull=always",
          "-v",
          "./agent_folder:/mnt/data/",
          "ghcr.io/evalstate/mcp-py-repl:latest",
        ]
      roots:
        - uri: "file://./agent_folder/"
          name: "agent_folder"
          server_uri_alias: "file:///mnt/data/"
openai:
  # Secrets (API keys, etc.) are stored in an mcp_agent.secrets.yaml file which can be gitignored
  default_model: "gpt-4o-mini" #Temporarily leave this for existing hardcoded calls

google:
  default_model: "gemini-2.0-flash-lite-001"

llm:
  default_provider: "google"