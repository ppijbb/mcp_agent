"""
GitHub PR Review Bot - Ultra Compact Version

ì´ ëª¨ë“ˆì€ GitHub PR ë¦¬ë·° ë´‡ì˜ ë©”ì¸ ì§„ì…ì ì…ë‹ˆë‹¤.
ì›¹í›… ì„œë²„ì™€ ë´‡ ë¡œì§ì´ ëª¨ë‘ í†µí•©ëœ ultra compactí•œ êµ¬ì¡°ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
"""

import os
import sys
import asyncio
import logging
import hmac
import hashlib
import json
import subprocess
from typing import Dict, List, Any, Optional
from datetime import datetime
from dataclasses import dataclass
from dotenv import load_dotenv
from fastapi import FastAPI, Request, HTTPException, BackgroundTasks
from fastapi.responses import JSONResponse
import uvicorn

from .core.config import config
from .core.ai import gemini_service, MCPIntegrationManager
from .core.api import GitHubClient

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="GitHub PR Review Bot - Ultra Compact",
    description="GitHub PR ë¦¬ë·° ìë™í™” ë´‡ (ultra compactí•œ êµ¬ì¡°)",
    version="5.0.0"
)

# ë°ì´í„° ëª¨ë¸
@dataclass
class PRInfo:
    """PR ì •ë³´ - ë‹¨ì¼ ë°ì´í„° ëª¨ë¸"""
    pr_number: int
    repo_full_name: str
    pr_title: str
    pr_body: str
    pr_diff: str
    language: str
    files: List[str]
    author: str
    stats: Dict[str, int]
    head_ref: str
    base_ref: str
    action: str
    detailed_changes: Optional[Dict[str, Any]] = None
    line_by_line_changes: Optional[Dict[str, Any]] = None

# ë´‡ ì¸ìŠ¤í„´ìŠ¤
github_client = None
gemini_service_instance = None
mcp_manager = None

def validate_environment():
    """í™˜ê²½ ë³€ìˆ˜ ê²€ì¦"""
    required_vars = [
        'GITHUB_TOKEN'
    ]
    
    missing_vars = []
    for var in required_vars:
        if not getattr(config, var.lower(), None):
            missing_vars.append(var)
    
    if missing_vars:
        logger.error(f"í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {', '.join(missing_vars)}")
        sys.exit(1)
    
    logger.info("í™˜ê²½ ë³€ìˆ˜ ê²€ì¦ ì™„ë£Œ")

@app.on_event("startup")
async def startup_event():
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ ì´ˆê¸°í™”"""
    global github_client, gemini_service_instance, mcp_manager
    try:
        github_client = GitHubClient()
        gemini_service_instance = gemini_service
        mcp_manager = MCPIntegrationManager()
        logger.info("GitHub PR Review Bot ì‹œì‘ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"ë´‡ ì‹œì‘ ì‹¤íŒ¨: {e}")
        if config.github.fail_fast_on_error:
            sys.exit(1)
        raise HTTPException(status_code=500, detail="ë´‡ ì‹œì‘ ì‹¤íŒ¨")

@app.on_event("shutdown")
async def shutdown_event():
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ ì‹œ ì •ë¦¬"""
    logger.info("GitHub PR Review Bot ì¢…ë£Œ")

@app.get("/")
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "message": "GitHub PR Review Bot - Ultra Compact",
        "version": "5.0.0",
        "status": "running"
    }

# ë´‡ ë¡œì§ í•¨ìˆ˜ë“¤
def verify_signature(payload: bytes, signature: str) -> bool:
    """ì›¹í›… ì„œëª… ê²€ì¦"""
    if not config.github.webhook_secret:
        logger.error("ì›¹í›… ì‹œí¬ë¦¿ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        if config.github.fail_fast_on_error:
            sys.exit(1)
        raise ValueError("ì›¹í›… ì‹œí¬ë¦¿ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    
    try:
        expected_signature = hmac.new(
            config.github.webhook_secret.encode('utf-8'),
            payload,
            hashlib.sha256
        ).hexdigest()
        
        expected_signature = f"sha256={expected_signature}"
        is_valid = hmac.compare_digest(signature, expected_signature)
        
        if is_valid:
            logger.info("ì›¹í›… ì„œëª… ê²€ì¦ ì„±ê³µ")
        else:
            logger.warning("ì›¹í›… ì„œëª… ê²€ì¦ ì‹¤íŒ¨")
        
        return is_valid
        
    except Exception as e:
        logger.error(f"ì›¹í›… ì„œëª… ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
        if config.github.fail_fast_on_error:
            sys.exit(1)
        raise ValueError(f"ì›¹í›… ì„œëª… ê²€ì¦ ì‹¤íŒ¨: {e}")

def parse_payload(payload: bytes) -> Dict[str, Any]:
    """ì›¹í›… í˜ì´ë¡œë“œ íŒŒì‹±"""
    try:
        data = json.loads(payload.decode('utf-8'))
        logger.info(f"ì›¹í›… í˜ì´ë¡œë“œ íŒŒì‹± ì„±ê³µ: {data.get('action', 'unknown')} ì´ë²¤íŠ¸")
        return data
    except json.JSONDecodeError as e:
        logger.error(f"ì›¹í›… í˜ì´ë¡œë“œ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        if config.github.fail_fast_on_error:
            sys.exit(1)
        raise ValueError(f"ì›¹í›… í˜ì´ë¡œë“œ íŒŒì‹± ì‹¤íŒ¨: {e}")
    except Exception as e:
        logger.error(f"ì›¹í›… í˜ì´ë¡œë“œ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
        if config.github.fail_fast_on_error:
            sys.exit(1)
        raise ValueError(f"ì›¹í›… í˜ì´ë¡œë“œ íŒŒì‹± ì‹¤íŒ¨: {e}")

def extract_pr_info(event_data: Dict[str, Any]) -> PRInfo:
    """PR ì •ë³´ ì¶”ì¶œ - í–¥ìƒëœ ë³€ê²½ì‚¬í•­ ì¶”ì """
    pr = event_data.get('pull_request', {})
    repository = event_data.get('repository', {})
    
    if not pr or not repository:
        raise ValueError("PR ë˜ëŠ” ì €ì¥ì†Œ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # PR íŒŒì¼ ì •ë³´ ì¡°íšŒ (í–¥ìƒëœ ë²„ì „)
    pr_files = github_client.get_pr_files(repository['full_name'], pr['number'])
    pr_diff = github_client.get_pr_diff(repository['full_name'], pr['number'])
    
    # ìƒì„¸í•œ ë³€ê²½ì‚¬í•­ ë¶„ì„
    detailed_changes = github_client.get_detailed_changes(repository['full_name'], pr['number'])
    
    # ë¼ì¸ë³„ ë³€ê²½ì‚¬í•­ ë¶„ì„
    line_by_line_changes = github_client.get_line_by_line_changes(repository['full_name'], pr['number'])
    
    # ì–¸ì–´ ê°ì§€
    language = detect_language(pr_files)
    
    return PRInfo(
        pr_number=pr['number'],
        repo_full_name=repository['full_name'],
        pr_title=pr.get('title', ''),
        pr_body=pr.get('body', ''),
        pr_diff=pr_diff,
        language=language,
        files=[f['filename'] for f in pr_files],  # ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë³€ê²½
        author=pr.get('user', {}).get('login', 'unknown'),
        stats={
            'additions': pr.get('additions', 0),
            'deletions': pr.get('deletions', 0),
            'changed_files': pr.get('changed_files', 0)
        },
        head_ref=pr.get('head', {}).get('ref', ''),
        base_ref=pr.get('base', {}).get('ref', ''),
        action=event_data.get('action', ''),
        detailed_changes=detailed_changes,  # ìƒì„¸ ë³€ê²½ì‚¬í•­ ì¶”ê°€
        line_by_line_changes=line_by_line_changes  # ë¼ì¸ë³„ ë³€ê²½ì‚¬í•­ ì¶”ê°€
    )

def detect_language(pr_files: List[Any]) -> str:
    """í”„ë¡œê·¸ë˜ë° ì–¸ì–´ ê°ì§€"""
    if not pr_files:
        return "unknown"
    
    extensions = {}
    for file in pr_files:
        # ë”•ì…”ë„ˆë¦¬ í˜•íƒœì™€ ê°ì²´ í˜•íƒœ ëª¨ë‘ ì§€ì›
        if isinstance(file, dict):
            filename = file.get('filename', '')
        else:
            filename = getattr(file, 'filename', '')
            
        if '.' in filename:
            ext = filename.split('.')[-1].lower()
            extensions[ext] = extensions.get(ext, 0) + 1
    
    if extensions:
        most_common_ext = max(extensions, key=extensions.get)
        language_map = {
            'py': 'python', 'js': 'javascript', 'ts': 'typescript',
            'java': 'java', 'cpp': 'cpp', 'c': 'c', 'cs': 'csharp',
            'go': 'go', 'rs': 'rust', 'php': 'php', 'rb': 'ruby',
            'swift': 'swift', 'kt': 'kotlin', 'scala': 'scala',
            'r': 'r', 'm': 'matlab', 'sh': 'bash', 'sql': 'sql',
            'html': 'html', 'css': 'css', 'xml': 'xml', 'json': 'json',
            'yaml': 'yaml', 'yml': 'yaml', 'md': 'markdown'
        }
        return language_map.get(most_common_ext, most_common_ext)
    
    return "unknown"

def should_review_pr(pr_info: PRInfo) -> bool:
    """PR ë¦¬ë·° ì—¬ë¶€ ê²°ì •"""
    if not config.github.auto_review_enabled:
        return False
    
    # Draft PR ìŠ¤í‚µ
    if config.github.skip_draft_prs and pr_info.action == "opened":
        # Draft PR í™•ì¸ì„ ìœ„í•´ PR ê°ì²´ ì¡°íšŒ
        pr = github_client.get_pull_request(pr_info.repo_full_name, pr_info.pr_number)
        if pr.draft:
            logger.info("ë“œë˜í”„íŠ¸ PRì´ë¯€ë¡œ ë¦¬ë·° ìŠ¤í‚µ")
            return False
    
    # PR í¬ê¸° ì²´í¬
    total_changes = pr_info.stats['additions'] + pr_info.stats['deletions']
    if total_changes < config.github.min_pr_size_threshold:
        logger.info(f"PR í¬ê¸°ê°€ ë„ˆë¬´ ì‘ì•„ì„œ ë¦¬ë·° ìŠ¤í‚µ: {total_changes} < {config.github.min_pr_size_threshold}")
        return False
    
    if total_changes > config.github.max_pr_size_threshold:
        logger.info(f"PR í¬ê¸°ê°€ ë„ˆë¬´ ì»¤ì„œ ë¦¬ë·° ìŠ¤í‚µ: {total_changes} > {config.github.max_pr_size_threshold}")
        return False
    
    if not config.github.require_explicit_review_request:
        return True
    
    # ëª…ì‹œì  ë¦¬ë·° ìš”ì²­ í‚¤ì›Œë“œ í™•ì¸
    review_keywords = ["@review-bot", "[REVIEW]", "[ë¦¬ë·°ìš”ì²­]"]
    return any(keyword in pr_info.pr_body for keyword in review_keywords)

def generate_review(pr_info: PRInfo) -> str:
    """ë¦¬ë·° ìƒì„± - í–¥ìƒëœ ë³€ê²½ì‚¬í•­ ì¶”ì  ê¸°ë°˜"""
    try:
        # MCP ì„œë¹„ìŠ¤ë¥¼ í†µí•œ í–¥ìƒëœ ì½”ë“œ ë¶„ì„
        mcp_result = mcp_manager.analyze_code(
            code=pr_info.pr_diff,
            language=pr_info.language,
            context={
                "pr_number": pr_info.pr_number,
                "pr_title": pr_info.pr_title,
                "pr_body": pr_info.pr_body,
                "author": pr_info.author,
                "files": pr_info.files,
                "repo_full_name": pr_info.repo_full_name,
                "file_path": f"{pr_info.repo_full_name}#{pr_info.pr_number}",
                "detailed_changes": pr_info.detailed_changes,
                "line_by_line_changes": pr_info.line_by_line_changes
            }
        )
        
        # ë¦¬ë·° í¬ë§·íŒ…
        review_parts = []
        
        # í—¤ë”
        review_parts.append(f"## ğŸ” PR #{pr_info.pr_number} ë¦¬ë·° (í–¥ìƒëœ ë³€ê²½ì‚¬í•­ ì¶”ì )")
        review_parts.append("")
        
        # ê¸°ë³¸ ì •ë³´
        review_parts.append("### ğŸ“‹ ê¸°ë³¸ ì •ë³´")
        review_parts.append(f"- **ì €ì¥ì†Œ**: {pr_info.repo_full_name}")
        review_parts.append(f"- **ë¸Œëœì¹˜**: {pr_info.head_ref} â†’ {pr_info.base_ref}")
        review_parts.append(f"- **ì–¸ì–´**: {pr_info.language}")
        review_parts.append(f"- **ë³€ê²½ëœ íŒŒì¼**: {len(pr_info.files)}ê°œ")
        review_parts.append(f"- **ë³€ê²½ í†µê³„**: +{pr_info.stats['additions']}/-{pr_info.stats['deletions']}")
        review_parts.append("")
        
        # ìƒì„¸ ë³€ê²½ì‚¬í•­ ë¶„ì„ (ìƒˆë¡œìš´ ê¸°ëŠ¥)
        if pr_info.detailed_changes:
            review_parts.append("### ğŸ” ìƒì„¸ ë³€ê²½ì‚¬í•­ ë¶„ì„")
            change_summary = pr_info.detailed_changes.get('summary', {})
            review_parts.append(f"- **ì´ íŒŒì¼ ìˆ˜**: {change_summary.get('total_files', 0)}ê°œ")
            review_parts.append(f"- **ì´ ë³€ê²½ ë¼ì¸**: {change_summary.get('total_changes', 0)}ì¤„")
            review_parts.append(f"- **ì»¤ë°‹ ìˆ˜**: {change_summary.get('commits_count', 0)}ê°œ")
            review_parts.append("")
            
            # ë³€ê²½ ì¹´í…Œê³ ë¦¬ ë¶„ì„
            categories = pr_info.detailed_changes.get('change_categories', {})
            if categories.get('new_files'):
                review_parts.append("#### ğŸ“ ìƒˆë¡œ ì¶”ê°€ëœ íŒŒì¼")
                for file_info in categories['new_files']:
                    review_parts.append(f"- `{file_info['filename']}` ({file_info['changes']}ì¤„)")
                review_parts.append("")
            
            if categories.get('deleted_files'):
                review_parts.append("#### ğŸ—‘ï¸ ì‚­ì œëœ íŒŒì¼")
                for file_info in categories['deleted_files']:
                    review_parts.append(f"- `{file_info['filename']}` ({file_info['changes']}ì¤„)")
                review_parts.append("")
            
            if categories.get('critical_files'):
                review_parts.append("#### âš ï¸ ì¤‘ìš” íŒŒì¼ ë³€ê²½")
                for file_info in categories['critical_files']:
                    review_parts.append(f"- `{file_info['filename']}` ({file_info['change_type']}, {file_info['changes']}ì¤„)")
                review_parts.append("")
            
            # ì˜í–¥ë„ ë¶„ì„
            impact_analysis = pr_info.detailed_changes.get('impact_analysis', {})
            if impact_analysis.get('api_changes'):
                review_parts.append("#### ğŸ”Œ API ë³€ê²½ì‚¬í•­")
                for change in impact_analysis['api_changes']:
                    review_parts.append(f"- `{change['file']}`: {change['type']}")
                review_parts.append("")
            
            if impact_analysis.get('breaking_changes'):
                review_parts.append("#### ğŸ’¥ ì ì¬ì  Breaking Changes")
                for change in impact_analysis['breaking_changes']:
                    review_parts.append(f"- `{change['file']}`: {change['type']}")
                review_parts.append("")
            
            if impact_analysis.get('dependency_changes'):
                review_parts.append("#### ğŸ“¦ ì˜ì¡´ì„± ë³€ê²½ì‚¬í•­")
                for change in impact_analysis['dependency_changes']:
                    review_parts.append(f"- `{change['file']}`: {change['type']}")
                review_parts.append("")
            
            # ì˜ë¯¸ì  ë³€ê²½ì‚¬í•­ ë¶„ì„
            semantic_changes = pr_info.detailed_changes.get('semantic_changes', {})
            if any(semantic_changes.values()):
                review_parts.append("#### ğŸ¯ ì˜ë¯¸ì  ë³€ê²½ì‚¬í•­")
                for category, changes in semantic_changes.items():
                    if changes:
                        category_name = {
                            'feature_additions': 'ìƒˆ ê¸°ëŠ¥ ì¶”ê°€',
                            'bug_fixes': 'ë²„ê·¸ ìˆ˜ì •',
                            'refactoring': 'ë¦¬íŒ©í† ë§',
                            'performance_improvements': 'ì„±ëŠ¥ ê°œì„ ',
                            'security_updates': 'ë³´ì•ˆ ì—…ë°ì´íŠ¸'
                        }.get(category, category)
                        review_parts.append(f"- **{category_name}**: {len(changes)}ê°œ íŒŒì¼")
                review_parts.append("")
        
        # ë¼ì¸ë³„ ë³€ê²½ì‚¬í•­ ë¶„ì„ (ìƒˆë¡œìš´ ê¸°ëŠ¥)
        if pr_info.line_by_line_changes:
            review_parts.append("### ğŸ“ ë¼ì¸ë³„ ë³€ê²½ì‚¬í•­ ë¶„ì„")
            line_summary = pr_info.line_by_line_changes.get('summary', {})
            review_parts.append(f"- **ë¶„ì„ëœ íŒŒì¼**: {line_summary.get('total_files_analyzed', 0)}ê°œ")
            review_parts.append(f"- **ì¶”ê°€ëœ ë¼ì¸**: {line_summary.get('total_lines_added', 0)}ì¤„")
            review_parts.append(f"- **ì‚­ì œëœ ë¼ì¸**: {line_summary.get('total_lines_removed', 0)}ì¤„")
            review_parts.append("")
            
            # ì¤‘ìš” ë³€ê²½ì‚¬í•­ í‘œì‹œ
            critical_changes = []
            function_changes = []
            import_changes = []
            
            for file_change in pr_info.line_by_line_changes.get('file_changes', []):
                critical_changes.extend(file_change.get('critical_changes', []))
                function_changes.extend(file_change.get('function_changes', []))
                import_changes.extend(file_change.get('import_changes', []))
            
            if critical_changes:
                review_parts.append("#### âš ï¸ ì¤‘ìš” ë³€ê²½ì‚¬í•­ ê°ì§€")
                for change in critical_changes[:5]:  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
                    review_parts.append(f"- `{change['line'][:50]}...` ({change['type']})")
                review_parts.append("")
            
            if function_changes:
                review_parts.append("#### ğŸ”§ í•¨ìˆ˜ ë³€ê²½ì‚¬í•­")
                for change in function_changes[:5]:  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
                    review_parts.append(f"- `{change['function_name']}` ({change['type']})")
                review_parts.append("")
            
            if import_changes:
                review_parts.append("#### ğŸ“¦ Import ë³€ê²½ì‚¬í•­")
                for change in import_changes[:5]:  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
                    review_parts.append(f"- `{change['module']}` ({change['type']})")
                review_parts.append("")
        
        # AI ë¶„ì„ ê²°ê³¼
        analysis_type = mcp_result.get('analysis_type', 'unknown')
        if analysis_type == 'mcp_enhanced_gemini_with_external_context':
            review_parts.append("### ğŸ¤– MCP ì—°ë™ AI ë¶„ì„ ê²°ê³¼ (ì™¸ë¶€ ì½”ë“œë² ì´ìŠ¤ í¬í•¨)")
            review_parts.append("**GitHub ë©”íƒ€ë°ì´í„°, ëŒ“ê¸€ ë¶„ì„, ì™¸ë¶€ ì½”ë“œë² ì´ìŠ¤ ì¡°íšŒ í¬í•¨**")
        elif analysis_type == 'mcp_enhanced_gemini':
            review_parts.append("### ğŸ¤– MCP ì—°ë™ AI ë¶„ì„ ê²°ê³¼ (ë¬´ë£Œ)")
            review_parts.append("**GitHub ë©”íƒ€ë°ì´í„° ë° ëŒ“ê¸€ ë¶„ì„ í¬í•¨**")
        else:
            review_parts.append("### ğŸ¤– Gemini AI ë¶„ì„ ê²°ê³¼ (ë¬´ë£Œ)")
        
        result = mcp_result.get('result', {})
        if result.get('review'):
            review_parts.append(result['review'])
        else:
            review_parts.append("AI ë¶„ì„ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        review_parts.append("")
        
        # MCP ë©”íƒ€ë°ì´í„° ì •ë³´
        if mcp_result.get('github_metadata', {}).get('status') == 'success':
            review_parts.append("### ğŸ“Š GitHub ë©”íƒ€ë°ì´í„°")
            review_parts.append("- âœ… PR ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ")
            review_parts.append("")
        
        if mcp_result.get('comments_analysis', {}).get('status') == 'success':
            review_parts.append("### ğŸ’¬ PR ëŒ“ê¸€ ë¶„ì„")
            review_parts.append("- âœ… ê¸°ì¡´ ëŒ“ê¸€ ë° í”¼ë“œë°± ë¶„ì„ ì™„ë£Œ")
            review_parts.append("")
        
        # ë¹„ìš© ì •ë³´
        review_parts.append("### ğŸ’° ë¹„ìš© ì •ë³´")
        review_parts.append("- âœ… **ì™„ì „ ë¬´ë£Œ**: API í˜¸ì¶œ ì—†ì´ ë¡œì»¬ Gemini CLI ì‚¬ìš©")
        review_parts.append("- âœ… **AI ë¦¬ë·°**: Google Gemini AIë¥¼ í†µí•œ ê³ í’ˆì§ˆ ë¦¬ë·°")
        review_parts.append("")
        
        # ê¶Œì¥ì‚¬í•­
        review_parts.append("### âœ… ê¶Œì¥ì‚¬í•­")
        review_parts.append("- ì½”ë“œ ìŠ¤íƒ€ì¼ ê°€ì´ë“œë¥¼ ì¤€ìˆ˜í•˜ì„¸ìš”")
        review_parts.append("- í…ŒìŠ¤íŠ¸ ì½”ë“œë¥¼ ì¶”ê°€í•˜ì„¸ìš”")
        review_parts.append("- ë¬¸ì„œí™”ë¥¼ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”")
        review_parts.append("- ë³´ì•ˆ ì·¨ì•½ì ì„ í™•ì¸í•˜ì„¸ìš”")
        review_parts.append("")
        
        # í‘¸í„°
        review_parts.append("---")
        review_parts.append(f"*ë¦¬ë·° ìƒì„± ì‹œê°„: {datetime.now().isoformat()}*")
        review_parts.append("*ë¬´ë£Œ AI ë¦¬ë·° - Gemini CLI ê¸°ë°˜*")
        
        return "\n".join(review_parts)
        
    except Exception as e:
        logger.error(f"ë¦¬ë·° ìƒì„± ì‹¤íŒ¨: {e}")
        return f"## âš ï¸ ë¦¬ë·° ìƒì„± ì‹¤íŒ¨\n\nAI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\n\nê¸°ë³¸ ë¦¬ë·°ë¥¼ ì œê³µí•©ë‹ˆë‹¤."

def process_pr_review(pr_info: PRInfo) -> Dict[str, Any]:
    """PR ë¦¬ë·° ì²˜ë¦¬"""
    try:
        # ë¦¬ë·° ì—¬ë¶€ í™•ì¸
        if not should_review_pr(pr_info):
            logger.info(f"PR #{pr_info.pr_number} ë¦¬ë·° ìŠ¤í‚µ: í•„í„°ë§ ì¡°ê±´ì— í•´ë‹¹")
            return {"status": "skipped", "reason": "filtered_out"}
        
        # ë¦¬ë·° ìƒì„±
        review_content = generate_review(pr_info)
        
        # ë¦¬ë·° ê²Œì‹œ
        posted_review = github_client.create_review(
            repo_full_name=pr_info.repo_full_name,
            pr_number=pr_info.pr_number,
            body=review_content,
            event="COMMENT"
        )
        
        return {
            "status": "completed",
            "pr_number": pr_info.pr_number,
            "repository": pr_info.repo_full_name,
            "review_id": posted_review.id,
            "free_ai_review": True
        }
        
    except Exception as e:
        logger.error(f"PR ë¦¬ë·° ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        if config.github.fail_fast_on_error:
            sys.exit(1)
        raise ValueError(f"PR ë¦¬ë·° ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    if not github_client or not gemini_service_instance or not mcp_manager:
        raise HTTPException(status_code=503, detail="ë´‡ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
    
    try:
        mcp_health = mcp_manager.health_check_all_servers()
        health_status = {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "services": {
                "github": "connected",
                "gemini": "available",
                "mcp": mcp_health
            }
        }
        return health_status
    except Exception as e:
        logger.error(f"í—¬ìŠ¤ ì²´í¬ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"í—¬ìŠ¤ ì²´í¬ ì‹¤íŒ¨: {e}")

@app.get("/info")
async def get_info():
    """ì„œë¹„ìŠ¤ ì •ë³´ ì¡°íšŒ"""
    if not github_client or not gemini_service_instance or not mcp_manager:
        raise HTTPException(status_code=503, detail="ë´‡ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
    
    try:
        return {
            "application": "GitHub PR Review Bot",
            "version": "5.0.0",
            "architecture": "ultra_compact",
            "free_ai_review": True,
            "cost": "$0.00 (ì™„ì „ ë¬´ë£Œ)"
        }
    except Exception as e:
        logger.error(f"ì„œë¹„ìŠ¤ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ì„œë¹„ìŠ¤ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")

@app.get("/stats")
async def get_stats():
    """ì‚¬ìš©ëŸ‰ í†µê³„ ì¡°íšŒ"""
    if not github_client or not gemini_service_instance or not mcp_manager:
        raise HTTPException(status_code=503, detail="ë´‡ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
    
    try:
        usage_stats = {
            "gemini_stats": gemini_service_instance.get_usage_stats(),
            "mcp_stats": mcp_manager.get_usage_stats(),
            "timestamp": datetime.now().isoformat()
        }
        return {
            "usage_stats": usage_stats,
            "free_ai_review": True,
            "cost": "$0.00 (ì™„ì „ ë¬´ë£Œ)"
        }
    except Exception as e:
        logger.error(f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")

@app.get("/mcp")
async def get_mcp_info():
    """MCP ì‚¬ìš©ëŸ‰ ì •ë³´ ì¡°íšŒ"""
    if not github_client or not gemini_service_instance or not mcp_manager:
        raise HTTPException(status_code=503, detail="ë´‡ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
    
    try:
        usage_stats = {
            "gemini_stats": gemini_service_instance.get_usage_stats(),
            "mcp_stats": mcp_manager.get_usage_stats(),
            "timestamp": datetime.now().isoformat()
        }
        available_tools = mcp_manager.get_available_tools()
        mcp_health = mcp_manager.health_check_all_servers()
        
        return {
            "usage_stats": usage_stats,
            "available_tools": available_tools,
            "mcp_health": mcp_health,
            "free_ai_review": True,
            "cost": "$0.00 (ì™„ì „ ë¬´ë£Œ)",
            "mcp_integration": True
        }
    except Exception as e:
        logger.error(f"MCP ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"MCP ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")

@app.get("/optimization")
async def get_optimization_status():
    """ìµœì í™” ìƒíƒœ ì¡°íšŒ"""
    try:
        return {
            "gemini_model": config.gemini.gemini_model,
            "gemini_cli_path": config.gemini.gemini_cli_path,
            "aggressive_caching": config.optimization.enable_aggressive_caching,
            "batch_processing": config.optimization.enable_batch_processing,
            "max_requests_per_day": config.gemini.max_requests_per_day,
            "pr_size_thresholds": {
                "min": config.github.min_pr_size_threshold,
                "max": config.github.max_pr_size_threshold
            },
            "skip_draft_prs": config.github.skip_draft_prs,
            "skip_auto_merge_prs": config.github.skip_auto_merge_prs,
            "free_ai_review": True,
            "cost": "$0.00 (ì™„ì „ ë¬´ë£Œ)"
        }
    except Exception as e:
        logger.error(f"ìµœì í™” ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ìµœì í™” ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")

@app.post("/webhook")
async def github_webhook(request: Request, background_tasks: BackgroundTasks):
    """GitHub ì›¹í›… ì—”ë“œí¬ì¸íŠ¸"""
    if not github_client or not gemini_service_instance or not mcp_manager:
        raise HTTPException(status_code=503, detail="ë´‡ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
    
    try:
        # ìš”ì²­ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        payload = await request.body()
        signature = request.headers.get("X-Hub-Signature-256", "")
        event_type = request.headers.get("X-GitHub-Event", "")
        
        if not signature:
            logger.warning("ì›¹í›… ì„œëª…ì´ ì—†ìŠµë‹ˆë‹¤.")
            raise HTTPException(status_code=400, detail="ì›¹í›… ì„œëª…ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        if not event_type:
            logger.warning("GitHub ì´ë²¤íŠ¸ íƒ€ì…ì´ ì—†ìŠµë‹ˆë‹¤.")
            raise HTTPException(status_code=400, detail="GitHub ì´ë²¤íŠ¸ íƒ€ì…ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        logger.info(f"ì›¹í›… ì´ë²¤íŠ¸ ìˆ˜ì‹ : {event_type}")
        
        # ì›¹í›… ì´ë²¤íŠ¸ ì²˜ë¦¬
        if event_type == "pull_request":
            # 1. ì„œëª… ê²€ì¦
            if not verify_signature(payload, signature):
                raise ValueError("ì›¹í›… ì„œëª… ê²€ì¦ ì‹¤íŒ¨")
            
            # 2. í˜ì´ë¡œë“œ íŒŒì‹±
            event_data = parse_payload(payload)
            
            # 3. PR ì •ë³´ ì¶”ì¶œ
            pr_info = extract_pr_info(event_data)
            
            # 4. PR ë¦¬ë·° ì²˜ë¦¬
            result = process_pr_review(pr_info)
            
            logger.info(f"ì›¹í›… ì²˜ë¦¬ ì™„ë£Œ: {result.get('status', 'unknown')}")
            return JSONResponse(content=result)
        else:
            logger.info(f"ì´ë²¤íŠ¸ íƒ€ì… '{event_type}'ì€ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ")
            return JSONResponse(content={"status": "ignored", "reason": "unsupported_event_type"})
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì›¹í›… ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        if config.github.fail_fast_on_error:
            sys.exit(1)
        raise HTTPException(status_code=500, detail=f"ì›¹í›… ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

@app.post("/review/{repo_owner}/{repo_name}/{pr_number}")
async def manual_review(repo_owner: str, repo_name: str, pr_number: int):
    """ìˆ˜ë™ PR ë¦¬ë·° ì—”ë“œí¬ì¸íŠ¸"""
    if not github_client or not gemini_service_instance or not mcp_manager:
        raise HTTPException(status_code=503, detail="ë´‡ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
    
    try:
        repo_full_name = f"{repo_owner}/{repo_name}"
        
        logger.info(f"ìˆ˜ë™ PR ë¦¬ë·° ìš”ì²­: {repo_full_name}#{pr_number}")
        
        # PR ì •ë³´ ì¡°íšŒ ë° ë¦¬ë·° ìˆ˜í–‰
        pr = github_client.get_pull_request(repo_full_name, pr_number)
        pr_files = github_client.get_pr_files(repo_full_name, pr_number)
        pr_diff = github_client.get_pr_diff(repo_full_name, pr_number)
        detailed_changes = github_client.get_detailed_changes(repo_full_name, pr_number)
        line_by_line_changes = github_client.get_line_by_line_changes(repo_full_name, pr_number)
        
        # PR ì •ë³´ ìƒì„±
        pr_info = PRInfo(
            pr_number=pr_number,
            repo_full_name=repo_full_name,
            pr_title=pr.title,
            pr_body=pr.body or '',
            pr_diff=pr_diff,
            language=detect_language(pr_files),
            files=[f['filename'] for f in pr_files],  # ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë³€ê²½
            author=pr.user.login,
            stats={
                'additions': pr.additions,
                'deletions': pr.deletions,
                'changed_files': pr.changed_files
            },
            head_ref=pr.head.ref,
            base_ref=pr.base.ref,
            action='manual_review',
            detailed_changes=detailed_changes,
            line_by_line_changes=line_by_line_changes
        )
        
        # ë¦¬ë·° ì²˜ë¦¬
        result = process_pr_review(pr_info)
        
        logger.info(f"ìˆ˜ë™ PR ë¦¬ë·° ì™„ë£Œ: {repo_full_name}#{pr_number}")
        return JSONResponse(content=result)
        
    except Exception as e:
        logger.error(f"ìˆ˜ë™ PR ë¦¬ë·° ì‹¤íŒ¨: {e}")
        if config.github.fail_fast_on_error:
            sys.exit(1)
        raise HTTPException(status_code=500, detail=f"ìˆ˜ë™ PR ë¦¬ë·° ì‹¤íŒ¨: {e}")

async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        logger.info("GitHub PR Review Bot ì‹œì‘ - Ultra Compact Version")
        
        # í™˜ê²½ ë³€ìˆ˜ ê²€ì¦
        validate_environment()
        
        # ì„¤ì • ì •ë³´ ë¡œê·¸
        logger.info(f"GitHub ìë™ ë¦¬ë·°: {'í™œì„±í™”' if config.github.auto_review_enabled else 'ë¹„í™œì„±í™”'}")
        logger.info(f"ëª…ì‹œì  ë¦¬ë·° ìš”ì²­ í•„ìš”: {'ì˜ˆ' if config.github.require_explicit_review_request else 'ì•„ë‹ˆì˜¤'}")
        logger.info(f"ì¦‰ì‹œ ì‹¤íŒ¨ ëª¨ë“œ: {'í™œì„±í™”' if config.github.fail_fast_on_error else 'ë¹„í™œì„±í™”'}")
        logger.info("ë¬´ë£Œ AI ë¦¬ë·°: Gemini CLI ì‚¬ìš©")
        
        # ì›¹í›… ì„œë²„ ì‹œì‘
        logger.info("ì›¹í›… ì„œë²„ ì‹œì‘ ì¤‘...")
        uvicorn.run(
            app,
            host="0.0.0.0",
            port=8000,
            reload=False,
            log_level="info"
        )
        
    except KeyboardInterrupt:
        logger.info("ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
        sys.exit(0)
    except Exception as e:
        logger.error(f"ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())