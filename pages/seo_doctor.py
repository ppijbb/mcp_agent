"""
ğŸ¥ SEO Doctor Page

ì‚¬ì´íŠ¸ ì‘ê¸‰ì²˜ì¹˜ + ê²½ìŸì‚¬ ìŠ¤íŒŒì´ AI
"""

import streamlit as st
from pathlib import Path
import sys
import json
from datetime import datetime
import os
import pandas as pd

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from srcs.common.page_utils import create_agent_page
from srcs.common.standard_a2a_page_helper import execute_standard_agent_via_a2a
from srcs.common.agent_interface import AgentType

# ì„¤ì • íŒŒì¼ì—ì„œ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
try:
    from configs.settings import get_reports_path
except ImportError:
    st.error("âŒ ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. configs/settings.pyë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# Result Reader ì„í¬íŠ¸
try:
    from srcs.utils.result_reader import result_reader, result_display
except ImportError as e:
    st.error(f"âŒ ê²°ê³¼ ì½ê¸° ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    st.stop()

def display_results(result_data):
    st.markdown("---")
    st.subheader("ğŸ“Š SEO ë¶„ì„ ê²°ê³¼")

    if not result_data:
        st.warning("ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    emergency_level = result_data.get('emergency_level', 'N/A')
    st.metric("ì§„ë‹¨ ìˆ˜ì¤€", emergency_level)

    c1, c2, c3, c4 = st.columns(4)
    c1.metric("ì¢…í•© ì ìˆ˜", f"{result_data.get('overall_score', 0):.0f}")
    c2.metric("ì„±ëŠ¥", f"{result_data.get('performance_score', 0):.0f}")
    c3.metric("SEO", f"{result_data.get('seo_score', 0):.0f}")
    c4.metric("ì ‘ê·¼ì„±", f"{result_data.get('accessibility_score', 0):.0f}")
    
    with st.expander("ì„¸ë¶€ ì§„ë‹¨ ë‚´ìš© ë³´ê¸°", expanded=True):
        st.markdown("#### ì£¼ìš” ì›¹ ì§€í‘œ (Core Web Vitals)")
        
        st.markdown("#### ğŸš¨ ì¹˜ëª…ì ì¸ ë¬¸ì œ")
        st.table(pd.DataFrame(result_data.get('critical_issues', []), columns=["ë¬¸ì œì "]))
        
        st.markdown("#### âš¡ï¸ ë¹ ë¥¸ ìˆ˜ì • ì œì•ˆ")
        st.table(pd.DataFrame(result_data.get('quick_fixes', []), columns=["ìˆ˜ì • ì œì•ˆ"]))
    
    with st.expander("ì¢…í•© ê°œì„  ê¶Œì¥ ì‚¬í•­"):
        st.table(pd.DataFrame(result_data.get('recommendations', []), columns=["ê¶Œì¥ ì‚¬í•­"]))

    with st.expander("ê²½ìŸì‚¬ ë¶„ì„"):
        st.table(pd.DataFrame(result_data.get('competitor_analysis', [])))


def main():
    create_agent_page(
        agent_name="SEO Doctor Agent",
        page_icon="ğŸ¥",
        page_type="seo",
        title="SEO Doctor Agent",
        subtitle="ì›¹ì‚¬ì´íŠ¸ë¥¼ ì •ë°€ ì§„ë‹¨í•˜ê³  ê²€ìƒ‰ ì—”ì§„ ìµœì í™”(SEO)ë¥¼ ìœ„í•œ ì²˜ë°©ì„ ë‚´ë¦½ë‹ˆë‹¤.",
        module_path="srcs.seo_doctor.run_seo_doctor"
    )
    result_placeholder = st.empty()

    with st.form("seo_doctor_form"):
        st.subheader("ğŸ“ ë¶„ì„í•  ì›¹ì‚¬ì´íŠ¸ ì •ë³´ ì…ë ¥")
        
        url = st.text_input("ë¶„ì„í•  ì›¹ì‚¬ì´íŠ¸ URL", placeholder="https://example.com")
        
        include_competitors = st.checkbox("ê²½ìŸì‚¬ ë¶„ì„ í¬í•¨", value=True)
        
        competitor_urls_text = st.text_area(
            "ê²½ìŸì‚¬ URL (ì‰¼í‘œë¡œ êµ¬ë¶„)",
            placeholder="https://competitor1.com, https://competitor2.com",
            disabled=not include_competitors
        )
        
        submitted = st.form_submit_button("ğŸš€ SEO ì§„ë‹¨ ì‹œì‘", width='stretch')

    if submitted:
        if not url or "http" not in url:
            st.warning("ìœ íš¨í•œ URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”. (http:// ë˜ëŠ” https:// í¬í•¨)")
        else:
            reports_path = Path(get_reports_path('seo_doctor'))
            reports_path.mkdir(parents=True, exist_ok=True)
            result_json_path = reports_path / f"seo_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

            from srcs.common.standard_a2a_page_helper import (
                execute_standard_agent_via_a2a,
                process_standard_agent_result
            )
            from srcs.common.agent_interface import AgentType

            # í‘œì¤€í™”ëœ ë°©ì‹ìœ¼ë¡œ agent ì‹¤í–‰
            result = execute_standard_agent_via_a2a(
                placeholder=result_placeholder,
                agent_id="seo_doctor_agent",
                agent_name="SEO Doctor Agent",
                entry_point="srcs.seo_doctor.run_seo_doctor",
                agent_type=AgentType.MCP_AGENT,
                capabilities=["seo_analysis", "website_diagnosis", "competitor_analysis", "seo_optimization"],
                description="ì›¹ì‚¬ì´íŠ¸ë¥¼ ì •ë°€ ì§„ë‹¨í•˜ê³  ê²€ìƒ‰ ì—”ì§„ ìµœì í™”(SEO)ë¥¼ ìœ„í•œ ì²˜ë°©",
                input_params={
                    "url": url,
                    "include_competitors": include_competitors,
                    "competitor_urls": [u.strip() for u in competitor_urls_text.split(',')] if competitor_urls_text.strip() else []
                },
                result_json_path=result_json_path
            )

            # ê²°ê³¼ ì²˜ë¦¬
            processed = process_standard_agent_result(result, "seo_doctor_agent")
            if processed["success"] and processed["has_data"]:
                display_results(processed["data"])

    # ìµœì‹  SEO Doctor ê²°ê³¼ í™•ì¸
    st.markdown("---")
    st.markdown("## ğŸ“Š ìµœì‹  SEO Doctor ê²°ê³¼")
    
    latest_seo_result = result_reader.get_latest_result("seo_doctor_agent", "seo_analysis")
    
    if latest_seo_result:
        with st.expander("ğŸ¥ ìµœì‹  SEO ì§„ë‹¨ ê²°ê³¼", expanded=False):
            st.subheader("ğŸ¤– ìµœê·¼ SEO ì§„ë‹¨ ê²°ê³¼")
            
            if isinstance(latest_seo_result, dict):
                # ì›¹ì‚¬ì´íŠ¸ ì •ë³´ í‘œì‹œ
                url = latest_seo_result.get('url', 'N/A')
                emergency_level = latest_seo_result.get('emergency_level', 'N/A')
                
                st.success(f"**ë¶„ì„ URL: {url}**")
                st.info(f"**ì§„ë‹¨ ìˆ˜ì¤€: {emergency_level}**")
                
                # SEO ì ìˆ˜ ìš”ì•½
                col1, col2, col3, col4 = st.columns(4)
                col1.metric("ì¢…í•© ì ìˆ˜", f"{latest_seo_result.get('overall_score', 0):.0f}")
                col2.metric("ì„±ëŠ¥", f"{latest_seo_result.get('performance_score', 0):.0f}")
                col3.metric("SEO", f"{latest_seo_result.get('seo_score', 0):.0f}")
                col4.metric("ì ‘ê·¼ì„±", f"{latest_seo_result.get('accessibility_score', 0):.0f}")
                
                # ì¹˜ëª…ì ì¸ ë¬¸ì œ í‘œì‹œ
                critical_issues = latest_seo_result.get('critical_issues', [])
                if critical_issues:
                    st.subheader("ğŸš¨ ì¹˜ëª…ì ì¸ ë¬¸ì œ")
                    for issue in critical_issues:
                        st.write(f"â€¢ {issue}")
                
                # ë¹ ë¥¸ ìˆ˜ì • ì œì•ˆ í‘œì‹œ
                quick_fixes = latest_seo_result.get('quick_fixes', [])
                if quick_fixes:
                    st.subheader("âš¡ï¸ ë¹ ë¥¸ ìˆ˜ì • ì œì•ˆ")
                    for fix in quick_fixes:
                        st.write(f"â€¢ {fix}")
                
                # ë©”íƒ€ë°ì´í„° í‘œì‹œ
                if 'timestamp' in latest_seo_result:
                    st.caption(f"â° ì§„ë‹¨ ì‹œê°„: {latest_seo_result['timestamp']}")
            else:
                st.write("ê²°ê³¼ ë°ì´í„° í˜•ì‹ì´ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤.")
    else:
        st.info("ğŸ’¡ ì•„ì§ SEO Doctor Agentì˜ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ìœ„ì—ì„œ SEO ì§„ë‹¨ì„ ì‹¤í–‰í•´ë³´ì„¸ìš”.")

if __name__ == "__main__":
    main()