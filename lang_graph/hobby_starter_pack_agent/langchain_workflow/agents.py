"""
LangChain ê¸°ë°˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ
ë³µì¡í•œ ì‘ì—… ìë™í™” ë° ë„êµ¬ í†µí•©
Multi-LLM Provider Support: OpenRouter, Groq, Cerebras, OpenAI, Anthropic, Google
"""

import logging
from typing import Dict, Any, List, Optional, Union
from langchain.agents import AgentExecutor, create_openai_functions_agent
from langchain.agents.openai_functions_agent.base import OpenAIFunctionsAgent
from langchain.tools import BaseTool, tool
from langchain.schema import BaseMessage, HumanMessage, AIMessage
from langchain.memory import ConversationBufferMemory
from langchain.prompts import MessagesPlaceholder, ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain.schema.runnable import RunnablePassthrough
from langchain.output_parsers import PydanticOutputParser
from pydantic import BaseModel, Field
import json
from datetime import datetime

# Import LLM provider configuration
import os
from core.llm import get_llm_config, get_llm_manager

logger = logging.getLogger(__name__)

# ë„êµ¬ ì •ì˜ë¥¼ ìœ„í•œ Pydantic ëª¨ë¸ë“¤
class HobbyRecommendationInput(BaseModel):
    user_profile: Dict[str, Any] = Field(description="ì‚¬ìš©ì í”„ë¡œí•„ ì •ë³´")
    preferences: List[str] = Field(description="ì‚¬ìš©ì ì„ í˜¸ì‚¬í•­")
    constraints: Dict[str, Any] = Field(description="ì œì•½ì‚¬í•­ (ì‹œê°„, ì˜ˆì‚° ë“±)")

class HobbyRecommendationOutput(BaseModel):
    recommendations: List[Dict[str, Any]] = Field(description="ì¶”ì²œ ì·¨ë¯¸ ëª©ë¡")
    reasoning: str = Field(description="ì¶”ì²œ ê·¼ê±°")
    confidence_score: float = Field(description="ì¶”ì²œ ì‹ ë¢°ë„")

class CommunityMatchingInput(BaseModel):
    user_profile: Dict[str, Any] = Field(description="ì‚¬ìš©ì í”„ë¡œí•„")
    hobby_interests: List[str] = Field(description="ê´€ì‹¬ ì·¨ë¯¸")
    location: str = Field(description="í™œë™ ì§€ì—­")

class CommunityMatchingOutput(BaseModel):
    matched_communities: List[Dict[str, Any]] = Field(description="ë§¤ì¹­ëœ ì»¤ë®¤ë‹ˆí‹°")
    match_scores: Dict[str, float] = Field(description="ë§¤ì¹­ ì ìˆ˜")

class ScheduleIntegrationInput(BaseModel):
    current_schedule: Dict[str, Any] = Field(description="í˜„ì¬ ìŠ¤ì¼€ì¤„")
    hobby_activities: List[Dict[str, Any]] = Field(description="ì¶”ê°€í•  ì·¨ë¯¸ í™œë™")
    time_constraints: Dict[str, Any] = Field(description="ì‹œê°„ ì œì•½")

class ScheduleIntegrationOutput(BaseModel):
    integrated_schedule: Dict[str, Any] = Field(description="í†µí•©ëœ ìŠ¤ì¼€ì¤„")
    optimization_suggestions: List[str] = Field(description="ìµœì í™” ì œì•ˆ")

# LangChain ë„êµ¬ë“¤
@tool
def analyze_user_profile(user_input: str, conversation_history: str = "") -> Dict[str, Any]:
    """ì‚¬ìš©ì ì…ë ¥ì„ ë¶„ì„í•˜ì—¬ í”„ë¡œí•„ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” LLMì„ í˜¸ì¶œí•˜ì—¬ ë¶„ì„
        # ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œ ì‘ë‹µ ë°˜í™˜
        profile = {
            "interests": ["reading", "technology", "outdoor_activities"],
            "personality_type": "introvert",
            "skill_level": "beginner",
            "time_availability": "weekends",
            "budget_range": "medium",
            "location_preference": "Seoul",
            "confidence_score": 0.85,
            "analysis_reasoning": "ì‚¬ìš©ì ì…ë ¥ê³¼ ëŒ€í™” ê¸°ë¡ì„ ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤."
        }
        
        logger.info("ì‚¬ìš©ì í”„ë¡œí•„ ë¶„ì„ ì™„ë£Œ")
        return profile
        
    except Exception as e:
        logger.error(f"í”„ë¡œí•„ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return {"error": "í”„ë¡œí•„ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."}

@tool
def search_hobbies(query: str, user_profile: Dict[str, Any]) -> List[Dict[str, Any]]:
    """ì‚¬ìš©ì í”„ë¡œí•„ì— ë§ëŠ” ì·¨ë¯¸ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    try:
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰
        hobbies = [
            {
                "name": "ë…ì„œ",
                "category": "intellectual",
                "difficulty": "beginner",
                "time_commitment": "flexible",
                "cost": "low",
                "match_score": 0.9
            },
            {
                "name": "ë“±ì‚°",
                "category": "outdoor",
                "difficulty": "beginner",
                "time_commitment": "weekends",
                "cost": "medium",
                "match_score": 0.8
            }
        ]
        
        logger.info(f"ì·¨ë¯¸ ê²€ìƒ‰ ì™„ë£Œ: {len(hobbies)}ê°œ ê²°ê³¼")
        return hobbies
        
    except Exception as e:
        logger.error(f"ì·¨ë¯¸ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return []

@tool
def find_communities(hobby_categories: List[str], location: str) -> List[Dict[str, Any]]:
    """ì·¨ë¯¸ ì¹´í…Œê³ ë¦¬ì— ë§ëŠ” ì»¤ë®¤ë‹ˆí‹°ë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
    try:
        communities = [
            {
                "name": "ë…ì„œ ëª¨ì„",
                "type": "online",
                "category": "intellectual",
                "members": 150,
                "activity_level": "high",
                "location": "Seoul"
            },
            {
                "name": "ë“±ì‚° ë™í˜¸íšŒ",
                "type": "offline",
                "category": "outdoor",
                "members": 80,
                "activity_level": "medium",
                "location": "Seoul"
            }
        ]
        
        logger.info(f"ì»¤ë®¤ë‹ˆí‹° ê²€ìƒ‰ ì™„ë£Œ: {len(communities)}ê°œ ê²°ê³¼")
        return communities
        
    except Exception as e:
        logger.error(f"ì»¤ë®¤ë‹ˆí‹° ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return []

@tool
def optimize_schedule(current_schedule: Dict[str, Any], new_activities: List[Dict[str, Any]]) -> Dict[str, Any]:
    """í˜„ì¬ ìŠ¤ì¼€ì¤„ì— ìƒˆë¡œìš´ í™œë™ì„ ìµœì í™”í•˜ì—¬ í†µí•©í•©ë‹ˆë‹¤."""
    try:
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ìŠ¤ì¼€ì¤„ ìµœì í™” ì•Œê³ ë¦¬ì¦˜
        optimized_schedule = {
            "weekdays": {
                "evening": ["ë…ì„œ", "ì˜¨ë¼ì¸ ê°•ì˜"],
                "night": ["ëª…ìƒ", "ì¼ê¸° ì“°ê¸°"]
            },
            "weekends": {
                "morning": ["ë“±ì‚°", "ìš”ê°€"],
                "afternoon": ["ì»¤ë®¤ë‹ˆí‹° í™œë™", "ìƒˆë¡œìš´ ì·¨ë¯¸ ì‹œë„"],
                "evening": ["ì¹œêµ¬ë“¤ê³¼ ë§Œë‚¨", "ì˜í™” ê°ìƒ"]
            }
        }
        
        logger.info("ìŠ¤ì¼€ì¤„ ìµœì í™” ì™„ë£Œ")
        return optimized_schedule
        
    except Exception as e:
        logger.error(f"ìŠ¤ì¼€ì¤„ ìµœì í™” ì‹¤íŒ¨: {e}")
        return {"error": "ìŠ¤ì¼€ì¤„ ìµœì í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."}

class HSPLangChainAgent:
    """HSP Agent ì „ìš© LangChain ì—ì´ì „íŠ¸"""
    
    def __init__(self, llm_config: Optional[Dict[str, Any]] = None, use_random_free: bool = True):
        """
        Initialize LangChain agent
        
        Args:
            llm_config: Optional dict config (legacy support)
            use_random_free: If True (default), uses random free provider (OpenRouter, Groq, Cerebras)
                            If False, uses primary provider from environment
        """
        # Support both legacy dict config and new LLM provider system
        self.llm_config = llm_config
        self.llm = None
        self.tools = []
        self.agent = None
        self.agent_executor = None
        self.memory = None
        
        # Initialize LLM and agent
        self._initialize_llm(use_random_free=use_random_free)
        self._initialize_tools()
        self._initialize_agent()
        
        logger.info("HSP LangChain Agent ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _initialize_llm(self, use_random_free: bool = True):
        """LLM ì´ˆê¸°í™” - Supports OpenRouter, Groq, Cerebras, OpenAI, Anthropic, Google"""
        try:
            if use_random_free:
                # DEFAULT: Use random free provider (OpenRouter, Groq, Cerebras)
                from core.llm import get_random_free_config
                config = get_random_free_config()
                if config:
                    # Create OpenAI-compatible client (works with OpenRouter, Groq, Cerebras)
                    self.llm = ChatOpenAI(
                        model=config.model,
                        temperature=config.temperature,
                        openai_api_key=config.api_key,
                        openai_api_base=config.base_url,
                        max_tokens=config.max_tokens
                    )
                    logger.info(f"ğŸ² LLM ì´ˆê¸°í™” ì™„ë£Œ (random free): {config.provider.value} - {config.model}")
                else:
                    # Fallback to primary provider
                    from core.llm import get_llm_config
                    config = get_llm_config()
                    if config:
                        self.llm = ChatOpenAI(
                            model=config.model,
                            temperature=config.temperature,
                            openai_api_key=config.api_key,
                            openai_api_base=config.base_url,
                            max_tokens=config.max_tokens
                        )
                        logger.info(f"LLM ì´ˆê¸°í™” ì™„ë£Œ (fallback): {config.provider.value} - {config.model}")
                    else:
                        raise ValueError("No LLM provider configured")
            else:
                # Use primary provider from environment
                from core.llm import get_llm_config
                config = get_llm_config()
                if config:
                    self.llm = ChatOpenAI(
                        model=config.model,
                        temperature=config.temperature,
                        openai_api_key=config.api_key,
                        openai_api_base=config.base_url,
                        max_tokens=config.max_tokens
                    )
                    logger.info(f"LLM ì´ˆê¸°í™” ì™„ë£Œ: {config.provider.value} - {config.model}")
                else:
                    # Fallback to environment variables (legacy support)
                    import os
                    api_key = os.getenv("OPENAI_API_KEY")
                    if not api_key:
                        raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                    
                    model = os.getenv("LLM_MODEL", "gpt-4o")
                    self.llm = ChatOpenAI(
                        model=model,
                        temperature=0.7,
                        openai_api_key=api_key
                    )
                    logger.info(f"LLM ì´ˆê¸°í™” ì™„ë£Œ (legacy): {model}")
            
        except Exception as e:
            logger.error(f"LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise ValueError(f"LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def _initialize_tools(self):
        """ë„êµ¬ ì´ˆê¸°í™”"""
        self.tools = [
            analyze_user_profile,
            search_hobbies,
            find_communities,
            optimize_schedule
        ]
        logger.info(f"{len(self.tools)}ê°œì˜ ë„êµ¬ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _initialize_agent(self):
        """ì—ì´ì „íŠ¸ ì´ˆê¸°í™”"""
        try:
            if not self.llm:
                logger.warning("LLMì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            # ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
            self.memory = ConversationBufferMemory(
                memory_key="chat_history",
                return_messages=True
            )
            
            # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
            prompt = ChatPromptTemplate.from_messages([
                ("system", """ë‹¹ì‹ ì€ ì·¨ë¯¸ ì¶”ì²œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
                ì‚¬ìš©ìì˜ ìš”ì²­ì— ë”°ë¼ ì ì ˆí•œ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”.
                í•­ìƒ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ê³ , êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”."""),
                MessagesPlaceholder(variable_name="chat_history"),
                ("human", "{input}"),
                MessagesPlaceholder(variable_name="agent_scratchpad")
            ])
            
            # ì—ì´ì „íŠ¸ ìƒì„±
            self.agent = create_openai_functions_agent(
                llm=self.llm,
                tools=self.tools,
                prompt=prompt
            )
            
            # ì—ì´ì „íŠ¸ ì‹¤í–‰ê¸° ìƒì„±
            self.agent_executor = AgentExecutor(
                agent=self.agent,
                tools=self.tools,
                memory=self.memory,
                verbose=True,
                handle_parsing_errors=True
            )
            
            logger.info("LangChain ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    async def run_agent(self, user_input: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """ì—ì´ì „íŠ¸ ì‹¤í–‰"""
        try:
            if not self.agent_executor:
                return {"error": "ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}
            
            # ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ì…ë ¥ì— í¬í•¨
            if context:
                enhanced_input = f"{user_input}\n\nì»¨í…ìŠ¤íŠ¸: {json.dumps(context, ensure_ascii=False)}"
            else:
                enhanced_input = user_input
            
            # ì—ì´ì „íŠ¸ ì‹¤í–‰
            result = await self.agent_executor.ainvoke({
                "input": enhanced_input
            })
            
            logger.info("ì—ì´ì „íŠ¸ ì‹¤í–‰ ì™„ë£Œ")
            return {
                "success": True,
                "output": result.get("output", ""),
                "intermediate_steps": result.get("intermediate_steps", []),
                "chat_history": self.memory.chat_memory.messages
            }
            
        except Exception as e:
            logger.error(f"ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "output": "ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            }
    
    async def get_hobby_recommendations(self, user_profile: Dict[str, Any], 
                                       preferences: List[str], 
                                       constraints: Dict[str, Any]) -> HobbyRecommendationOutput:
        """ì·¨ë¯¸ ì¶”ì²œ ì—ì´ì „íŠ¸ ì‹¤í–‰"""
        try:
            # ì…ë ¥ ê²€ì¦
            input_data = HobbyRecommendationInput(
                user_profile=user_profile,
                preferences=preferences,
                constraints=constraints
            )
            
            # ì—ì´ì „íŠ¸ ì‹¤í–‰
            agent_input = f"""
            ì‚¬ìš©ì í”„ë¡œí•„: {json.dumps(user_profile, ensure_ascii=False)}
            ì„ í˜¸ì‚¬í•­: {', '.join(preferences)}
            ì œì•½ì‚¬í•­: {json.dumps(constraints, ensure_ascii=False)}
            
            ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°œì¸í™”ëœ ì·¨ë¯¸ë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”.
            """
            
            result = await self.run_agent(agent_input)
            
            if result["success"]:
                # ê²°ê³¼ íŒŒì‹± (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë” ì •êµí•œ íŒŒì‹± í•„ìš”)
                return HobbyRecommendationOutput(
                    recommendations=[
                        {
                            "name": "ì¶”ì²œ ì·¨ë¯¸",
                            "category": "ì¼ë°˜",
                            "difficulty": "beginner",
                            "match_score": 0.8
                        }
                    ],
                    reasoning=result["output"],
                    confidence_score=0.8
                )
            else:
                raise Exception(result["error"])
                
        except Exception as e:
            logger.error(f"ì·¨ë¯¸ ì¶”ì²œ ì‹¤íŒ¨: {e}")
            return HobbyRecommendationOutput(
                recommendations=[],
                reasoning="ì¶”ì²œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                confidence_score=0.0
            )
    
    async def match_communities(self, user_profile: Dict[str, Any], 
                               hobby_interests: List[str], 
                               location: str) -> CommunityMatchingOutput:
        """ì»¤ë®¤ë‹ˆí‹° ë§¤ì¹­ ì—ì´ì „íŠ¸ ì‹¤í–‰"""
        try:
            # ì…ë ¥ ê²€ì¦
            input_data = CommunityMatchingInput(
                user_profile=user_profile,
                hobby_interests=hobby_interests,
                location=location
            )
            
            # ì—ì´ì „íŠ¸ ì‹¤í–‰
            agent_input = f"""
            ì‚¬ìš©ì í”„ë¡œí•„: {json.dumps(user_profile, ensure_ascii=False)}
            ê´€ì‹¬ ì·¨ë¯¸: {', '.join(hobby_interests)}
            í™œë™ ì§€ì—­: {location}
            
            ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì í•©í•œ ì»¤ë®¤ë‹ˆí‹°ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”.
            """
            
            result = await self.run_agent(agent_input)
            
            if result["success"]:
                return CommunityMatchingOutput(
                    matched_communities=[
                        {
                            "name": "ì¶”ì²œ ì»¤ë®¤ë‹ˆí‹°",
                            "type": "online",
                            "members": 100,
                            "match_score": 0.85
                        }
                    ],
                    match_scores={"ì¶”ì²œ ì»¤ë®¤ë‹ˆí‹°": 0.85}
                )
            else:
                raise Exception(result["error"])
                
        except Exception as e:
            logger.error(f"ì»¤ë®¤ë‹ˆí‹° ë§¤ì¹­ ì‹¤íŒ¨: {e}")
            return CommunityMatchingOutput(
                matched_communities=[],
                match_scores={}
            )
    
    async def integrate_schedule(self, current_schedule: Dict[str, Any], 
                                hobby_activities: List[Dict[str, Any]], 
                                time_constraints: Dict[str, Any]) -> ScheduleIntegrationOutput:
        """ìŠ¤ì¼€ì¤„ í†µí•© ì—ì´ì „íŠ¸ ì‹¤í–‰"""
        try:
            # ì…ë ¥ ê²€ì¦
            input_data = ScheduleIntegrationInput(
                current_schedule=current_schedule,
                hobby_activities=hobby_activities,
                time_constraints=time_constraints
            )
            
            # ì—ì´ì „íŠ¸ ì‹¤í–‰
            agent_input = f"""
            í˜„ì¬ ìŠ¤ì¼€ì¤„: {json.dumps(current_schedule, ensure_ascii=False)}
            ì¶”ê°€í•  ì·¨ë¯¸ í™œë™: {json.dumps(hobby_activities, ensure_ascii=False)}
            ì‹œê°„ ì œì•½: {json.dumps(time_constraints, ensure_ascii=False)}
            
            ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìŠ¤ì¼€ì¤„ì„ ìµœì í™”í•˜ê³  í†µí•©í•´ì£¼ì„¸ìš”.
            """
            
            result = await self.run_agent(agent_input)
            
            if result["success"]:
                return ScheduleIntegrationOutput(
                    integrated_schedule={
                        "weekdays": {"evening": ["í†µí•©ëœ í™œë™"]},
                        "weekends": {"morning": ["ìƒˆë¡œìš´ ì·¨ë¯¸"]}
                    },
                    optimization_suggestions=["ì‹œê°„ íš¨ìœ¨ì„± í–¥ìƒ", "í™œë™ ê· í˜• ì¡°ì •"]
                )
            else:
                raise Exception(result["error"])
                
        except Exception as e:
            logger.error(f"ìŠ¤ì¼€ì¤„ í†µí•© ì‹¤íŒ¨: {e}")
            return ScheduleIntegrationOutput(
                integrated_schedule={},
                optimization_suggestions=[]
            )
    
    def get_agent_status(self) -> Dict[str, Any]:
        """ì—ì´ì „íŠ¸ ìƒíƒœ ì •ë³´"""
        return {
            "initialized": self.agent is not None,
            "llm_available": self.llm is not None,
            "tools_count": len(self.tools),
            "memory_size": len(self.memory.chat_memory.messages) if self.memory else 0,
            "last_execution": datetime.now().isoformat()
        }
    
    def clear_memory(self):
        """ë©”ëª¨ë¦¬ ì´ˆê¸°í™”"""
        if self.memory:
            self.memory.clear()
            logger.info("ì—ì´ì „íŠ¸ ë©”ëª¨ë¦¬ ì´ˆê¸°í™” ì™„ë£Œ")
