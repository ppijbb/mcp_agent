# Local Researcher Project Environment Configuration (v2.0 - 8대 혁신)

# =============================================================================
# CORE LLM CONFIGURATION (Multi-Model Orchestration - 혁신 3)
# =============================================================================
# 기본 제공자 (OpenRouter + Gemini 2.5 Flash Lite)
LLM_PROVIDER=openrouter
LLM_MODEL=google/gemini-2.5-flash-lite
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=4000

# OpenRouter API Key (필수)
OPENROUTER_API_KEY=your_openrouter_api_key_here

# Google API Key (deprecated but still required)
GOOGLE_API_KEY=your_google_api_key_here

# Multi-Model Orchestration (Gemini 2.5 Flash Lite 우선)
PLANNING_MODEL=google/gemini-2.5-flash-lite
REASONING_MODEL=google/gemini-2.5-flash-lite
VERIFICATION_MODEL=google/gemini-2.5-flash-lite
GENERATION_MODEL=google/gemini-2.5-flash-lite
COMPRESSION_MODEL=google/gemini-2.5-flash-lite

# Cost optimization
BUDGET_LIMIT=100.0
ENABLE_COST_OPTIMIZATION=true

# =============================================================================
# ADAPTIVE SUPERVISOR CONFIGURATION (혁신 1)
# =============================================================================
AGENT_MAX_RETRIES=3
AGENT_TIMEOUT=300
ENABLE_SELF_PLANNING=true
ENABLE_AGENT_COMMUNICATION=true

# Adaptive Supervisor settings
MAX_CONCURRENT_RESEARCH_UNITS=5
MIN_RESEARCHERS=1
MAX_RESEARCHERS=10
ENABLE_FAST_TRACK=true
ENABLE_AUTO_RETRY=true
PRIORITY_QUEUE_ENABLED=true

# Quality monitoring
ENABLE_QUALITY_MONITORING=true
QUALITY_THRESHOLD=0.7

# =============================================================================
# RESEARCH CONFIGURATION (Streaming Pipeline - 혁신 5)
# =============================================================================
MAX_SOURCES=20
SEARCH_TIMEOUT=30
ENABLE_ACADEMIC_SEARCH=true
ENABLE_WEB_SEARCH=true
ENABLE_BROWSER_AUTOMATION=true

# Streaming Pipeline settings
ENABLE_STREAMING=true
STREAM_CHUNK_SIZE=1024
ENABLE_PROGRESSIVE_REPORTING=true
ENABLE_INCREMENTAL_SAVE=true

# Parallel processing
ENABLE_PARALLEL_COMPRESSION=true
ENABLE_PARALLEL_VERIFICATION=true

# =============================================================================
# UNIVERSAL MCP HUB CONFIGURATION (혁신 6)
# =============================================================================
MCP_ENABLED=true
MCP_TIMEOUT=30

# Universal MCP Hub settings
ENABLE_PLUGIN_ARCHITECTURE=true
ENABLE_SMART_TOOL_SELECTION=true
ENABLE_AUTO_FALLBACK=false

# MCP Server Names (comma-separated)
MCP_SERVER_NAMES=g-search,tavily,exa,fetch,filesystem,python_coder,code_interpreter,arxiv,scholar,crunchbase,linkedin

# MCP Tool Categories (comma-separated)
MCP_SEARCH_TOOLS=g-search,tavily,exa
MCP_DATA_TOOLS=fetch,filesystem
MCP_CODE_TOOLS=python_coder,code_interpreter
MCP_ACADEMIC_TOOLS=arxiv,scholar
MCP_BUSINESS_TOOLS=crunchbase,linkedin

# =============================================================================
# HIERARCHICAL COMPRESSION CONFIGURATION (혁신 2)
# =============================================================================
ENABLE_HIERARCHICAL_COMPRESSION=true
COMPRESSION_LEVELS=3
PRESERVE_IMPORTANT_INFO=true
ENABLE_COMPRESSION_VALIDATION=true
COMPRESSION_HISTORY_ENABLED=true
MIN_COMPRESSION_RATIO=0.05

# =============================================================================
# CONTINUOUS VERIFICATION CONFIGURATION (혁신 4)
# =============================================================================
ENABLE_CONTINUOUS_VERIFICATION=true
VERIFICATION_STAGES=3
CONFIDENCE_THRESHOLD=0.6
ENABLE_EARLY_WARNING=true
ENABLE_FACT_CHECK=true
ENABLE_UNCERTAINTY_MARKING=true

# =============================================================================
# ADAPTIVE CONTEXT WINDOW CONFIGURATION (혁신 7)
# =============================================================================
ENABLE_ADAPTIVE_CONTEXT=true
MIN_TOKENS=2000
MAX_TOKENS=1000000
IMPORTANCE_BASED_PRESERVATION=true
ENABLE_AUTO_COMPRESSION=true
ENABLE_LONG_TERM_MEMORY=true
MEMORY_REFRESH_INTERVAL=3600

# =============================================================================
# PRODUCTION-GRADE RELIABILITY CONFIGURATION (혁신 8)
# =============================================================================
ENABLE_CIRCUIT_BREAKER=true
ENABLE_EXPONENTIAL_BACKOFF=true
ENABLE_STATE_PERSISTENCE=true
ENABLE_HEALTH_CHECK=true
ENABLE_GRACEFUL_DEGRADATION=true
ENABLE_DETAILED_LOGGING=true

# Circuit breaker settings
FAILURE_THRESHOLD=5
RECOVERY_TIMEOUT=60

# State persistence
STATE_BACKEND=redis
STATE_TTL=3600

# =============================================================================
# OUTPUT CONFIGURATION
# =============================================================================
OUTPUT_DIR=output
ENABLE_PDF=true
ENABLE_MARKDOWN=true
ENABLE_JSON=true
ENABLE_DOCX=true
ENABLE_HTML=true
ENABLE_LATEX=false

# =============================================================================
# CHROMADB CONFIGURATION
# =============================================================================
# ChromaDB는 벡터 검색을 위해 사용됩니다. 선택사항이지만 권장됩니다.
# ChromaDB가 없으면 벡터 검색 기능이 비활성화되고 파일 스토리지만 사용됩니다.
#
# ChromaDB 설치:
#   pip install chromadb
#
# ChromaDB 자동 초기화 및 디렉토리:
CHROMADB_PERSIST_DIR=./storage/chromadb

# =============================================================================
# PRODUCTION DEPLOYMENT NOTES
# =============================================================================
# 모든 환경 변수는 필수입니다. 기본값이 없으므로 반드시 설정해야 합니다.
# 시스템 시작 시 환경 변수가 누락되면 명확한 에러 메시지와 함께 종료됩니다.
# 
# 필수 API 키:
# - OPENROUTER_API_KEY: OpenRouter API 키 (sk-or-로 시작)
# - GOOGLE_API_KEY: Google API 키 (deprecated but required)
#
# 필수 환경 변수:
# - LLM_MODEL: LLM 모델 식별자 (예: google/gemini-2.5-flash-lite)
# - LLM_PROVIDER: 제공자 이름 (예: openrouter)
# - LLM_TEMPERATURE: 온도 설정 (0.0-1.0)
# - LLM_MAX_TOKENS: 최대 토큰 수
#
# MCP 서버가 실행 중이어야 하며, 필수 도구들이 정상 작동해야 합니다.
# Production 환경에서는 모든 의존성이 설치되고 설정되어야 합니다.
#
# ChromaDB가 없어도 시스템은 정상 작동하지만, 벡터 검색 기능이 비활성화됩니다.
# 벡터 검색을 사용하려면: pip install chromadb
