#!/usr/bin/env python3
"""
Autonomous Multi-Agent Research System - Main Entry Point
Implements 8 Core Innovations: Production-Grade Reliability, Universal MCP Hub, Streaming Pipeline

MCP agent ë¼ì´ë¸ŒëŸ¬ë¦¬ ê¸°ë°˜ì˜ ììœ¨ ë¦¬ì„œì²˜ ì‹œìŠ¤í…œ.
ëª¨ë“  í•˜ë“œì½”ë”©, fallback, mock ì½”ë“œë¥¼ ì œê±°í•˜ê³  ì‹¤ì œ MCP agentë¥¼ ì‚¬ìš©.

Usage:
    python main.py --request "ì—°êµ¬ ì£¼ì œ"                    # CLI ëª¨ë“œ
    python main.py --web                                    # ì›¹ ëª¨ë“œ
    python main.py --mcp-server                            # MCP ì„œë²„ ëª¨ë“œ
    python main.py --streaming                             # ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ
"""

import asyncio
import sys
import argparse
import subprocess
import signal
import logging
from pathlib import Path
from typing import Dict, Any, Optional, List, Tuple
from datetime import datetime
from enum import Enum
import json
import os

# Add project root to path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from researcher_config import config, update_config_from_env
from src.agents.autonomous_researcher import AutonomousResearcherAgent
from src.core.autonomous_orchestrator import AutonomousOrchestrator
from src.core.reliability import execute_with_reliability
from src.monitoring.system_monitor import HealthMonitor
from src.core.llm_manager import execute_llm_task, TaskType
from mcp_integration import get_available_tools, execute_tool

# Configure logging for production-grade reliability
# Advanced logging setup: setup logger manually to ensure logs directory exists and avoid issues with logging.basicConfig (per best practices)
log_dir = project_root / "logs"
log_dir.mkdir(parents=True, exist_ok=True)
log_file = log_dir / "researcher.log"

logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# Remove existing handlers to avoid duplicate logs on reloads (e.g., under some app servers or noteboks)
if logger.hasHandlers():
    logger.handlers.clear()

# File handler
file_handler = logging.FileHandler(log_file, encoding='utf-8')
file_handler.setLevel(logging.INFO)
file_handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
logger.addHandler(file_handler)

# Console handler
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)
console_handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
logger.addHandler(console_handler)


class MCPIntegrationManager:
    """MCP í†µí•© ê´€ë¦¬ì - 2025ë…„ 10ì›” ìµœì‹  ë²„ì „ (OpenRouter + Gemini 2.5 Flash Lite)"""
    
    def __init__(self):
        self.config = config
        self.mcp_enabled = config.mcp.enabled
        self.health_monitor = HealthMonitor()
        self.available_tools = []
        self.tool_performance = {}
        self.mcp_hub = None
        
    async def start_mcp_server(self):
        """MCP ì„œë²„ ì‹œì‘ - OpenRouterì™€ Gemini 2.5 Flash Lite ê¸°ë°˜"""
        if not self.mcp_enabled:
            logger.error("MCP is disabled in configuration")
            return False
            
        try:
            logger.info("ğŸš€ Starting MCP Server with OpenRouter and Gemini 2.5 Flash Lite...")
            logger.info(f"Primary model: {config.llm.primary_model}")
            logger.info(f"OpenRouter API: {'Configured' if config.llm.openrouter_api_key else 'Not configured'}")
            logger.info(f"Tool categories: {len(config.mcp.search_tools + config.mcp.data_tools + config.mcp.code_tools + config.mcp.academic_tools + config.mcp.business_tools)}")
            
            # Initialize MCP Hub
            from mcp_integration import UniversalMCPHub
            self.mcp_hub = UniversalMCPHub()
            await self.mcp_hub.initialize_mcp()
            
            # Start health monitoring
            await self.health_monitor.start_monitoring()
            
            logger.info("âœ… MCP Server started successfully with OpenRouter and Gemini 2.5 Flash Lite")
            return True
            
        except Exception as e:
            logger.error(f"Failed to start MCP server: {e}")
            return False
    
    async def start_mcp_client(self):
        """MCP í´ë¼ì´ì–¸íŠ¸ ì‹œì‘ - OpenRouterì™€ Gemini 2.5 Flash Lite ê¸°ë°˜"""
        if not self.mcp_enabled:
            logger.error("MCP is disabled in configuration")
            return False
            
        try:
            logger.info("ğŸ”— Starting MCP Client with OpenRouter and Gemini 2.5 Flash Lite...")
            logger.info(f"Primary model: {config.llm.primary_model}")
            
            # Initialize MCP Hub
            from mcp_integration import UniversalMCPHub
            self.mcp_hub = UniversalMCPHub()
            await self.mcp_hub.initialize_mcp()
            
            # Discover available tools
            self.available_tools = await get_available_tools()
            logger.info(f"Discovered {len(self.available_tools)} MCP tools")
            
            # Initialize performance tracking
            await self._initialize_performance_tracking()
            
            # Test tool connectivity
            await self._test_tool_connectivity()
            
            logger.info("âœ… MCP Client connected successfully with OpenRouter and Gemini 2.5 Flash Lite")
            return True
            
        except Exception as e:
            logger.error(f"Failed to start MCP client: {e}")
            return False
    
    async def _initialize_mcp_tools(self):
        """Initialize MCP tools with OpenRouter and Gemini 2.5 Flash Lite."""
        try:
            if not self.mcp_hub:
                logger.warning("MCP Hub not initialized")
                return
                
            # Load all configured MCP tools
            for tool_name in config.mcp.server_names:
                logger.info(f"Initializing MCP tool: {tool_name}")
                
                # Test tool availability with simple query
                try:
                    test_params = {"query": "test", "max_results": 1}
                    test_result = await self.mcp_hub.execute_tool(tool_name, test_params)
                    if test_result.success:
                        logger.info(f"âœ… {tool_name} initialized successfully")
                    else:
                        logger.warning(f"âš ï¸ {tool_name} failed: {test_result.error}")
                except Exception as e:
                    logger.warning(f"âš ï¸ {tool_name} test failed: {e}")
                    
        except Exception as e:
            logger.warning(f"MCP tools initialization failed: {e}")
    
    async def _initialize_performance_tracking(self):
        """Initialize performance tracking for Smart Tool Selection."""
        for tool in self.available_tools:
            self.tool_performance[tool] = {
                'success_count': 0,
                'failure_count': 0,
                'average_response_time': 0.0,
                'last_used': None,
                'reliability_score': 1.0
            }
    
    async def _test_tool_connectivity(self):
        """Test connectivity to all available tools."""
        if not self.mcp_hub:
            logger.warning("MCP Hub not initialized for connectivity test")
            return
            
        for tool in self.available_tools:
            try:
                start_time = datetime.now()
                # Use appropriate test parameters based on tool type
                test_params = {"query": "connectivity test", "max_results": 1}
                result = await self.mcp_hub.execute_tool(tool, test_params)
                end_time = datetime.now()
                
                response_time = (end_time - start_time).total_seconds()
                
                if result.success:
                    self.tool_performance[tool]['success_count'] += 1
                    self.tool_performance[tool]['average_response_time'] = response_time
                    logger.info(f"âœ… {tool}: {response_time:.2f}s response time")
                else:
                    self.tool_performance[tool]['failure_count'] += 1
                    logger.warning(f"âš ï¸ {tool}: Test failed")
                    
            except Exception as e:
                self.tool_performance[tool]['failure_count'] += 1
                logger.warning(f"âš ï¸ {tool}: Connection test failed - {e}")
    
    async def get_tool_health_status(self) -> Dict[str, Any]:
        """Get health status of all MCP tools."""
        health_status = {
            'total_tools': len(self.available_tools),
            'healthy_tools': 0,
            'unhealthy_tools': 0,
            'tool_details': {}
        }
        
        for tool, perf in self.tool_performance.items():
            total_attempts = perf['success_count'] + perf['failure_count']
            success_rate = perf['success_count'] / total_attempts if total_attempts > 0 else 0
            
            tool_health = {
                'success_rate': success_rate,
                'average_response_time': perf['average_response_time'],
                'reliability_score': perf['reliability_score'],
                'status': 'healthy' if success_rate > 0.8 else 'unhealthy'
            }
            
            health_status['tool_details'][tool] = tool_health
            
            if tool_health['status'] == 'healthy':
                health_status['healthy_tools'] += 1
            else:
                health_status['unhealthy_tools'] += 1
        
        return health_status


class WebAppManager:
    """ì›¹ ì•± ê´€ë¦¬ì - Streaming Pipeline (Innovation 5) ì§€ì›"""
    
    def __init__(self):
        self.project_root = project_root
        self.health_monitor = HealthMonitor()
        
    def start_web_app(self):
        """ì›¹ ì•± ì‹œì‘ - Production-Grade Reliability ì ìš©"""
        try:
            streamlit_app_path = self.project_root / "src" / "web" / "streamlit_app.py"
            
            if not streamlit_app_path.exists():
                logger.error(f"Streamlit app not found at {streamlit_app_path}")
                return False
            
            logger.info("ğŸŒ Starting Local Researcher Web Application with Streaming Pipeline...")
            logger.info("App will be available at: http://localhost:8501")
            logger.info("Features: Real-time streaming, Progressive reporting, Incremental save")
            logger.info("Press Ctrl+C to stop the application")
            
            # Create logs directory if it doesn't exist
            logs_dir = self.project_root / "logs"
            logs_dir.mkdir(exist_ok=True)
            
            cmd = [
                sys.executable, "-m", "streamlit", "run",
                str(streamlit_app_path),
                "--server.port", "8501",
                "--server.address", "0.0.0.0",
                "--browser.gatherUsageStats", "false",
                "--server.enableCORS", "false",
                "--server.enableXsrfProtection", "false"
            ]
            
            # Start health monitoring
            asyncio.create_task(self.health_monitor.start_monitoring())
            
            subprocess.run(cmd, cwd=str(self.project_root))
            return True
            
        except KeyboardInterrupt:
            logger.info("Application stopped by user")
            return True
        except Exception as e:
            logger.error(f"Error running web application: {e}")
            return False
    
    async def get_web_app_health(self) -> Dict[str, Any]:
        """Get web application health status."""
        return {
            'status': 'running',
            'port': 8501,
            'streaming_enabled': True,
            'progressive_reporting': True,
            'incremental_save': True,
            'timestamp': datetime.now().isoformat()
        }


# AutonomousResearcherAgent is now in src/agents/autonomous_researcher.py


class AutonomousResearchSystem:
    """ììœ¨ ë¦¬ì„œì²˜ ì‹œìŠ¤í…œ - 8ê°€ì§€ í•µì‹¬ í˜ì‹  í†µí•© ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        # Load configurations
        update_config_from_env()
        self.config = config
        
        # Initialize components with 8 innovations
        self.orchestrator = AutonomousOrchestrator()
        self.mcp_manager = MCPIntegrationManager()
        self.web_manager = WebAppManager()
        self.health_monitor = HealthMonitor()
        
        # Initialize signal handlers for graceful shutdown
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
        
    def _signal_handler(self, signum, frame):
        """Handle shutdown signals gracefully."""
        logger.info(f"Received signal {signum}, initiating graceful shutdown...")
        asyncio.create_task(self._graceful_shutdown())
    
    async def _graceful_shutdown(self):
        """Graceful shutdown with state persistence."""
        try:
            logger.info("Performing graceful shutdown...")
            await self.health_monitor.stop_monitoring()
            logger.info("âœ… Graceful shutdown completed")
        except Exception as e:
            logger.error(f"Error during graceful shutdown: {e}")
    
    async def run_research(self, request: str, output_path: Optional[str] = None, 
                          streaming: bool = False) -> Dict[str, Any]:
        """ì—°êµ¬ ì‹¤í–‰ - 8ê°€ì§€ í•µì‹¬ í˜ì‹  ì ìš©"""
        logger.info("ğŸ¤– Starting Autonomous Research System with 8 Core Innovations")
        logger.info("=" * 80)
        logger.info(f"Request: {request}")
        logger.info(f"Primary LLM: {self.config.llm.primary_model}")
        logger.info(f"Planning Model: {self.config.llm.planning_model}")
        logger.info(f"Reasoning Model: {self.config.llm.reasoning_model}")
        logger.info(f"Verification Model: {self.config.llm.verification_model}")
        logger.info(f"Self-planning: {self.config.agent.enable_self_planning}")
        logger.info(f"Agent Communication: {self.config.agent.enable_agent_communication}")
        logger.info(f"MCP Enabled: {self.config.mcp.enabled}")
        logger.info(f"Streaming Pipeline: {streaming}")
        logger.info(f"Adaptive Supervisor: {self.config.agent.max_concurrent_research_units}")
        logger.info(f"Hierarchical Compression: {self.config.compression.enabled}")
        logger.info(f"Continuous Verification: {self.config.verification.enabled}")
        logger.info(f"Adaptive Context Window: {self.config.context_window.enabled}")
        logger.info("=" * 80)
        
        try:
            # Start health monitoring
            await self.health_monitor.start_monitoring()
            
            # Initialize MCP client if enabled
            if self.config.mcp.enabled:
                await self.mcp_manager.start_mcp_client()
            
            # Run research with production-grade reliability
            if streaming:
                result = await self._run_streaming_research(request)
            else:
                result = await self.orchestrator.run_research(request)
            
            # Apply hierarchical compression if enabled
            if self.config.compression.enabled:
                result = await self._apply_hierarchical_compression(result)
            
            # Save results with incremental save
            if output_path:
                await self._save_results_incrementally(result, output_path)
            else:
                self._display_results(result)
            
            # Get final health status
            health_status = self.health_monitor.get_system_health()
            result['system_health'] = health_status
            
            logger.info("âœ… Research completed successfully with 8 Core Innovations")
            return result
            
        except Exception as e:
            logger.error(f"Research failed: {e}")
            # Get error health status
            error_health = self.health_monitor.get_system_health()
            logger.error(f"System health at failure: {error_health}")
            raise
    
    async def _run_streaming_research(self, request: str) -> Dict[str, Any]:
        """Run research with streaming pipeline (Innovation 5)."""
        logger.info("ğŸŒŠ Starting streaming research pipeline...")
        
        # Create streaming callback
        async def streaming_callback(partial_result: Dict[str, Any]):
            logger.info(f"ğŸ“Š Streaming partial result: {partial_result.get('type', 'unknown')}")
            # In a real implementation, this would send to web interface
            print(f"ğŸ“Š Partial Result: {partial_result.get('summary', 'Processing...')}")
        
        # Run with streaming
        result = await self.orchestrator.run_research_with_streaming(
            request=request,
            streaming_callback=streaming_callback
        )
        
        logger.info("âœ… Streaming research completed")
        return result
    
    async def _apply_hierarchical_compression(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """Apply hierarchical compression (Innovation 2)."""
        if not self.config.compression.enabled:
            return result
        
        logger.info("ğŸ—œï¸ Applying hierarchical compression...")
        
        # Import compression module
        from src.core.compression import compress_data
        
        # Compress large text fields
        if 'synthesis_results' in result:
            compressed_synthesis = await compress_data(
                result['synthesis_results']
            )
            result['synthesis_results_compressed'] = compressed_synthesis
        
        logger.info("âœ… Hierarchical compression applied")
        return result
    
    async def _save_results_incrementally(self, result: Dict[str, Any], output_path: str):
        """Save results with incremental save (Innovation 5)."""
        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)
        
        # Save incrementally
        temp_file = output_file.with_suffix('.tmp')
        
        with open(temp_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
        
        # Atomic move
        temp_file.replace(output_file)
        
        logger.info(f"âœ… Results saved incrementally to: {output_file}")
    
    def _display_results(self, result: Dict[str, Any]):
        """Display results with enhanced formatting."""
        print("\nğŸ“‹ Research Results with 8 Core Innovations:")
        print("=" * 80)
        
        # Display main research content
        if 'content' in result and result['content']:
            print("\nğŸ“ Research Content:")
            print("-" * 60)
            print(result['content'])
            print("-" * 60)
        elif 'synthesis_results' in result:
            synthesis = result['synthesis_results']
            if isinstance(synthesis, dict) and 'content' in synthesis:
                print("\nğŸ“ Research Content:")
                print("-" * 60)
                print(synthesis['content'])
                print("-" * 60)
            else:
                print(f"\nğŸ“ Synthesis: {synthesis}")
        else:
            print("\nâŒ No research content found in results")
        
        # Display research metadata
        if 'metadata' in result:
            metadata = result['metadata']
            print(f"\nğŸ“Š Research Metadata:")
            print(f"  â€¢ Model Used: {metadata.get('model_used', 'N/A')}")
            print(f"  â€¢ Execution Time: {metadata.get('execution_time', 'N/A'):.2f}s")
            print(f"  â€¢ Cost: ${metadata.get('cost', 0):.4f}")
            print(f"  â€¢ Confidence: {metadata.get('confidence', 'N/A')}")
        
        # Display synthesis results
        if 'synthesis_results' in result and isinstance(result['synthesis_results'], dict):
            synthesis = result['synthesis_results']
            if 'synthesis_results' in synthesis:
                print(f"\nğŸ“ Synthesis: {synthesis.get('synthesis_results', 'N/A')}")
        
        # Display innovation stats
        if 'innovation_stats' in result:
            stats = result['innovation_stats']
            print(f"\nğŸš€ Innovation Statistics:")
            print(f"  â€¢ Adaptive Supervisor: {stats.get('adaptive_supervisor', 'N/A')}")
            print(f"  â€¢ Hierarchical Compression: {stats.get('hierarchical_compression', 'N/A')}")
            print(f"  â€¢ Multi-Model Orchestration: {stats.get('multi_model_orchestration', 'N/A')}")
            print(f"  â€¢ Continuous Verification: {stats.get('continuous_verification', 'N/A')}")
            print(f"  â€¢ Streaming Pipeline: {stats.get('streaming_pipeline', 'N/A')}")
            print(f"  â€¢ Universal MCP Hub: {stats.get('universal_mcp_hub', 'N/A')}")
            print(f"  â€¢ Adaptive Context Window: {stats.get('adaptive_context_window', 'N/A')}")
            print(f"  â€¢ Production-Grade Reliability: {stats.get('production_grade_reliability', 'N/A')}")
        
        # Display system health
        if 'system_health' in result:
            health = result['system_health']
            print(f"\nğŸ¥ System Health: {health.get('overall_status', 'Unknown')}")
            print(f"  â€¢ Health Score: {health.get('health_score', 'N/A')}")
            print(f"  â€¢ Monitoring Active: {health.get('monitoring_active', 'N/A')}")
        
        print("=" * 80)
    
    async def run_mcp_server(self):
        """MCP ì„œë²„ ì‹¤í–‰"""
        await self.mcp_manager.start_mcp_server()
    
    async def run_mcp_client(self):
        """MCP í´ë¼ì´ì–¸íŠ¸ ì‹¤í–‰"""
        await self.mcp_manager.start_mcp_client()
    
    def run_web_app(self):
        """ì›¹ ì•± ì‹¤í–‰"""
        return self.web_manager.start_web_app()
    
    async def run_health_check(self):
        """Run comprehensive health check for all system components."""
        logger.info("ğŸ¥ Running comprehensive health check...")
        
        # Check MCP tools health
        if self.config.mcp.enabled:
            mcp_health = await self.mcp_manager.get_tool_health_status()
            logger.info(f"MCP Tools Health: {mcp_health['healthy_tools']}/{mcp_health['total_tools']} healthy")
            
            for tool, health in mcp_health['tool_details'].items():
                status_icon = "âœ…" if health['status'] == 'healthy' else "âŒ"
                logger.info(f"  {status_icon} {tool}: {health['success_rate']:.1%} success rate")
        
        # Check system health
        system_health = self.health_monitor.get_system_health()
        logger.info(f"System Health: {system_health.get('overall_status', 'Unknown')}")
        
        # Check web app health
        web_health = await self.web_manager.get_web_app_health()
        logger.info(f"Web App Health: {web_health.get('status', 'Unknown')}")
        
        logger.info("âœ… Health check completed")


async def main():
    """Main function - 8ê°€ì§€ í•µì‹¬ í˜ì‹  í†µí•© ì‹¤í–‰ ì§„ì…ì """
    parser = argparse.ArgumentParser(
        description="Autonomous Multi-Agent Research System with 8 Core Innovations",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python main.py --request "ì¸ê³µì§€ëŠ¥ì˜ ë¯¸ë˜ ì „ë§"
  python main.py --request "ì—°êµ¬ ì£¼ì œ" --output results/report.json
  python main.py --request "ì—°êµ¬ ì£¼ì œ" --streaming
  python main.py --web
  python main.py --mcp-server
  python main.py --mcp-client
  python main.py --health-check
        """
    )
    
    # Mode selection
    mode_group = parser.add_mutually_exclusive_group(required=True)
    mode_group.add_argument("--request", help="Research request (CLI mode)")
    mode_group.add_argument("--web", action="store_true", help="Start web application with streaming")
    mode_group.add_argument("--mcp-server", action="store_true", help="Start MCP server with Universal MCP Hub")
    mode_group.add_argument("--mcp-client", action="store_true", help="Start MCP client with Smart Tool Selection")
    mode_group.add_argument("--health-check", action="store_true", help="Check system health and MCP tools")
    
    # Optional arguments
    parser.add_argument("--output", help="Output file path for research results")
    parser.add_argument("--config", help="Configuration file path")
    parser.add_argument("--streaming", action="store_true", help="Enable streaming pipeline for real-time results")
    parser.add_argument("--verbose", "-v", action="store_true", help="Enable verbose logging")
    
    args = parser.parse_args()
    
    # Set logging level
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # Create logs directory
    logs_dir = project_root / "logs"
    logs_dir.mkdir(exist_ok=True)
    
    # Initialize system
    system = AutonomousResearchSystem()
    
    try:
        if args.request:
            # CLI Research Mode with 8 innovations
            await system.run_research(
                args.request, 
                args.output, 
                streaming=args.streaming
            )
            
        elif args.web:
            # Web Application Mode with Streaming Pipeline
            system.run_web_app()
            
        elif args.mcp_server:
            # MCP Server Mode with Universal MCP Hub
            success = await system.run_mcp_server()
            if not success:
                sys.exit(1)
            
        elif args.mcp_client:
            # MCP Client Mode with Smart Tool Selection
            success = await system.run_mcp_client()
            if not success:
                sys.exit(1)
            
        elif args.health_check:
            # Health Check Mode
            await system.run_health_check()
            
    except KeyboardInterrupt:
        logger.info("Operation cancelled by user")
        await system._graceful_shutdown()
        sys.exit(0)
    except Exception as e:
        logger.error(f"Error: {e}")
        await system._graceful_shutdown()
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())