"""
Agent Orchestrator for Multi-Agent System

LangGraph ê¸°ë°˜ ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì‹œìŠ¤í…œ
4ëŒ€ í•µì‹¬ ì—ì´ì „íŠ¸ë¥¼ ì¡°ìœ¨í•˜ì—¬ í˜‘ì—… ì›Œí¬í”Œë¡œìš° êµ¬ì¶•
"""

import asyncio
import logging
from typing import Dict, Any, List, Optional, Literal, Annotated
from datetime import datetime
from dataclasses import dataclass, field
import operator

from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from pydantic import BaseModel, Field
from typing_extensions import TypedDict

from src.core.shared_memory import get_shared_memory, MemoryScope
from src.core.skills_manager import get_skill_manager
from src.core.skills_selector import get_skill_selector, SkillMatch
from src.core.skills_loader import Skill
from src.core.agent_result_sharing import SharedResultsManager, AgentDiscussionManager
from src.core.researcher_config import get_agent_config

logger = logging.getLogger(__name__)

# Loggerê°€ handlerê°€ ì—†ìœ¼ë©´ root loggerì˜ handler ì‚¬ìš©
if not logger.handlers:
    logger.setLevel(logging.INFO)
    # Root loggerì˜ handler ì‚¬ìš© (main.pyì—ì„œ ì„¤ì •ëœ handler)
    parent_logger = logging.getLogger()
    if parent_logger.handlers:
        logger.handlers = parent_logger.handlers
        logger.propagate = True
    else:
        # Fallback: ê¸°ë³¸ handler ì„¤ì •
        handler = logging.StreamHandler()
        handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
        logger.addHandler(handler)
        logger.setLevel(logging.INFO)


###################
# State Definitions
###################

def override_reducer(current_value, new_value):
    """Reducer function that allows overriding values in state."""
    if isinstance(new_value, dict) and new_value.get("type") == "override":
        return new_value.get("value", new_value)
    else:
        return operator.add(current_value, new_value)


class AgentState(TypedDict):
    """Main agent state containing messages and research data."""
    
    messages: Annotated[list, add_messages]
    user_query: str
    research_plan: Optional[str]
    research_results: Annotated[list, override_reducer]  # Changed: supports both dict and str
    verified_results: Annotated[list, override_reducer]  # Changed: supports both dict and str
    final_report: Optional[str]
    current_agent: Optional[str]
    iteration: int
    session_id: Optional[str]
    research_failed: bool
    verification_failed: bool
    report_failed: bool
    error: Optional[str]


###################
# Agent Definitions
###################

@dataclass
class AgentContext:
    """Agent execution context."""
    agent_id: str
    session_id: str
    shared_memory: Any
    config: Any = None
    shared_results_manager: Optional[SharedResultsManager] = None
    discussion_manager: Optional[AgentDiscussionManager] = None


class PlannerAgent:
    """Planner agent - creates research plans (Skills-based)."""
    
    def __init__(self, context: AgentContext, skill: Optional[Skill] = None):
        self.context = context
        self.name = "planner"
        self.skill = skill
        
        # Skillì´ ì—†ìœ¼ë©´ ë¡œë“œ ì‹œë„
        if self.skill is None:
            skill_manager = get_skill_manager()
            self.skill = skill_manager.load_skill("research_planner")
        
        # Skill instruction ì‚¬ìš©
        if self.skill:
            self.instruction = self.skill.instructions
        else:
            self.instruction = "You are a research planning agent."
    
    async def execute(self, state: AgentState) -> AgentState:
        """Execute planning task with Skills-based instruction and detailed logging."""
        logger.info(f"=" * 80)
        logger.info(f"[{self.name.upper()}] Starting research planning")
        logger.info(f"Query: {state['user_query']}")
        logger.info(f"Session: {state['session_id']}")
        logger.info(f"=" * 80)
        
        # Read from shared memory
        memory = self.context.shared_memory
        previous_plans = memory.search(state['user_query'], limit=3)
        
        logger.info(f"[{self.name}] Previous plans found: {len(previous_plans) if previous_plans else 0}")
        
        # Skills-based instruction ì‚¬ìš©
        instruction = self.instruction if self.skill else "You are a research planning agent."
        
        logger.info(f"[{self.name}] Using skill: {self.skill is not None}")
        
        # LLM í˜¸ì¶œì€ llm_managerë¥¼ í†µí•´ Gemini ì§ê²° ì‚¬ìš©
        from src.core.llm_manager import execute_llm_task, TaskType
        
        # Use Skills instruction
        prompt = f"""{instruction}

Task: Create a detailed research plan for: {state['user_query']}

Based on previous research:
{previous_plans if previous_plans else "No previous research found"}

Create a comprehensive research plan with:
1. Research objectives
2. Key areas to investigate
3. Expected sources and methods
4. Success criteria

Keep it concise and actionable (max 300 words)."""

        logger.info(f"[{self.name}] Calling LLM for planning...")
        # Gemini ì‹¤í–‰
        model_result = await execute_llm_task(
            prompt=prompt,
            task_type=TaskType.PLANNING,
            model_name=None,
            system_message=None
        )
        plan = model_result.content or 'No plan generated'
        
        logger.info(f"[{self.name}] âœ… Plan generated: {len(plan)} characters")
        logger.info(f"[{self.name}] Plan preview: {plan[:200]}...")
        
        state['research_plan'] = plan
        state['current_agent'] = self.name
        
        # Write to shared memory
        memory.write(
            key=f"plan_{state['session_id']}",
            value=plan,
            scope=MemoryScope.SESSION,
            session_id=state['session_id'],
            agent_id=self.name
        )
        
        logger.info(f"[{self.name}] Plan saved to shared memory")
        logger.info(f"=" * 80)
        
        return state


class ExecutorAgent:
    """Executor agent - executes research tasks using tools (Skills-based)."""
    
    def __init__(self, context: AgentContext, skill: Optional[Skill] = None):
        self.context = context
        self.name = "executor"
        self.skill = skill
        
        # Skillì´ ì—†ìœ¼ë©´ ë¡œë“œ ì‹œë„
        if self.skill is None:
            skill_manager = get_skill_manager()
            self.skill = skill_manager.load_skill("research_executor")
        
        # Skill instruction ì‚¬ìš©
        if self.skill:
            self.instruction = self.skill.instructions
        else:
            self.instruction = "You are a research execution agent."
    
    async def execute(self, state: AgentState) -> AgentState:
        """Execute research tasks with detailed logging."""
        logger.info(f"=" * 80)
        logger.info(f"[{self.name.upper()}] Starting research execution")
        logger.info(f"Query: {state['user_query']}")
        logger.info(f"Session: {state['session_id']}")
        logger.info(f"=" * 80)
        
        # Read plan from shared memory
        memory = self.context.shared_memory
        plan = memory.read(
            key=f"plan_{state['session_id']}",
            scope=MemoryScope.SESSION,
            session_id=state['session_id']
        )
        
        logger.info(f"[{self.name}] Research plan loaded: {plan is not None}")
        if plan:
            logger.info(f"[{self.name}] Plan preview: {plan[:200]}...")
        
        # ì‹¤ì œ ì—°êµ¬ ì‹¤í–‰ - MCP Hubë¥¼ í†µí•œ ë³‘ë ¬ ê²€ìƒ‰ ìˆ˜í–‰
        query = state['user_query']
        results = []
        
        try:
            # MCP Hub ì´ˆê¸°í™” í™•ì¸
            from src.core.mcp_integration import get_mcp_hub, execute_tool, ToolCategory
            
            hub = get_mcp_hub()
            logger.info(f"[{self.name}] MCP Hub status: {len(hub.mcp_sessions) if hub.mcp_sessions else 0} servers connected")
            
            if not hub.mcp_sessions:
                logger.info(f"[{self.name}] Initializing MCP Hub...")
                await hub.initialize_mcp()
                logger.info(f"[{self.name}] MCP Hub initialized: {len(hub.mcp_sessions)} servers")
            
            # ì—°êµ¬ ê³„íšì—ì„œ ì—¬ëŸ¬ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± (LLM ê¸°ë°˜, í•˜ë“œì½”ë”© ì œê±°)
            from src.core.llm_manager import execute_llm_task, TaskType
            
            search_queries = [query]  # ê¸°ë³¸ ì¿¼ë¦¬
            if plan:
                # LLMìœ¼ë¡œ ì—°êµ¬ ê³„íšì—ì„œ ê²€ìƒ‰ ì¿¼ë¦¬ ì¶”ì¶œ
                query_generation_prompt = f"""ì—°êµ¬ ê³„íš:
{plan}

ì›ë˜ ì§ˆë¬¸: {query}

ìœ„ ì—°êµ¬ ê³„íšì„ ë°”íƒ•ìœ¼ë¡œ ê²€ìƒ‰ì— ì‚¬ìš©í•  êµ¬ì²´ì ì¸ ê²€ìƒ‰ ì¿¼ë¦¬ 3-5ê°œë¥¼ ìƒì„±í•˜ì„¸ìš”.
ê° ì¿¼ë¦¬ëŠ” ì„œë¡œ ë‹¤ë¥¸ ê´€ì ì´ë‚˜ ì¸¡ë©´ì„ ë‹¤ë£¨ì–´ì•¼ í•©ë‹ˆë‹¤.
ì‘ë‹µ í˜•ì‹: ê° ì¤„ì— í•˜ë‚˜ì˜ ê²€ìƒ‰ ì¿¼ë¦¬ë§Œ ì‘ì„±í•˜ì„¸ìš”. ë²ˆí˜¸ë‚˜ ê¸°í˜¸ ì—†ì´ ì¿¼ë¦¬ë§Œ ì‘ì„±í•˜ì„¸ìš”."""
                
                try:
                    query_result = await execute_llm_task(
                        prompt=query_generation_prompt,
                        task_type=TaskType.PLANNING,
                        model_name=None,
                        system_message="You are a research query generator. Generate specific search queries based on research plans."
                    )
                    
                    generated_queries = query_result.content or ""
                    # ê° ì¤„ì„ ì¿¼ë¦¬ë¡œ íŒŒì‹±
                    for line in generated_queries.split('\n'):
                        line = line.strip()
                        if line and not line.startswith('#') and len(line) > 5:
                            search_queries.append(line)
                    
                    # ì¤‘ë³µ ì œê±°
                    search_queries = list(dict.fromkeys(search_queries))[:5]  # ìµœëŒ€ 5ê°œ
                    logger.info(f"[{self.name}] Generated {len(search_queries)} search queries from plan")
                except Exception as e:
                    logger.warning(f"[{self.name}] Failed to generate search queries from plan: {e}, using original query only")
            
            # ë³‘ë ¬ ê²€ìƒ‰ ì‹¤í–‰
            logger.info(f"[{self.name}] Executing {len(search_queries)} searches in parallel...")
            
            async def execute_single_search(search_query: str, query_index: int) -> Dict[str, Any]:
                """ë‹¨ì¼ ê²€ìƒ‰ ì‹¤í–‰."""
                try:
                    logger.info(f"[{self.name}] Search {query_index + 1}/{len(search_queries)}: '{search_query}'")
                    search_result = await execute_tool(
                        "g-search",
                        {"query": search_query, "max_results": 10}
                    )
                    return {
                        "query": search_query,
                        "index": query_index,
                        "result": search_result,
                        "success": search_result.get('success', False)
                    }
                except Exception as e:
                    logger.error(f"[{self.name}] Search {query_index + 1} failed: {e}")
                    return {
                        "query": search_query,
                        "index": query_index,
                        "result": {"success": False, "error": str(e)},
                        "success": False
                    }
            
            # ëª¨ë“  ê²€ìƒ‰ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰
            search_tasks = [execute_single_search(q, i) for i, q in enumerate(search_queries)]
            search_results_list = await asyncio.gather(*search_tasks)
            
            logger.info(f"[{self.name}] âœ… Completed {len(search_results_list)} parallel searches")
            
            # ëª¨ë“  ì„±ê³µí•œ ê²€ìƒ‰ ê²°ê³¼ í†µí•©
            successful_results = [sr for sr in search_results_list if sr.get('success') and sr.get('result', {}).get('data')]
            
            if not successful_results:
                error_msg = f"ì—°êµ¬ ì‹¤í–‰ ì‹¤íŒ¨: ëª¨ë“  ê²€ìƒ‰ ì¿¼ë¦¬ ì‹¤í–‰ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
                logger.error(f"[{self.name}] âŒ {error_msg}")
                raise RuntimeError(error_msg)
            
            # ëª¨ë“  ê²€ìƒ‰ ê²°ê³¼ë¥¼ í†µí•© (í•˜ë“œì½”ë”© ì œê±°, ë™ì  í†µí•©)
            all_search_data = []
            for sr in successful_results:
                result_data = sr['result'].get('data', {})
                if isinstance(result_data, dict):
                    items = result_data.get('results', result_data.get('items', []))
                    if isinstance(items, list):
                        all_search_data.extend(items)
                elif isinstance(result_data, list):
                    all_search_data.extend(result_data)
            
            # í†µí•©ëœ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ê²€ìƒ‰ ê²°ê³¼ í˜•ì‹ìœ¼ë¡œ êµ¬ì„±
            search_result = {
                'success': True,
                'data': {
                    'results': all_search_data,
                    'total_results': len(all_search_data),
                    'source': 'parallel_search'
                }
            }
            
            logger.info(f"[{self.name}] âœ… Integrated {len(all_search_data)} results from {len(successful_results)} successful searches")
            
            # ëª¨ë“  ê²€ìƒ‰ ê²°ê³¼ë¥¼ SharedResultsManagerì— ê³µìœ 
            if self.context.shared_results_manager:
                for sr in search_results_list:
                    if sr.get('success'):
                        task_id = f"search_{sr['index']}"
                        await self.context.shared_results_manager.share_result(
                            task_id=task_id,
                            agent_id=self.name,
                            result=sr['result'],
                            metadata={"query": sr['query'], "index": sr['index']},
                            confidence=1.0 if sr.get('success') else 0.0
                        )
                        logger.info(f"[{self.name}] Shared search result for query: '{sr['query']}'")
            
            logger.info(f"[{self.name}] Search completed: success={search_result.get('success')}, total_results={search_result.get('data', {}).get('total_results', 0)}")
            logger.info(f"[{self.name}] Search result type: {type(search_result)}, keys: {list(search_result.keys()) if isinstance(search_result, dict) else 'N/A'}")
            
            if search_result.get('success') and search_result.get('data'):
                data = search_result.get('data', {})
                logger.info(f"[{self.name}] Data type: {type(data)}, keys: {list(data.keys()) if isinstance(data, dict) else 'N/A'}")
                
                # ê²€ìƒ‰ ê²°ê³¼ íŒŒì‹± - ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›
                search_results = []
                if isinstance(data, dict):
                    # í‘œì¤€ í˜•ì‹: {"query": "...", "results": [...], "total_results": N, "source": "..."}
                    search_results = data.get('results', [])
                    logger.info(f"[{self.name}] Found 'results' key: {len(search_results)} items")
                    
                    if not search_results:
                        # ë‹¤ë¥¸ í‚¤ ì‹œë„
                        search_results = data.get('items', data.get('data', []))
                        logger.info(f"[{self.name}] Tried 'items' or 'data' keys: {len(search_results)} items")
                    
                    # data ìì²´ê°€ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° (ì¤‘ì²©ëœ ê²½ìš°)
                    if not search_results and isinstance(data, dict):
                        # dataì˜ ê°’ ì¤‘ ë¦¬ìŠ¤íŠ¸ ì°¾ê¸°
                        for key, value in data.items():
                            if isinstance(value, list) and len(value) > 0:
                                # ì²« ë²ˆì§¸ í•­ëª©ì´ dictì¸ì§€ í™•ì¸
                                if value and isinstance(value[0], dict):
                                    search_results = value
                                    logger.info(f"[{self.name}] Found list in key '{key}': {len(search_results)} items")
                                    break
                elif isinstance(data, list):
                    search_results = data
                    logger.info(f"[{self.name}] Data is directly a list: {len(search_results)} items")
                
                logger.info(f"[{self.name}] âœ… Parsed {len(search_results)} search results")
                
                # ë””ë²„ê¹…: ì²« ë²ˆì§¸ ê²°ê³¼ ìƒ˜í”Œ ì¶œë ¥
                if search_results and len(search_results) > 0:
                    first_result = search_results[0]
                    logger.info(f"[{self.name}] First result type: {type(first_result)}, sample: {str(first_result)[:200]}")
                
                if search_results and len(search_results) > 0:
                    # ì‹¤ì œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ êµ¬ì¡°í™”ëœ í˜•ì‹ìœ¼ë¡œ ì €ì¥
                    unique_results = []
                    seen_urls = set()
                    
                    logger.info(f"[{self.name}] Processing {len(search_results)} results...")
                    
                    for i, result in enumerate(search_results, 1):
                        # ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›
                        if isinstance(result, dict):
                            title = result.get('title', result.get('name', result.get('Title', 'No title')))
                            snippet = result.get('snippet', result.get('content', result.get('summary', result.get('description', result.get('abstract', '')))))
                            url = result.get('url', result.get('link', result.get('href', result.get('URL', ''))))
                            
                            # snippetì— ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ì—¬ëŸ¬ ê²°ê³¼ê°€ ë“¤ì–´ìˆëŠ” ê²½ìš° íŒŒì‹±
                            if snippet and ("Found" in snippet or "search results" in snippet.lower() or "\n1." in snippet):
                                logger.info(f"[{self.name}] Detected markdown format in snippet, parsing...")
                                import re
                                parsed_results = []
                                lines = snippet.split('\n')
                                current_result = None
                                
                                for line in lines:
                                    original_line = line
                                    line = line.strip()
                                    if not line:
                                        continue
                                    
                                    # íŒ¨í„´ 1: ë§ˆí¬ë‹¤ìš´ ë§í¬ "1. [Title](URL)"
                                    link_match = re.match(r'^\d+\.\s*\[([^\]]+)\]\(([^\)]+)\)', line)
                                    # íŒ¨í„´ 2: ë²ˆí˜¸ì™€ ì œëª©ë§Œ "1. [Title]" ë˜ëŠ” "1. Title"
                                    title_match = re.match(r'^\d+\.\s*(?:\[([^\]]+)\]|(.+?))(?:\s*$|:)', line)
                                    # íŒ¨í„´ 3: URL ì¤„ "   URL: https://..."
                                    url_match = re.search(r'URL:\s*(https?://[^\s]+)', line, re.IGNORECASE)
                                    # íŒ¨í„´ 4: Summary ì¤„ "   Summary: ..."
                                    summary_match = re.search(r'Summary:\s*(.+)$', line, re.IGNORECASE)
                                    
                                    if link_match:
                                        # ì´ì „ ê²°ê³¼ ì €ì¥
                                        if current_result and current_result.get('title'):
                                            parsed_results.append(current_result)
                                        
                                        title_parsed = link_match.group(1)
                                        url_parsed = link_match.group(2)
                                        current_result = {
                                            "title": title_parsed,
                                            "url": url_parsed,
                                            "snippet": ""
                                        }
                                    elif title_match and not current_result:
                                        # ë²ˆí˜¸ì™€ ì œëª©ë§Œ ìˆëŠ” ê²½ìš° (ë‹¤ìŒ ì¤„ì— URLì´ ì˜¬ ê²ƒìœ¼ë¡œ ì˜ˆìƒ)
                                        title_parsed = title_match.group(1) or title_match.group(2)
                                        if title_parsed:
                                            current_result = {
                                                "title": title_parsed.strip(),
                                                "url": "",
                                                "snippet": ""
                                            }
                                    elif url_match:
                                        # URLì´ ë³„ë„ ì¤„ì— ìˆëŠ” ê²½ìš°
                                        if current_result:
                                            current_result["url"] = url_match.group(1)
                                        else:
                                            # URLë§Œ ìˆê³  ì œëª©ì´ ì—†ëŠ” ê²½ìš° (ì´ì „ ê²°ê³¼ì— ì¶”ê°€)
                                            if parsed_results:
                                                parsed_results[-1]["url"] = url_match.group(1)
                                    elif summary_match and current_result:
                                        # Summary ì¤„
                                        current_result["snippet"] = summary_match.group(1).strip()
                                    elif current_result and line and not any([
                                        line.startswith('URL:'), 
                                        line.startswith('Summary:'),
                                        line.startswith('Found'),
                                        'search results' in line.lower()
                                    ]):
                                        # ì„¤ëª… í…ìŠ¤íŠ¸ (ë“¤ì—¬ì“°ê¸°ëœ ê²½ìš°)
                                        if original_line.startswith('   ') or original_line.startswith('\t'):
                                            if current_result["snippet"]:
                                                current_result["snippet"] += " " + line
                                            else:
                                                current_result["snippet"] = line
                                
                                # ë§ˆì§€ë§‰ ê²°ê³¼ ì¶”ê°€
                                if current_result and current_result.get('title'):
                                    parsed_results.append(current_result)
                                
                                if parsed_results:
                                    logger.info(f"[{self.name}] Parsed {len(parsed_results)} results from markdown snippet")
                                    # íŒŒì‹±ëœ ê²°ê³¼ë“¤ì„ unique_resultsì— ì¶”ê°€
                                    for parsed_result in parsed_results:
                                        parsed_url = parsed_result.get('url', '')
                                        if parsed_url and parsed_url in seen_urls:
                                            continue
                                        if parsed_url:
                                            seen_urls.add(parsed_url)
                                        
                                        unique_results.append({
                                            "index": len(unique_results) + 1,
                                            "title": parsed_result.get('title', ''),
                                            "snippet": parsed_result.get('snippet', '')[:500],
                                            "url": parsed_url,
                                            "source": "search"
                                        })
                                        logger.info(f"[{self.name}] Parsed result: {parsed_result.get('title', '')[:50]}... (URL: {parsed_url[:50] if parsed_url else 'N/A'}...)")
                                    
                                    # ì›ë³¸ ê²°ê³¼ëŠ” ê±´ë„ˆë›°ê¸°
                                    continue
                            
                            logger.debug(f"[{self.name}] Result {i}: title={title[:50] if title else 'N/A'}, url={url[:50] if url else 'N/A'}")
                        elif isinstance(result, str):
                            # ë¬¸ìì—´ í˜•ì‹ì¸ ê²½ìš° íŒŒì‹± ì‹œë„ (ë§ˆí¬ë‹¤ìš´ ë§í¬ í˜•ì‹)
                            import re
                            link_match = re.match(r'^\d+\.\s*\[([^\]]+)\]\(([^\)]+)\)', result.strip())
                            if link_match:
                                title = link_match.group(1)
                                url = link_match.group(2)
                                snippet = ""
                                logger.info(f"[{self.name}] Parsed string result {i} as markdown: {title[:50]}")
                            else:
                                logger.warning(f"[{self.name}] Result {i} is string but not markdown format, skipping: {result[:100]}")
                                continue
                        else:
                            logger.warning(f"[{self.name}] Unknown result format for result {i}: {type(result)}, value: {str(result)[:100]}")
                            continue
                        
                        # URL ì¤‘ë³µ ì œê±°
                        if url and url in seen_urls:
                            logger.debug(f"[{self.name}] Duplicate URL skipped: {url}")
                            continue
                        if url:
                            seen_urls.add(url)
                        
                        # êµ¬ì¡°í™”ëœ ê²°ê³¼ ì €ì¥
                        result_dict = {
                            "index": len(unique_results) + 1,
                            "title": title,
                            "snippet": snippet[:500] if snippet else "",
                            "url": url,
                            "source": "search"
                        }
                        unique_results.append(result_dict)
                        
                        logger.info(f"[{self.name}] Result {i}: {title[:50]}... (URL: {url[:50] if url else 'N/A'}...)")
                    
                    # ê²°ê³¼ë¥¼ êµ¬ì¡°í™”ëœ í˜•ì‹ìœ¼ë¡œ ì €ì¥
                    if unique_results:
                        results = unique_results
                        logger.info(f"[{self.name}] âœ… Collected {len(results)} unique results")
                    else:
                        error_msg = f"ì—°êµ¬ ì‹¤í–‰ ì‹¤íŒ¨: ê²€ìƒ‰ ê²°ê³¼ë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                        logger.error(f"[{self.name}] âŒ {error_msg}")
                        raise RuntimeError(error_msg)
                else:
                    # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŒ - ì‹¤íŒ¨ ì²˜ë¦¬
                    error_msg = f"ì—°êµ¬ ì‹¤í–‰ ì‹¤íŒ¨: '{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    logger.error(f"[{self.name}] âŒ {error_msg}")
                    raise RuntimeError(error_msg)
            else:
                # ê²€ìƒ‰ ì‹¤íŒ¨ - ì—ëŸ¬ ë°˜í™˜
                error_msg = f"ì—°êµ¬ ì‹¤í–‰ ì‹¤íŒ¨: ê²€ìƒ‰ ë„êµ¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. {search_result.get('error', 'Unknown error')}"
                logger.error(f"[{self.name}] âŒ {error_msg}")
                raise RuntimeError(error_msg)
                
        except Exception as e:
            # ì‹¤ì œ ì˜¤ë¥˜ ë°œìƒ - ì‹¤íŒ¨ ì²˜ë¦¬
            error_msg = f"ì—°êµ¬ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}"
            logger.error(error_msg)
            
            # ì‹¤íŒ¨ ìƒíƒœ ê¸°ë¡
            state['research_results'] = []
            state['current_agent'] = self.name
            state['error'] = error_msg
            state['research_failed'] = True
            
            # ë©”ëª¨ë¦¬ì— ì‹¤íŒ¨ ì •ë³´ ê¸°ë¡
            memory.write(
                key=f"execution_error_{state['session_id']}",
                value=error_msg,
                scope=MemoryScope.SESSION,
                session_id=state['session_id'],
                agent_id=self.name
            )
            
            # ì‹¤íŒ¨ ìƒíƒœ ë°˜í™˜ (ë”ë¯¸ ë°ì´í„° ì—†ì´)
            return state
        
        # ì„±ê³µì ìœ¼ë¡œ ê²°ê³¼ ìˆ˜ì§‘ëœ ê²½ìš°
        state['research_results'] = results  # ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥ (ë®ì–´ì“°ê¸°)
        state['current_agent'] = self.name
        state['research_failed'] = False
        
        logger.info(f"[{self.name}] âœ… Research execution completed: {len(results)} results")
        
        # Write to shared memory (êµ¬ì¡°í™”ëœ í˜•ì‹)
        memory.write(
            key=f"research_results_{state['session_id']}",
            value=results,
            scope=MemoryScope.SESSION,
            session_id=state['session_id'],
            agent_id=self.name
        )
        
        logger.info(f"[{self.name}] Results saved to shared memory")
        logger.info(f"=" * 80)
        
        return state


class VerifierAgent:
    """Verifier agent - verifies research results (Skills-based)."""
    
    def __init__(self, context: AgentContext, skill: Optional[Skill] = None):
        self.context = context
        self.name = "verifier"
        self.skill = skill
        
        # Skillì´ ì—†ìœ¼ë©´ ë¡œë“œ ì‹œë„
        if self.skill is None:
            skill_manager = get_skill_manager()
            self.skill = skill_manager.load_skill("evaluator")
        
        # Skill instruction ì‚¬ìš©
        if self.skill:
            self.instruction = self.skill.instructions
        else:
            self.instruction = "You are a verification agent."
    
    async def execute(self, state: AgentState) -> AgentState:
        """Verify research results with LLM-based verification."""
        logger.info(f"=" * 80)
        logger.info(f"[{self.name.upper()}] Starting verification")
        logger.info(f"=" * 80)
        
        # ì—°êµ¬ ì‹¤íŒ¨ í™•ì¸
        if state.get('research_failed'):
            logger.error(f"[{self.name}] âŒ Research execution failed, skipping verification")
            state['verified_results'] = []
            state['verification_failed'] = True
            state['current_agent'] = self.name
            return state
        
        memory = self.context.shared_memory
        
        # Read results from state or shared memory
        results = state.get('research_results', [])
        if not results:
            results = memory.read(
                key=f"research_results_{state['session_id']}",
                scope=MemoryScope.SESSION,
                session_id=state['session_id']
            ) or []
        
        # SharedResultsManagerì—ì„œ ë‹¤ë¥¸ Executorì˜ ê²°ê³¼ë„ ê°€ì ¸ì˜¤ê¸°
        if self.context.shared_results_manager:
            shared_results = await self.context.shared_results_manager.get_shared_results(
                exclude_agent_id=self.name
            )
            logger.info(f"[{self.name}] Found {len(shared_results)} shared results from other agents")
            
            # ê³µìœ ëœ ê²°ê³¼ë¥¼ resultsì— ì¶”ê°€
            for shared_result in shared_results:
                if isinstance(shared_result.result, dict) and shared_result.result.get('data'):
                    # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ êµ¬ì¡°í™”ëœ ë°ì´í„° ì¶”ì¶œ
                    data = shared_result.result.get('data', {})
                    if isinstance(data, dict):
                        shared_search_results = data.get('results', data.get('items', []))
                        if isinstance(shared_search_results, list):
                            results.extend(shared_search_results)
                    elif isinstance(data, list):
                        results.extend(data)
        
        logger.info(f"[{self.name}] Found {len(results)} results to verify (including shared results)")
        
        if not results or len(results) == 0:
            error_msg = "ê²€ì¦ ì‹¤íŒ¨: ê²€ì¦í•  ì—°êµ¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
            logger.error(f"[{self.name}] âŒ {error_msg}")
            state['verified_results'] = []
            state['verification_failed'] = True
            state['error'] = error_msg
            state['current_agent'] = self.name
            return state
        
        # LLMì„ ì‚¬ìš©í•œ ì‹¤ì œ ê²€ì¦
        from src.core.llm_manager import execute_llm_task, TaskType
        
        verified = []
        for i, result in enumerate(results, 1):
            if isinstance(result, dict):
                title = result.get('title', '')
                snippet = result.get('snippet', '')
                url = result.get('url', '')
                
                # LLMìœ¼ë¡œ ê²€ì¦
                verification_prompt = f"""ë‹¤ìŒ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê²€ì¦í•˜ì„¸ìš”:

ì œëª©: {title}
ë‚´ìš©: {snippet[:300]}
URL: {url}

ì›ë˜ ì¿¼ë¦¬: {state['user_query']}

ì´ ê²°ê³¼ê°€ ì¿¼ë¦¬ì™€ ê´€ë ¨ì´ ìˆê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ”ì§€ ê²€ì¦í•˜ì„¸ìš”.
ì‘ë‹µ í˜•ì‹: "VERIFIED" ë˜ëŠ” "REJECTED"ì™€ ê°„ë‹¨í•œ ì´ìœ ë¥¼ í•œ ì¤„ë¡œ ì‘ì„±í•˜ì„¸ìš”."""
                
                try:
                    verification_result = await execute_llm_task(
                        prompt=verification_prompt,
                        task_type=TaskType.VERIFICATION,
                        model_name=None,
                        system_message="You are a verification agent. Verify if search results are relevant and reliable."
                    )
                    
                    verification_text = verification_result.content or "UNKNOWN"
                    is_verified = "VERIFIED" in verification_text.upper() or "REJECT" not in verification_text.upper()
                    
                    if is_verified:
                        verified.append({
                            "index": i,
                            "title": title,
                            "snippet": snippet,
                            "url": url,
                            "status": "verified",
                            "verification_note": verification_text[:200]
                        })
                        logger.info(f"[{self.name}] âœ… Result {i} verified: {title[:50]}...")
                    else:
                        logger.info(f"[{self.name}] âš ï¸ Result {i} rejected: {title[:50]}...")
                        continue
                except Exception as e:
                    logger.warning(f"[{self.name}] Verification failed for result {i}: {e}, including anyway")
                    verified.append({
                        "index": i,
                        "title": title,
                        "snippet": snippet,
                        "url": url,
                        "status": "partial",
                        "verification_note": "Verification failed, but included"
                    })
            else:
                logger.warning(f"[{self.name}] Unknown result format: {type(result)}")
                continue
        
        logger.info(f"[{self.name}] âœ… Verification completed: {len(verified)}/{len(results)} results verified")
        
        # ê²€ì¦ ê²°ê³¼ë¥¼ SharedResultsManagerì— ê³µìœ 
        if self.context.shared_results_manager:
            for verified_result in verified:
                task_id = f"verification_{verified_result.get('index', 0)}"
                await self.context.shared_results_manager.share_result(
                    task_id=task_id,
                    agent_id=self.name,
                    result=verified_result,
                    metadata={"status": verified_result.get('status', 'unknown')},
                    confidence=1.0 if verified_result.get('status') == 'verified' else 0.5
                )
            
            # ë‹¤ë¥¸ ì—ì´ì „íŠ¸ì˜ ê²€ì¦ ê²°ê³¼ì™€ í† ë¡  (ê²€ì¦ ê²°ê³¼ê°€ ë‹¤ë¥¸ ê²½ìš°)
            if self.context.discussion_manager and len(verified) > 0:
                other_verified = await self.context.shared_results_manager.get_shared_results(
                    agent_id=None,  # ëª¨ë“  ì—ì´ì „íŠ¸
                    exclude_agent_id=self.name
                )
                
                # ê²€ì¦ëœ ê²°ê³¼ë§Œ í•„í„°ë§
                other_verified_results = [r for r in other_verified if isinstance(r.result, dict) and r.result.get('status') == 'verified']
                
                if other_verified_results:
                    # ì²« ë²ˆì§¸ ê²€ì¦ ê²°ê³¼ì— ëŒ€í•´ í† ë¡ 
                    first_verified = verified[0]
                    result_id = f"verification_{first_verified.get('index', 0)}"
                    discussion = await self.context.discussion_manager.agent_discuss_result(
                        result_id=result_id,
                        agent_id=self.name,
                        other_agent_results=other_verified_results[:3]  # ìµœëŒ€ 3ê°œ
                    )
                    if discussion:
                        logger.info(f"[{self.name}] Discussion completed: {discussion[:100]}...")
        
        state['verified_results'] = verified
        state['current_agent'] = self.name
        state['verification_failed'] = False if verified else True
        
        # Write to shared memory
        memory.write(
            key=f"verified_{state['session_id']}",
            value=verified,
            scope=MemoryScope.SESSION,
            session_id=state['session_id'],
            agent_id=self.name
        )
        
        logger.info(f"[{self.name}] Verified results saved to shared memory")
        logger.info(f"=" * 80)
        
        return state


class GeneratorAgent:
    """Generator agent - creates final report (Skills-based)."""
    
    def __init__(self, context: AgentContext, skill: Optional[Skill] = None):
        self.context = context
        self.name = "generator"
        self.skill = skill
        
        # Skillì´ ì—†ìœ¼ë©´ ë¡œë“œ ì‹œë„
        if self.skill is None:
            skill_manager = get_skill_manager()
            self.skill = skill_manager.load_skill("synthesizer")
        
        # Skill instruction ì‚¬ìš©
        if self.skill:
            self.instruction = self.skill.instructions
        else:
            self.instruction = "You are a report generation agent."
    
    async def execute(self, state: AgentState) -> AgentState:
        """Generate final report."""
        logger.info(f"[{self.name}] Generating final report...")
        
        # ì—°êµ¬ ë˜ëŠ” ê²€ì¦ ì‹¤íŒ¨ í™•ì¸ - Fallback ì œê±°, ëª…í™•í•œ ì—ëŸ¬ë§Œ ë°˜í™˜
        if state.get('research_failed') or state.get('verification_failed'):
            error_msg = state.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')
            logger.error(f"[{self.name}] âŒ Research or verification failed: {error_msg}")
            state['final_report'] = None
            state['current_agent'] = self.name
            state['report_failed'] = True
            state['error'] = error_msg
            return state
        
        memory = self.context.shared_memory
        
        # Read verified results from state or shared memory
        verified_results = state.get('verified_results', [])
        if not verified_results:
            verified_results = memory.read(
                key=f"verified_{state['session_id']}",
                scope=MemoryScope.SESSION,
                session_id=state['session_id']
            ) or []
        
        # SharedResultsManagerì—ì„œ ëª¨ë“  ê³µìœ ëœ ê²€ì¦ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
        if self.context.shared_results_manager:
            all_shared_results = await self.context.shared_results_manager.get_shared_results()
            logger.info(f"[{self.name}] Found {len(all_shared_results)} shared results from all agents")
            
            # ê²€ì¦ëœ ê²°ê³¼ë§Œ í•„í„°ë§í•˜ì—¬ ì¶”ê°€
            for shared_result in all_shared_results:
                if isinstance(shared_result.result, dict):
                    # ê²€ì¦ëœ ê²°ê³¼ì¸ ê²½ìš°
                    if shared_result.result.get('status') == 'verified':
                        # ì¤‘ë³µ ì œê±° (URL ê¸°ì¤€)
                        existing_urls = {r.get('url', '') for r in verified_results if isinstance(r, dict)}
                        result_url = shared_result.result.get('url', '')
                        if result_url and result_url not in existing_urls:
                            verified_results.append(shared_result.result)
                            logger.info(f"[{self.name}] Added shared verified result: {shared_result.result.get('title', '')[:50]}...")
        
        logger.info(f"[{self.name}] Found {len(verified_results)} verified results for report generation (including shared results)")
        
        if not verified_results or len(verified_results) == 0:
            # Fallback ì œê±° - ëª…í™•í•œ ì—ëŸ¬ë§Œ ë°˜í™˜
            error_msg = "ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: ê²€ì¦ëœ ì—°êµ¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
            logger.error(f"[{self.name}] âŒ {error_msg}")
            state['final_report'] = None
            state['current_agent'] = self.name
            state['report_failed'] = True
            state['error'] = error_msg
            return state
        
        # ì‹¤ì œ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš° LLMìœ¼ë¡œ ë³´ê³ ì„œ ìƒì„±
        logger.info(f"[{self.name}] Generating report with LLM from {len(verified_results)} verified results...")
        
        # ê²€ì¦ëœ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        verified_text = ""
        for result in verified_results:
            if isinstance(result, dict):
                verified_text += f"\n- {result.get('title', '')}: {result.get('snippet', '')[:200]}... (Source: {result.get('url', '')})\n"
            else:
                verified_text += f"\n- {str(result)}\n"
        
        # LLMìœ¼ë¡œ ì‚¬ìš©ì ìš”ì²­ì— ë§ëŠ” í˜•ì‹ìœ¼ë¡œ ìƒì„±
        from src.core.llm_manager import execute_llm_task, TaskType
        
        # ì‚¬ìš©ì ìš”ì²­ì„ ê·¸ëŒ€ë¡œ ì „ë‹¬ - LLMì´ í˜•ì‹ì„ ê²°ì •í•˜ë„ë¡
        generation_prompt = f"""ì‚¬ìš©ì ìš”ì²­: {state['user_query']}

ê²€ì¦ëœ ì—°êµ¬ ê²°ê³¼:
{verified_text}

ì‚¬ìš©ìì˜ ìš”ì²­ì„ ì •í™•íˆ ì´í•´í•˜ê³ , ìš”ì²­í•œ í˜•ì‹ì— ë§ê²Œ ê²°ê³¼ë¥¼ ìƒì„±í•˜ì„¸ìš”.
- ë³´ê³ ì„œë¥¼ ìš”ì²­í–ˆë‹¤ë©´ ë³´ê³ ì„œ í˜•ì‹ìœ¼ë¡œ
- ì½”ë“œë¥¼ ìš”ì²­í–ˆë‹¤ë©´ ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œë¡œ
- ë¬¸ì„œë¥¼ ìš”ì²­í–ˆë‹¤ë©´ ë¬¸ì„œ í˜•ì‹ìœ¼ë¡œ

ìš”ì²­ëœ í˜•ì‹ì— ë§ê²Œ ì™„ì „í•˜ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìƒì„±í•˜ì„¸ìš”."""

        try:
            report_result = await execute_llm_task(
                prompt=generation_prompt,
                task_type=TaskType.GENERATION,
                model_name=None,
                system_message="You are an expert assistant. Generate results in the exact format requested by the user. If they ask for a report, create a report. If they ask for code, create executable code. Follow the user's request precisely without adding unnecessary templates or structures."
            )
            
            report = report_result.content or f"# Report: {state['user_query']}\n\nNo report generated."
            
            # Safety filter ì°¨ë‹¨ í™•ì¸ - Fallback ì œê±°, ëª…í™•í•œ ì˜¤ë¥˜ ë°˜í™˜
            if "blocked by safety" in report.lower() or "content blocked" in report.lower() or len(report) < 100:
                error_msg = "ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: Safety filterì— ì˜í•´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ë¥¼ ìˆ˜ì •í•˜ê±°ë‚˜ ë‹¤ë¥¸ ëª¨ë¸ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”."
                logger.error(f"[{self.name}] âŒ {error_msg}")
                state['final_report'] = None
                state['report_failed'] = True
                state['error'] = error_msg
                state['current_agent'] = self.name
                return state
            else:
                logger.info(f"[{self.name}] âœ… Report generated: {len(report)} characters")
        except Exception as e:
            logger.error(f"[{self.name}] âŒ Report generation failed: {e}")
            # Fallback ì œê±° - ëª…í™•í•œ ì˜¤ë¥˜ ë°˜í™˜
            error_msg = f"ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {str(e)}"
            state['final_report'] = None
            state['report_failed'] = True
            state['error'] = error_msg
            state['current_agent'] = self.name
            return state
        
        state['final_report'] = report
        state['current_agent'] = self.name
        state['report_failed'] = False
        
        # Write to shared memory
        memory.write(
            key=f"report_{state['session_id']}",
            value=report,
            scope=MemoryScope.SESSION,
            session_id=state['session_id'],
            agent_id=self.name
        )
        
        logger.info(f"[{self.name}] âœ… Report saved to shared memory")
        logger.info(f"=" * 80)
        
        return state


###################
# Orchestrator
###################

class AgentOrchestrator:
    """Orchestrator for multi-agent workflow."""
    
    def __init__(self, config: Any = None):
        """Initialize orchestrator."""
        self.config = config
        self.shared_memory = get_shared_memory()
        self.skill_manager = get_skill_manager()
        self.agent_config = get_agent_config()
        self.graph = None
        # GraphëŠ” ì²« ì‹¤í–‰ ì‹œ ì¿¼ë¦¬ ê¸°ë°˜ìœ¼ë¡œ ë¹Œë“œ
        
        # SharedResultsManagerì™€ AgentDiscussionManagerëŠ” execute ì‹œì ì— ì´ˆê¸°í™”
        # (objective_idê°€ í•„ìš”í•˜ë¯€ë¡œ)
        self.shared_results_manager: Optional[SharedResultsManager] = None
        self.discussion_manager: Optional[AgentDiscussionManager] = None
        
        logger.info("AgentOrchestrator initialized")
    
    def _build_graph(self, user_query: Optional[str] = None, session_id: Optional[str] = None) -> None:
        """Build LangGraph workflow with Skills auto-selection."""
        
        # Create context for all agents
        context = AgentContext(
            agent_id="orchestrator",
            session_id=session_id or "default",
            shared_memory=self.shared_memory,
            config=self.config,
            shared_results_manager=self.shared_results_manager,
            discussion_manager=self.discussion_manager
        )
        
        # Skills ìë™ ì„ íƒ (ì¿¼ë¦¬ê°€ ìˆìœ¼ë©´)
        selected_skills = {}
        if user_query:
            skill_selector = get_skill_selector()
            matches = skill_selector.select_skills_for_task(user_query)
            for match in matches:
                skill = self.skill_manager.load_skill(match.skill_id)
                if skill:
                    selected_skills[match.skill_id] = skill
        
        # Initialize agents with Skills
        self.planner = PlannerAgent(context, selected_skills.get("research_planner"))
        self.executor = ExecutorAgent(context, selected_skills.get("research_executor"))
        self.verifier = VerifierAgent(context, selected_skills.get("evaluator"))
        self.generator = GeneratorAgent(context, selected_skills.get("synthesizer"))
        
        # Build graph
        workflow = StateGraph(AgentState)
        
        # Add nodes
        workflow.add_node("planner", self._planner_node)
        workflow.add_node("executor", self._executor_node)
        workflow.add_node("verifier", self._verifier_node)
        workflow.add_node("generator", self._generator_node)
        workflow.add_node("end", self._end_node)
        
        # Define edges
        workflow.set_entry_point("planner")
        workflow.add_edge("planner", "executor")
        workflow.add_edge("executor", "verifier")
        workflow.add_edge("verifier", "generator")
        workflow.add_edge("generator", "end")
        
        # Compile graph
        self.graph = workflow.compile()
        
        logger.info("LangGraph workflow built")
    
    async def _planner_node(self, state: AgentState) -> AgentState:
        """Planner node execution with tracking."""
        logger.info("=" * 80)
        logger.info("ğŸ”µ [WORKFLOW] â†’ Planner Node")
        logger.info("=" * 80)
        result = await self.planner.execute(state)
        logger.info(f"ğŸ”µ [WORKFLOW] âœ“ Planner completed: {result.get('current_agent')}")
        return result
    
    async def _executor_node(self, state: AgentState) -> AgentState:
        """Executor node execution with tracking."""
        logger.info("=" * 80)
        logger.info("ğŸŸ¢ [WORKFLOW] â†’ Executor Node")
        logger.info("=" * 80)
        result = await self.executor.execute(state)
        logger.info(f"ğŸŸ¢ [WORKFLOW] âœ“ Executor completed: {len(result.get('research_results', []))} results")
        return result
    
    async def _verifier_node(self, state: AgentState) -> AgentState:
        """Verifier node execution with tracking."""
        logger.info("=" * 80)
        logger.info("ğŸŸ¡ [WORKFLOW] â†’ Verifier Node")
        logger.info("=" * 80)
        result = await self.verifier.execute(state)
        logger.info(f"ğŸŸ¡ [WORKFLOW] âœ“ Verifier completed: {len(result.get('verified_results', []))} verified")
        return result
    
    async def _generator_node(self, state: AgentState) -> AgentState:
        """Generator node execution with tracking."""
        logger.info("=" * 80)
        logger.info("ğŸŸ£ [WORKFLOW] â†’ Generator Node")
        logger.info("=" * 80)
        result = await self.generator.execute(state)
        logger.info(f"ğŸŸ£ [WORKFLOW] âœ“ Generator completed: report_length={len(result.get('final_report', ''))}")
        return result
    
    async def _end_node(self, state: AgentState) -> AgentState:
        """End node - final state with summary."""
        logger.info("=" * 80)
        logger.info("âœ… [WORKFLOW] â†’ End Node - Workflow Completed")
        logger.info("=" * 80)
        logger.info(f"Session: {state.get('session_id')}")
        logger.info(f"Final Agent: {state.get('current_agent')}")
        logger.info(f"Research Results: {len(state.get('research_results', []))}")
        logger.info(f"Verified Results: {len(state.get('verified_results', []))}")
        logger.info(f"Report Generated: {bool(state.get('final_report'))}")
        logger.info(f"Failed: {state.get('research_failed') or state.get('verification_failed') or state.get('report_failed')}")
        logger.info("=" * 80)
        return state
    
    async def execute(self, user_query: str, session_id: Optional[str] = None) -> Dict[str, Any]:
        """
        Execute multi-agent workflow with Skills auto-selection.
        
        Args:
            user_query: User's research query
            session_id: Session ID
            
        Returns:
            Final result from the workflow
        """
        if session_id is None:
            session_id = f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        logger.info(f"Starting workflow for query: {user_query}")
        
        # Objective ID ìƒì„± (ë³‘ë ¬ ì‹¤í–‰ ë° ê²°ê³¼ ê³µìœ ìš©)
        objective_id = f"objective_{session_id}"
        
        # SharedResultsManagerì™€ AgentDiscussionManager ì´ˆê¸°í™” (ë³‘ë ¬ ì‹¤í–‰ í™œì„±í™” ì‹œ)
        if self.agent_config.enable_agent_communication:
            self.shared_results_manager = SharedResultsManager(objective_id=objective_id)
            self.discussion_manager = AgentDiscussionManager(
                objective_id=objective_id,
                shared_results_manager=self.shared_results_manager
            )
            logger.info("âœ… Agent result sharing and discussion enabled")
        else:
            self.shared_results_manager = None
            self.discussion_manager = None
            logger.info("Agent communication disabled")
        
        # Graphê°€ ì—†ê±°ë‚˜ ì¿¼ë¦¬ ê¸°ë°˜ ì¬ë¹Œë“œê°€ í•„ìš”í•œ ê²½ìš° ë¹Œë“œ
        if self.graph is None:
            self._build_graph(user_query, session_id)
        
        # Initialize state
        initial_state = AgentState(
            messages=[],
            user_query=user_query,
            research_plan=None,
            research_results=[],
            verified_results=[],
            final_report=None,
            current_agent=None,
            iteration=0,
            session_id=session_id
        )
        
        # Execute workflow
        try:
            result = await self.graph.ainvoke(initial_state)
            logger.info("Workflow execution completed successfully")
            return result
        except Exception as e:
            logger.error(f"Workflow execution failed: {e}")
            raise
    
    async def stream(self, user_query: str, session_id: Optional[str] = None):
        """Stream workflow execution."""
        if session_id is None:
            session_id = f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # Initialize state
        initial_state = AgentState(
            messages=[],
            user_query=user_query,
            research_plan=None,
            research_results=[],
            verified_results=[],
            final_report=None,
            current_agent=None,
            iteration=0,
            session_id=session_id
        )
        
        # Stream execution
        async for event in self.graph.astream(initial_state):
            yield event


# Global orchestrator instance
_orchestrator: Optional[AgentOrchestrator] = None


def get_orchestrator(config: Any = None) -> AgentOrchestrator:
    """Get global orchestrator instance."""
    global _orchestrator
    
    if _orchestrator is None:
        _orchestrator = AgentOrchestrator(config=config)
    
    return _orchestrator


def init_orchestrator(config: Any = None) -> AgentOrchestrator:
    """Initialize orchestrator."""
    global _orchestrator
    
    _orchestrator = AgentOrchestrator(config=config)
    
    return _orchestrator

