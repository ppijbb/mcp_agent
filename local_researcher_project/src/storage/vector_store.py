#!/usr/bin/env python3
"""
Vector Store for Local Researcher Project (v2.0 - 8ëŒ€ í˜ì‹ )

Production-grade ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ í†µí•© ì‹œìŠ¤í…œ.
ChromaDBì™€ Qdrantë¥¼ ì§€ì›í•˜ë©°, ì—°êµ¬ ê²°ê³¼ ìž„ë² ë”© ë° ì €ìž¥,
ì‹œë§¨í‹± ê²€ìƒ‰, ìœ ì‚¬ ì—°êµ¬ ì°¾ê¸° ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

2025ë…„ 10ì›” ìµœì‹  ê¸°ìˆ  ìŠ¤íƒ:
- ChromaDB 0.4.18+ for vector storage
- Qdrant for advanced vector operations
- sentence-transformers 2.2.2+ for embeddings
- Production-grade reliability patterns
"""

import asyncio
import logging
import json
import uuid
from datetime import datetime, timezone
from typing import Dict, Any, List, Optional, Tuple, Union
from dataclasses import dataclass, asdict
from enum import Enum
import numpy as np
from pathlib import Path
import os

# Vector database imports
try:
    import chromadb
    from chromadb.config import Settings
    CHROMADB_AVAILABLE = True
except ImportError:
    CHROMADB_AVAILABLE = False

try:
    from qdrant_client import QdrantClient
    from qdrant_client.http import models
    QDRANT_AVAILABLE = True
except ImportError:
    QDRANT_AVAILABLE = False

# Embedding imports
try:
    from sentence_transformers import SentenceTransformer
    SENTENCE_TRANSFORMERS_AVAILABLE = True
except ImportError:
    SENTENCE_TRANSFORMERS_AVAILABLE = False

# MCP integration
import sys
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.core.mcp_integration import execute_tool
from src.core.reliability import execute_with_reliability
from src.core.logging_config import get_logger

logger = get_logger(__name__)


class VectorDBType(Enum):
    """ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ íƒ€ìž…."""
    CHROMADB = "chromadb"
    QDRANT = "qdrant"
    HYBRID = "hybrid"  # ChromaDB + Qdrant


@dataclass
class ResearchMemory:
    """ì—°êµ¬ ë©”ëª¨ë¦¬ ë°ì´í„° êµ¬ì¡°."""
    research_id: str
    user_id: str
    topic: str
    timestamp: datetime
    embedding: List[float]
    metadata: Dict[str, Any]
    results: Dict[str, Any]
    content: str
    summary: str
    keywords: List[str]
    confidence_score: float = 0.0
    source_count: int = 0
    verification_status: str = "unverified"
    
    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜."""
        data = asdict(self)
        data['timestamp'] = self.timestamp.isoformat()
        return data


@dataclass
class SearchResult:
    """ê²€ìƒ‰ ê²°ê³¼."""
    research_id: str
    similarity_score: float
    content: str
    summary: str
    metadata: Dict[str, Any]
    timestamp: datetime


class VectorStore:
    """
    Production-grade ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ í†µí•© ì‹œìŠ¤í…œ.
    
    Features:
    - ChromaDB ë˜ëŠ” Qdrant í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    - ì—°êµ¬ ê²°ê³¼ ìž„ë² ë”© ë° ì €ìž¥
    - ì‹œë§¨í‹± ê²€ìƒ‰ ê¸°ëŠ¥
    - ìœ ì‚¬ ì—°êµ¬ ì°¾ê¸°
    - í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤í† ë¦¬ì§€ ì§€ì›
    """
    
    def __init__(
        self,
        db_type: VectorDBType = VectorDBType.CHROMADB,
        collection_name: str = "research_memories",
        persist_directory: str = "./vector_db"
    ):
        """
        ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”.
        
        Args:
            db_type: ì‚¬ìš©í•  ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ íƒ€ìž…
            collection_name: ì»¬ë ‰ì…˜ ì´ë¦„
            persist_directory: ë°ì´í„° ì €ìž¥ ë””ë ‰í† ë¦¬
        """
        self.db_type = db_type
        self.collection_name = collection_name
        self.persist_directory = Path(persist_directory)
        self.persist_directory.mkdir(parents=True, exist_ok=True)
        
        # ìž„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        self.embedding_model = self._initialize_embedding_model()
        
        # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.chroma_client = None
        self.qdrant_client = None
        self.collection = None
        
        if db_type in [VectorDBType.CHROMADB, VectorDBType.HYBRID]:
            self._initialize_chromadb()
        
        if db_type in [VectorDBType.QDRANT, VectorDBType.HYBRID]:
            self._initialize_qdrant()
        
        logger.info(f"VectorStore initialized with {db_type.value} database")
    
    def _initialize_embedding_model(self) -> Optional[SentenceTransformer]:
        """ìž„ë² ë”© ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        if not SENTENCE_TRANSFORMERS_AVAILABLE:
            logger.warning("sentence-transformers not available, using MCP tools for embeddings")
            return None
        
        try:
            # ë‹¤êµ­ì–´ ì§€ì› ëª¨ë¸ ì‚¬ìš©
            model = SentenceTransformer('all-MiniLM-L6-v2')
            logger.info("Embedding model initialized: all-MiniLM-L6-v2")
            return model
        except Exception as e:
            logger.warning(f"Failed to initialize embedding model: {e}")
            return None
    
    def _initialize_chromadb(self) -> None:
        """ChromaDBë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        if not CHROMADB_AVAILABLE:
            logger.warning("âš ï¸ ChromaDB not available - running without vector search capabilities")
            logger.warning("   Install with: pip install chromadb")
            logger.info("â„¹ï¸ ChromaDB not available: vector search disabled, basic operations only")
            self.chroma_client = None
            self.collection = None
            return
        
        try:
            logger.info(f"ðŸ”§ Initializing ChromaDB at: {self.persist_directory / 'chromadb'}")
            self.chroma_client = chromadb.PersistentClient(
                path=str(self.persist_directory / "chromadb"),
                settings=Settings(
                    anonymized_telemetry=False,
                    allow_reset=True
                )
            )
            
            # ì»¬ë ‰ì…˜ ìƒì„± ë˜ëŠ” ê°€ì ¸ì˜¤ê¸°
            self.collection = self.chroma_client.get_or_create_collection(
                name=self.collection_name,
                metadata={"description": "Research memories and findings"}
            )
            
            logger.info(f"âœ… ChromaDB initialized successfully with collection: {self.collection_name}")
            logger.info(f"ðŸ“Š Collection contains {self.collection.count()} items")
            
        except ImportError as e:
            logger.error(f"âŒ ChromaDB import failed: {e}")
            logger.error("   Install with: pip install chromadb")
            self.chroma_client = None
            self.collection = None
        except Exception as e:
            logger.error(f"âŒ Failed to initialize ChromaDB: {e}")
            logger.error(f"   Error type: {type(e).__name__}")
            logger.warning("âš ï¸ Falling back to in-memory mode without vector search")
            self.chroma_client = None
            self.collection = None
    
    def _initialize_qdrant(self) -> None:
        """Qdrantë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        if not QDRANT_AVAILABLE:
            logger.error("Qdrant not available")
            return
        
        try:
            # ë¡œì»¬ Qdrant ì„œë²„ ì‚¬ìš©
            self.qdrant_client = QdrantClient(
                path=str(self.persist_directory / "qdrant")
            )
            
            # ì»¬ë ‰ì…˜ ìƒì„±
            try:
                self.qdrant_client.create_collection(
                    collection_name=self.collection_name,
                    vectors_config=models.VectorParams(
                        size=384,  # all-MiniLM-L6-v2 embedding size
                        distance=models.Distance.COSINE
                    )
                )
            except Exception:
                # ì»¬ë ‰ì…˜ì´ ì´ë¯¸ ì¡´ìž¬í•˜ëŠ” ê²½ìš°
                pass
            
            logger.info(f"Qdrant initialized with collection: {self.collection_name}")
            
        except Exception as e:
            logger.error(f"Failed to initialize Qdrant: {e}")
            self.qdrant_client = None
    
    async def generate_embedding(self, text: str) -> List[float]:
        """í…ìŠ¤íŠ¸ ìž„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            if self.embedding_model:
                # ë¡œì»¬ ëª¨ë¸ ì‚¬ìš©
                embedding = self.embedding_model.encode(text)
                return embedding.tolist()
            else:
                # MCP ë„êµ¬ ì‚¬ìš©
                result = await execute_tool("embed_text", {
                    "text": text,
                    "model": "all-MiniLM-L6-v2"
                })
                
                if result.get('success', False):
                    return result.get('data', {}).get('embedding', [])
                else:
                    logger.warning("MCP embedding failed, using simple text hash")
                    # ê°„ë‹¨í•œ í•´ì‹œ ê¸°ë°˜ ìž„ë² ë”© (ChromaDB ì—†ì„ ë•Œ)
                    return self._simple_hash_embedding(text)
                    
        except Exception as e:
            logger.error(f"Embedding generation failed: {e}")
            return self._simple_hash_embedding(text)
    
    def _simple_hash_embedding(self, text: str) -> List[float]:
        """ê°„ë‹¨í•œ í•´ì‹œ ê¸°ë°˜ ìž„ë² ë”© (ChromaDB ì—†ì„ ë•Œ ì‚¬ìš©)."""
        import hashlib
        
        # í…ìŠ¤íŠ¸ë¥¼ í•´ì‹œí•˜ê³  384ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜
        hash_obj = hashlib.sha256(text.encode())
        hash_bytes = hash_obj.digest()
        
        # 384ì°¨ì› ë²¡í„° ìƒì„± (32ë°”ì´íŠ¸ í•´ì‹œë¥¼ ë°˜ë³µí•˜ì—¬ í™•ìž¥)
        embedding = []
        for i in range(384):
            byte_idx = i % 32
            embedding.append((hash_bytes[byte_idx] - 128) / 128.0)
        
        return embedding
    
    async def store_research_memory(self, memory: ResearchMemory) -> bool:
        """
        ì—°êµ¬ ë©”ëª¨ë¦¬ë¥¼ ì €ìž¥í•©ë‹ˆë‹¤.
        
        Args:
            memory: ì €ìž¥í•  ì—°êµ¬ ë©”ëª¨ë¦¬
            
        Returns:
            bool: ì €ìž¥ ì„±ê³µ ì—¬ë¶€
        """
        try:
            # ìž„ë² ë”© ìƒì„±
            if not memory.embedding:
                memory.embedding = await self.generate_embedding(memory.content)
            
            # ChromaDBì— ì €ìž¥
            if self.chroma_client and self.collection:
                await self._store_in_chromadb(memory)
            
            # Qdrantì— ì €ìž¥
            if self.qdrant_client:
                await self._store_in_qdrant(memory)
            
            logger.info(f"Research memory stored: {memory.research_id}")
            return True
            
        except Exception as e:
            logger.error(f"Failed to store research memory: {e}")
            return False
    
    async def _store_in_chromadb(self, memory: ResearchMemory) -> None:
        """ChromaDBì— ì €ìž¥í•©ë‹ˆë‹¤."""
        try:
            self.collection.add(
                ids=[memory.research_id],
                embeddings=[memory.embedding],
                documents=[memory.content],
                metadatas=[memory.metadata]
            )
            logger.debug(f"Stored in ChromaDB: {memory.research_id}")
        except Exception as e:
            logger.error(f"ChromaDB storage failed: {e}")
            raise
    
    async def _store_in_qdrant(self, memory: ResearchMemory) -> None:
        """Qdrantì— ì €ìž¥í•©ë‹ˆë‹¤."""
        try:
            self.qdrant_client.upsert(
                collection_name=self.collection_name,
                points=[
                    models.PointStruct(
                        id=hash(memory.research_id) % (2**63),  # 64ë¹„íŠ¸ ì •ìˆ˜ë¡œ ë³€í™˜
                        vector=memory.embedding,
                        payload={
                            "research_id": memory.research_id,
                            "user_id": memory.user_id,
                            "topic": memory.topic,
                            "timestamp": memory.timestamp.isoformat(),
                            "content": memory.content,
                            "summary": memory.summary,
                            "keywords": memory.keywords,
                            "confidence_score": memory.confidence_score,
                            "source_count": memory.source_count,
                            "verification_status": memory.verification_status,
                            **memory.metadata
                        }
                    )
                ]
            )
            logger.debug(f"Stored in Qdrant: {memory.research_id}")
        except Exception as e:
            logger.error(f"Qdrant storage failed: {e}")
            raise
    
    async def search_similar_research(
        self,
        query: str,
        user_id: Optional[str] = None,
        limit: int = 10,
        similarity_threshold: float = 0.7
    ) -> List[SearchResult]:
        """
        ìœ ì‚¬í•œ ì—°êµ¬ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            user_id: ì‚¬ìš©ìž ID (ì„ íƒì‚¬í•­)
            limit: ê²°ê³¼ ìˆ˜ ì œí•œ
            similarity_threshold: ìœ ì‚¬ë„ ìž„ê³„ê°’
            
        Returns:
            List[SearchResult]: ê²€ìƒ‰ ê²°ê³¼
        """
        try:
            # ì¿¼ë¦¬ ìž„ë² ë”© ìƒì„±
            query_embedding = await self.generate_embedding(query)
            
            results = []
            
            # ChromaDBì—ì„œ ê²€ìƒ‰
            if self.chroma_client and self.collection:
                chroma_results = await self._search_in_chromadb(
                    query_embedding, user_id, limit, similarity_threshold
                )
                results.extend(chroma_results)
            
            # Qdrantì—ì„œ ê²€ìƒ‰
            if self.qdrant_client:
                qdrant_results = await self._search_in_qdrant(
                    query_embedding, user_id, limit, similarity_threshold
                )
                results.extend(qdrant_results)
            
            # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
            unique_results = self._deduplicate_results(results)
            sorted_results = sorted(
                unique_results,
                key=lambda x: x.similarity_score,
                reverse=True
            )
            
            logger.info(f"Found {len(sorted_results)} similar research results")
            return sorted_results[:limit]
            
        except Exception as e:
            logger.error(f"Search failed: {e}")
            return []
    
    async def _search_in_chromadb(
        self,
        query_embedding: List[float],
        user_id: Optional[str],
        limit: int,
        similarity_threshold: float
    ) -> List[SearchResult]:
        """ChromaDBì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
        try:
            # í•„í„° ì¡°ê±´ ì„¤ì •
            where_filter = {}
            if user_id:
                where_filter["user_id"] = user_id
            
            # ê²€ìƒ‰ ì‹¤í–‰
            results = self.collection.query(
                query_embeddings=[query_embedding],
                n_results=limit,
                where=where_filter if where_filter else None
            )
            
            search_results = []
            if results['ids'] and results['ids'][0]:
                for i, research_id in enumerate(results['ids'][0]):
                    distance = results['distances'][0][i]
                    similarity_score = 1 - distance  # ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜
                    
                    if similarity_score >= similarity_threshold:
                        metadata = results['metadatas'][0][i] if results['metadatas'] else {}
                        content = results['documents'][0][i] if results['documents'] else ""
                        
                        search_results.append(SearchResult(
                            research_id=research_id,
                            similarity_score=similarity_score,
                            content=content,
                            summary=metadata.get('summary', ''),
                            metadata=metadata,
                            timestamp=datetime.fromisoformat(metadata.get('timestamp', datetime.now().isoformat()))
                        ))
            
            return search_results
            
        except Exception as e:
            logger.error(f"ChromaDB search failed: {e}")
            return []
    
    async def _search_in_qdrant(
        self,
        query_embedding: List[float],
        user_id: Optional[str],
        limit: int,
        similarity_threshold: float
    ) -> List[SearchResult]:
        """Qdrantì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
        try:
            # í•„í„° ì¡°ê±´ ì„¤ì •
            filter_conditions = None
            if user_id:
                filter_conditions = models.Filter(
                    must=[
                        models.FieldCondition(
                            key="user_id",
                            match=models.MatchValue(value=user_id)
                        )
                    ]
                )
            
            # ê²€ìƒ‰ ì‹¤í–‰
            results = self.qdrant_client.search(
                collection_name=self.collection_name,
                query_vector=query_embedding,
                limit=limit,
                query_filter=filter_conditions,
                score_threshold=similarity_threshold
            )
            
            search_results = []
            for result in results:
                payload = result.payload
                search_results.append(SearchResult(
                    research_id=payload.get('research_id', ''),
                    similarity_score=result.score,
                    content=payload.get('content', ''),
                    summary=payload.get('summary', ''),
                    metadata=payload,
                    timestamp=datetime.fromisoformat(payload.get('timestamp', datetime.now().isoformat()))
                ))
            
            return search_results
            
        except Exception as e:
            logger.error(f"Qdrant search failed: {e}")
            return []
    
    def _deduplicate_results(self, results: List[SearchResult]) -> List[SearchResult]:
        """ì¤‘ë³µ ê²°ê³¼ë¥¼ ì œê±°í•©ë‹ˆë‹¤."""
        seen_ids = set()
        unique_results = []
        
        for result in results:
            if result.research_id not in seen_ids:
                seen_ids.add(result.research_id)
                unique_results.append(result)
        
        return unique_results
    
    async def get_research_memory(self, research_id: str) -> Optional[ResearchMemory]:
        """íŠ¹ì • ì—°êµ¬ ë©”ëª¨ë¦¬ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        try:
            # ChromaDBì—ì„œ ê²€ìƒ‰
            if self.chroma_client and self.collection:
                results = self.collection.get(ids=[research_id])
                if results['ids']:
                    metadata = results['metadatas'][0] if results['metadatas'] else {}
                    content = results['documents'][0] if results['documents'] else ""
                    embedding = results['embeddings'][0] if results['embeddings'] else []
                    
                    return ResearchMemory(
                        research_id=research_id,
                        user_id=metadata.get('user_id', ''),
                        topic=metadata.get('topic', ''),
                        timestamp=datetime.fromisoformat(metadata.get('timestamp', datetime.now().isoformat())),
                        embedding=embedding,
                        metadata=metadata,
                        results=metadata.get('results', {}),
                        content=content,
                        summary=metadata.get('summary', ''),
                        keywords=metadata.get('keywords', []),
                        confidence_score=metadata.get('confidence_score', 0.0),
                        source_count=metadata.get('source_count', 0),
                        verification_status=metadata.get('verification_status', 'unverified')
                    )
            
            return None
            
        except Exception as e:
            logger.error(f"Failed to get research memory: {e}")
            return None
    
    async def update_research_memory(self, memory: ResearchMemory) -> bool:
        """ì—°êµ¬ ë©”ëª¨ë¦¬ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
        try:
            # ìž„ë² ë”© ìž¬ìƒì„±
            memory.embedding = await self.generate_embedding(memory.content)
            
            # ì €ìž¥ (upsert)
            return await self.store_research_memory(memory)
            
        except Exception as e:
            logger.error(f"Failed to update research memory: {e}")
            return False
    
    async def delete_research_memory(self, research_id: str) -> bool:
        """ì—°êµ¬ ë©”ëª¨ë¦¬ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤."""
        try:
            # ChromaDBì—ì„œ ì‚­ì œ
            if self.chroma_client and self.collection:
                self.collection.delete(ids=[research_id])
            
            # Qdrantì—ì„œ ì‚­ì œ
            if self.qdrant_client:
                self.qdrant_client.delete(
                    collection_name=self.collection_name,
                    points_selector=models.PointIdsList(
                        points=[hash(research_id) % (2**63)]
                    )
                )
            
            logger.info(f"Research memory deleted: {research_id}")
            return True
            
        except Exception as e:
            logger.error(f"Failed to delete research memory: {e}")
            return False
    
    async def get_user_research_history(self, user_id: str, limit: int = 50) -> List[ResearchMemory]:
        """ì‚¬ìš©ìžì˜ ì—°êµ¬ ížˆìŠ¤í† ë¦¬ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        try:
            # ChromaDBì—ì„œ ì‚¬ìš©ìžë³„ ê²€ìƒ‰
            if self.chroma_client and self.collection:
                results = self.collection.query(
                    query_embeddings=[[0.0] * 384],  # ë”ë¯¸ ìž„ë² ë”©
                    n_results=limit,
                    where={"user_id": user_id}
                )
                
                memories = []
                if results['ids'] and results['ids'][0]:
                    for i, research_id in enumerate(results['ids'][0]):
                        metadata = results['metadatas'][0][i] if results['metadatas'] else {}
                        content = results['documents'][0][i] if results['documents'] else ""
                        embedding = results['embeddings'][0][i] if results['embeddings'] else []
                        
                        memory = ResearchMemory(
                            research_id=research_id,
                            user_id=metadata.get('user_id', user_id),
                            topic=metadata.get('topic', ''),
                            timestamp=datetime.fromisoformat(metadata.get('timestamp', datetime.now().isoformat())),
                            embedding=embedding,
                            metadata=metadata,
                            results=metadata.get('results', {}),
                            content=content,
                            summary=metadata.get('summary', ''),
                            keywords=metadata.get('keywords', []),
                            confidence_score=metadata.get('confidence_score', 0.0),
                            source_count=metadata.get('source_count', 0),
                            verification_status=metadata.get('verification_status', 'unverified')
                        )
                        memories.append(memory)
                
                return memories
            
            return []
            
        except Exception as e:
            logger.error(f"Failed to get user research history: {e}")
            return []
    
    def get_collection_stats(self) -> Dict[str, Any]:
        """ì»¬ë ‰ì…˜ í†µê³„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        stats = {
            'db_type': self.db_type.value,
            'collection_name': self.collection_name,
            'chromadb_available': self.chroma_client is not None,
            'qdrant_available': self.qdrant_client is not None,
            'embedding_model_available': self.embedding_model is not None
        }
        
        try:
            if self.chroma_client and self.collection:
                count = self.collection.count()
                stats['total_documents'] = count
                stats['chromadb_status'] = 'active'
            else:
                stats['chromadb_status'] = 'inactive'
            
            if self.qdrant_client:
                info = self.qdrant_client.get_collection(self.collection_name)
                stats['qdrant_points'] = info.points_count
                stats['qdrant_status'] = 'active'
            else:
                stats['qdrant_status'] = 'inactive'
                
        except Exception as e:
            logger.warning(f"Failed to get collection stats: {e}")
            stats['error'] = str(e)
        
        return stats
